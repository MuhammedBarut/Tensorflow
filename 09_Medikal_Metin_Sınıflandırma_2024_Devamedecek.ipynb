{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Medikal Metinlerin SÄ±nÄ±flandÄ±rÄ±lmasÄ±**"
      ],
      "metadata": {
        "id": "76ILSckHUDRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\"Bu Ã§alÄ±ÅŸma kitabÄ±nÄ±n son Ã§alÄ±ÅŸma tarihi: {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "id": "bjYpVtvDXEZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783e2765-51ae-4a79-f3b1-b3534a522cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bu Ã§alÄ±ÅŸma kitabÄ±nÄ±n son Ã§alÄ±ÅŸma tarihi: 2025-01-02 19:29:58.423089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU var mÄ±?\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "jrV2Rn7OXYgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1583b019-4b29-4612-8f79-a09e100e5811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5a3cb6f8-b03a-a8b4-bddd-74a236c92ff7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ä°Ã§indekiler**\n",
        "```\n",
        "1. TanÄ±tÄ±m & Genel Bilgiler\n",
        "2. Veri\n",
        "  2.1. Verilerin YÃ¼klenmesi ve KontrolÃ¼\n",
        "  2.2. SatÄ±r Okuma Fonksiyonu\n",
        "  2.3. Veriyi Ã–n Ä°ÅŸleyecek Fonksiyon YazÄ±mÄ±\n",
        "  2.4. Verilerin Ä°ncelenmesi\n",
        "  2.5. Tek SÄ±cak KodlayÄ±cÄ± Ä°le SayÄ±sal Etiketler\n",
        "3. Modelleme\n",
        "  3.1. Model 0 Temel Model YazÄ±mÄ± ve DeÄŸerlendirilmesi\n",
        "  3.2. YardÄ±mcÄ± Fonksiyonlar DosyasÄ±\n",
        "  3.3. Derin Modelleme Ä°Ã§in Veri HazÄ±rlÄ±ÄŸÄ±\n",
        "  3.4. Metin VektÃ¶rleÅŸtirme\n",
        "  3.5. GÃ¶mme HazÄ±rlama\n",
        "  3.6. Veri KÃ¼melerini hazÄ±rlama\n",
        "  3.7. Kelime DÃ¼zeyinde Conv1D Ä°le Modelleme ve DeÄŸerlendirme\n",
        "  3.8. Tensorflow Hub Ä°le Modelleme ve DeÄŸerlendirme\n",
        "  3.9. Karakter DÃ¼zeyinde Conv1D Ä°le Modelleme ve DeÄŸerlendirme\n",
        "  3.10. Ã–nceden EÄŸitilmiÅŸ Token GÃ¶mmeler ve Karakter GÃ¶mmeleri BirleÅŸtirerek Modelleme ve DeÄŸerlendirme\n",
        "  3.11. Ã–nceden EÄŸitilmiÅŸ Token GÃ¶mmeler, Karakter GÃ¶mmeleri ve Konumsal GÃ¶mmeleri BirleÅŸtirerek Modelleme ve DeÄŸerlendirme\n",
        "4. Model SonuÃ§larÄ±nÄ± KarÅŸÄ±laÅŸtÄ±r\n",
        "5. Model Kaydetme ve YÃ¼kleme\n",
        "6. DeÄŸerlendirme\n",
        "  6.1. DoÄŸrulama Veri Setini DeÄŸerlendir\n",
        "  6.2. Test Veri Setinde Modeli DeÄŸerlendir\n",
        "  6.3. En Ã‡ok YanlÄ±ÅŸÄ± Bul\n",
        "  6.4. Ã–rnek Tahminler Yap\n",
        "  6.5. Kendi Denemelerim :)\n",
        "7. KaynakÃ§a\n",
        "```"
      ],
      "metadata": {
        "id": "WI5e_GQqUDEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. TanÄ±tÄ±m & Genel Bilgiler**"
      ],
      "metadata": {
        "id": "AlgHgm_9j5sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PubMed saÄŸlÄ±kla ilgili makalelerin yer aldÄ±ÄŸÄ± bir websitesidir. Bu Ã§alÄ±ÅŸmada 2017 tarihli PubMed 200k RCT makalesinin arkasÄ±ndaki derin Ã¶ÄŸrenme modelini Ã§oÄŸaltacaÄŸÄ±z: TÄ±bbi Ã–zetlerde SÄ±ralÄ± CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Bir Veri KÃ¼mesi. https://arxiv.org/abs/1710.06071\n",
        "\n",
        "YayÄ±nlandÄ±ÄŸÄ±nda, makale ~200.000 etiketli Randomize KontrollÃ¼ Deneme (RCT) Ã¶zetinden oluÅŸan PubMed 200k RCT adlÄ± yeni bir veri kÃ¼mesi sundu.\n",
        "\n",
        "Veri kÃ¼mesinin amacÄ±, NLP modellerinin sÄ±ralÄ± olarak gÃ¶rÃ¼nen cÃ¼mleleri sÄ±nÄ±flandÄ±rma yeteneÄŸini araÅŸtÄ±rmaktÄ±.\n",
        "\n",
        "BaÅŸka bir deyiÅŸle, bir RCT'nin Ã¶zeti gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, her cÃ¼mle soyutta nasÄ±l bir role hizmet eder?\n",
        "\n",
        "Uzun bir paragrafÄ± bÃ¶lÃ¼mlere ayÄ±rÄ±p Ã¶zetini Ã§Ä±karmak isteseydik? Buradaki model many to one sorunu. Ã–rnek bir paragrafta on cÃ¼mle varsa hepsi ayrÄ± ayrÄ± deÄŸerlendirilir, bu input, ama hedef paragrafÄ±n etiketi ise tek kelime, bu da output. Yani kolaylaÅŸtÄ±rmak iÃ§in her bir diziye hangi bÃ¶lÃ¼me ait olmalarÄ± gerektiÄŸine dair etiket veririz."
      ],
      "metadata": {
        "id": "jhvGdVthvDY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelleme AdÄ±mlarÄ±\n",
        "\n",
        "1. Verileri hazÄ±rlayÄ±n (tensÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n)\n",
        "2. Tensorflow hub'Ä±, Ã¶nceden eÄŸitilmiÅŸ bir model oluÅŸturun veya seÃ§in (sorunuza uyacak ÅŸekilde)\n",
        "3. Modeli verilere uydurun ve tahmin yapÄ±n\n",
        "4. Modeli deÄŸerlendirin\n",
        "5. Deneyerek geliÅŸtirin\n",
        "6. EÄŸitilen modelinizi kaydedin ve yeniden yÃ¼kleyin\n",
        "\n",
        "* TÃ¼m veri sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmeli. NÃ¶ral aÄŸlar metin veya doÄŸal dil iÅŸleyemez.\n",
        "* TÃ¼m tensÃ¶rler doÄŸru Ã¶lÃ§Ã¼de (ÅŸekil) olmalÄ±dÄ±r."
      ],
      "metadata": {
        "id": "JR5IyqAduq4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ã–rneÄŸin;\n",
        "\n",
        "**OkumasÄ± zor:**\n",
        "\n",
        "Nutritional psychiatry: the present state of the\n",
        "evidence\n",
        "\n",
        "Wolfgang Marx 1, Genevieve Moseley 2, Michael Berk 2, Felice Jacka 2\n",
        "\n",
        "Affiliations + expand\n",
        "PMID: 28942748 DOI: 10.1017/S0029665117002026\n",
        "Abstract Mental illness, including depression, anxiety and bipolar disorder, accounts for a significant\n",
        "proportion of global disability and poses a substantial social, economic and heath burden. Treatment is presently dominated by pharmacotherapy, such as antidepressants, and psychotherapy, such as cognitive behavioural therapy; however, such treatments avert less than half of the disease burden, suggesting that additional strategies are needed to prevent and treat mental disorders. There are now consistent mechanistic, observational and interventional data to suggest diet quality may be a modifiable risk factor for mental illness. This review provides an overview of the nutritional psychiatry field. It includes a discussion of the neurobiological mechanisms likely modulated by diet, the use of dietary and nutraceutical interventions in mental disorders, and recommendations for further research. Potential biological pathways related to mental disorders include inflammation, oxidative stress, the gut microbiome, epigenetic modifications and neuroplasticity. Consistent epidemiological evidence, particularly for depression, suggests an association between measures of diet quality and mental health, across multiple populations and age groups; these do not appear to be explained by other demographic, lifestyle factors or reverse causality. Our recently published intervention trial provides preliminary clinical evidence that dietary interventions in clinically diagnosed populations are feasible and can provide significant clinical benefit. Furthermore, nutraceuticals including n-3 fatty acids, folate, S- adenosylmethionine, N-acetyl cysteine and probiotics, among others, are promising avenues for future research. Continued research is now required to investigate the efficacy of intervention studies in large cohorts and within clinically relevant populations, particularly in patients with\n",
        "schizophrenia, bipolar and anxiety disorders.\n",
        "Source: https://pubmed.ncbi.n/m.nih.gov/28942748/\n",
        "\n",
        "**OkumasÄ± kolay:**\n",
        "\n",
        "Considerations for a surgical RCT for diffuse low-\n",
        "grade glioma: a survey\n",
        "\n",
        "Alireza Mansouri 1, Karanbir Brar 2, Michael D Cusimano 3\n",
        "Affiliations + expand\n",
        "\n",
        "PMID: 32537182 PMCID: PMC7274180 (available on 2021-06-01) DOI: 10.1093/nop/npz058\n",
        "\n",
        "Abstract\n",
        "Background: Diffuse low-grade gliomas (DLGGs) are heterogeneous tumors that inevitably\n",
        "-maximal safe resection of DLGGs has been favored. However, this transition is not supported by\n",
        "-ai realise it main an intes leadin a disa. Hi enver, ai. ansi, is sort upor up front :\n",
        "randomized controlled trial (RCT) data. Here, we sought to survey the neuro-oncology community\n",
        "\n",
        "Methods: A 21-question survey focusing on a surgical RCT for DLGGs was developed and validated by 2 neurosurgeons. A sample case of a patient for whom management might be debatable was presented to gather additional insight. The survey was disseminated to members of the Society for Neuro-Oncology (SNO) and responses were collected from March 16 to July 10,2018.\n",
        "\n",
        "Results: A total of 131 responses were collected. Sixty-three of 117 (54%) respondents thought an RCT would not be ethical, 39 of 117 (33%) would consider participating, and 56 of 117 (48%) believed an RCT would be valuable for determining the differing roles of biopsy, surgery, and observation. This was exemplified by an evenly distributed selection of the latter management options for our sample case. Eighty-three of 120 (69.2%) respondents did not believe in equipoise for DLGG patients. Quality of life and overall survival were deemed equally important end points for\n",
        "a putative RCT.\n",
        "\n",
        "Conclusions: Based on our survey, it is evident that management of certain DLGG patients is not well defined and an RCT may be justified. As with any surgical RCT, logistic challenges are anticipated. Robust patient-relevant end points and standardization of perioperative adjuncts are\n",
        "necessary if a surgical RCT is undertaken.\n",
        "Source: https://pubmed.ncbi.nlm.nih.gov/32537182/"
      ],
      "metadata": {
        "id": "0f2TXS9awbDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Veriler bazÄ± etiketler alÄ±r;**\n",
        "\n",
        "- background\n",
        "- objective\n",
        "- methods\n",
        "- result\n",
        "- conclusion\n",
        "\n",
        "Ã–rnek tahmin edilmiÅŸ output olarak [0.03, 0.82, 0.13, 0.02, 0.001] olabilir.\n",
        "\n",
        "Burada Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma var.\n",
        "\n",
        "input Ã¶rneÄŸi olarak shape = [batch_size, embedding_size]\n",
        "\n",
        "[None, 512] ya da [32, 512] gibi.\n",
        "\n",
        "Output shape [5] (YukarÄ±daki beÅŸ etikete dikkat. AslÄ±nda modelde makalede senin hangi parametreleri verdiÄŸinle ilgili bir konu).\n",
        "\n",
        "GiriÅŸ ve Ã§Ä±ktÄ± ÅŸekli Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z problemdeki gÃ¶mme stiline baÄŸlÄ±dÄ±r."
      ],
      "metadata": {
        "id": "1f55Khrvwr6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ã–rneÄŸin modele giren veri**\n",
        "\n",
        "Ã–rneÄŸin, aÅŸaÄŸÄ±daki girdiyi alan bir NLP modelini eÄŸitebilir miyiz (not: aÅŸaÄŸÄ±daki Ã¶rnekte tÃ¼m sayÄ±sal semboller \"@\" ile deÄŸiÅŸtirilmiÅŸtir):\n",
        "\n",
        "To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ). A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks. Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers. Pain was assessed using the visual analog pain scale ( @-@ mm ). Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD )., Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured. There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks. The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively. Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group. These differences remained significant at @ weeks. The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ). Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ).\n",
        "\n",
        "**Modelden Ã§Ä±kmÄ±ÅŸ olmasÄ± gereken durumu**\n",
        "\n",
        "Ve aÅŸaÄŸÄ±daki Ã§Ä±ktÄ±yÄ± dÃ¶ndÃ¼rÃ¼r:\n",
        "\n",
        "['###24293578\\n',\n",
        " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
        " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
        " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
        " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
        " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
        " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
        " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
        " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
        " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
        " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
        " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
        " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
        " '\\n']"
      ],
      "metadata": {
        "id": "37lwZ9uUw_aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AraÅŸtÄ±rmacÄ±larÄ±n literatÃ¼rÃ¼ gÃ¶zden geÃ§irmelerini gÃ¶zden geÃ§irmelerini ve gerektiÄŸinde daha derine dalmalarÄ±nÄ± saÄŸlamak iÃ§in soyut cÃ¼mleleri oynadÄ±klarÄ± role (Ã¶rneÄŸin amaÃ§, yÃ¶ntemler, sonuÃ§lar, vb.) sÄ±nÄ±flandÄ±rmak iÃ§in bir NLP modeli oluÅŸturun.\n",
        "\n",
        "1. Verilerimizin nereden geldiÄŸi: PubMed 200k RCT: TÄ±bbi Ã–zetlerde SÄ±ralÄ± CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in bir Veri KÃ¼mesi https://arxiv.org/abs/1710.06071\n",
        "\n",
        "2. Modelimiz nereden geliyor: TÄ±bbi kaÄŸÄ±t Ã¶zetlerinde ortak cÃ¼mle sÄ±nÄ±flandÄ±rmasÄ± iÃ§in sinir aÄŸlarÄ±. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "ğŸ“– Kaynaklar: Bu not defterindeki kodu gÃ¶zden geÃ§irmeden Ã¶nce, ne yapacaÄŸÄ±mÄ±za dair bir arka plan almak isteyebilirsiniz. Bunu yapmak iÃ§in, aÅŸaÄŸÄ±daki kaÄŸÄ±tlarÄ± gÃ¶zden geÃ§irmek iÃ§in bir (veya iki saat) harcayÄ±n ve ardÄ±ndan bu deftere dÃ¶nÃ¼n:"
      ],
      "metadata": {
        "id": "Qc-w9ycjxO4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Veri**"
      ],
      "metadata": {
        "id": "lZM8tNw0j5qB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1. Verilerin YÃ¼klenmesi ve KontrolÃ¼**"
      ],
      "metadata": {
        "id": "cS20h4pKj5ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PubMed 200k RCT veri kÃ¼mesini indirme iÅŸlemi\n",
        "# Makele yazarÄ± .txt formatÄ±nda dosyalarÄ± kaydetti https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "\n",
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "id": "BXqEQQkj2ofc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a0613c-86e7-4d68-95c7-8bd6adf44cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub sayfasÄ±ndaki README dosyasÄ±na baktÄ±ÄŸÄ±mÄ±zda aÅŸaÄŸÄ±daki bilgileri elde ediyoruz: https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "\n",
        "- PubMed 20k, PubMed 200k'nin bir alt kÃ¼mesidir. Yani, PubMed 20k'deki herhangi bir Ã¶zet mevcut, PubMed 200k'de de mevcuttur.\n",
        "\n",
        "- PubMed_200k_RCT, PubMed_200k_RCT_numbers_replaced_with_at_sign ile aynÄ±dÄ±r, ancak ikincisinde tÃ¼m sayÄ±lar @ ile deÄŸiÅŸtirilmiÅŸtir. (PubMed_20k_RCT vs. PubMed_20k_RCT_numbers_replaced_with_at_sign).\n",
        "\n",
        "- Github dosya boyutu sÄ±nÄ±rÄ± 100 MiB olduÄŸundan, PubMed_200k_RCT\\train.7z ve PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip dosyalarÄ±nÄ± sÄ±kÄ±ÅŸtÄ±rmak zorunda kaldÄ±k. Train.7z'yi aÃ§mak iÃ§in Windows'ta 7-Zip, Mac OS X'te Keka veya Linux'ta p7zip kullanabilirsiniz.\n",
        "\n",
        "BaÅŸlangÄ±Ã§ olarak, odaklanacaÄŸÄ±mÄ±z veri kÃ¼mesi PubMed_20k_RCT_numbers_replaced_with_at_sign'dÄ±r.\n",
        "\n",
        "TÃ¼m 200 bin veri kÃ¼mesiyle Ã§alÄ±ÅŸmak yerine, daha kÃ¼Ã§Ã¼k bir alt kÃ¼meyle baÅŸlayarak deneylerimizi hÄ±zlÄ± tutacaÄŸÄ±z. @ ile deÄŸiÅŸtirmek yerine sayÄ±larla veri kÃ¼mesini seÃ§ebilirdik ama seÃ§medik."
      ],
      "metadata": {
        "id": "FY2CYtR82sFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PubMed_20K veri setinde neler var?\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
        "\n",
        "# train.txt - eÄŸitim Ã¶rnekleri.\n",
        "# dev.txt - dev, doÄŸrulama kÃ¼mesinin baÅŸka bir adÄ± olan geliÅŸtirme kÃ¼mesinin kÄ±saltmasÄ±dÄ±r (doÄŸrulama olarak kullanÄ±yoruz)\n",
        "# test.txt - test Ã¶rnekleri."
      ],
      "metadata": {
        "id": "Rgq5cjTX22mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc6c302-cadf-4e10-981b-161eacc1136e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20k veri kÃ¼mesini kullanarak baÅŸlayÄ±n\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "95dvaBT14D7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hedef dizindeki tÃ¼m dosya adlarÄ±nÄ± kontrol edin\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "id": "sIP-gLEU4D4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad704f48-b2c9-413b-b1f2-660c5f92a2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2. SatÄ±r Okuma Fonksiyonu**"
      ],
      "metadata": {
        "id": "vRT64-fuj5l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google'a yaz --> \"python read text file\"\n",
        "# realpython.com/read-write-files-pyhton\n",
        "# r --> read; f--> file...dosyayÄ± oku sonra file'ye dÃ¶nÃ¼ÅŸtÃ¼r\n",
        "# readlines -->  Dosya nesnesinden kalan satÄ±rlarÄ± okur ve bunlarÄ± bir liste olarak dÃ¶ndÃ¼rÃ¼r\n",
        "\n",
        "# Bir belgenin satÄ±rlarÄ±nÄ± okumak iÃ§in iÅŸlev oluÅŸturun\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Dosya adÄ±nÄ± (bir metin dosyasÄ±) okur ve metnin satÄ±rlarÄ±nÄ± liste olarak dÃ¶ndÃ¼rÃ¼r.\n",
        "\n",
        "  ArgÃ¼manlar:\n",
        "      dosya adÄ±: okunacak hedef dosya yolunu iÃ§eren bir dize.\n",
        "\n",
        "  Return:\n",
        "      Hedef dosya adÄ±ndan satÄ±r baÅŸÄ±na bir dize iÃ§eren dizelerin listesi.\n",
        "      Ã–rneÄŸin:\n",
        "      [\"bu dosya adÄ±nÄ±n ilk satÄ±rÄ±dÄ±r\",\n",
        "       \"bu dosya adÄ±nÄ±n ikinci satÄ±rÄ±dÄ±r\",\n",
        "       \"...\"]\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "CBE60FwV4w80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bir metin dosyasÄ±nÄ±n dosya yolunu alan, aÃ§an, satÄ±rlarÄ±n her birini okuyan ve dÃ¶ndÃ¼ren get_lines() metodu\n",
        "\n",
        "# eÄŸitim dosyalarÄ±nÄ±n bulunduÄŸu satÄ±rlarÄ± okuyun\n",
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "id": "HU1nbwFB6X0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c888a7-d213-4a6d-b947-65ae327c4f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ã–rnek baÅŸlarÄ±nda ###4343 gibi sayÄ±sal kimlik biÃ§imleri var. BaÅŸlangÄ±cÄ± ayÄ±rt etmede kullanabilirsin.\n",
        "\n",
        "EÄŸitim metin dosyasÄ±ndaki satÄ±rlarÄ± okumak, farklÄ± Ã¶rnekler iÃ§eren dizelerin bir listesiyle sonuÃ§lanÄ±r, bir Ã¶rnekteki cÃ¼mleler ve cÃ¼mlenin Ã¶zette oynadÄ±ÄŸÄ± roldÃ¼r.\n",
        "\n",
        "Her cÃ¼mlenin rolÃ¼, bir sekme (\\t) ile ayrÄ±lmÄ±ÅŸ her satÄ±rÄ±n baÅŸÄ±nda Ã¶n eklenir ve her cÃ¼mle yeni bir satÄ±rla (\\n) biter.\n",
        "\n",
        "FarklÄ± Ã¶zetler kimlikleri (### ile baÅŸlayan satÄ±rlar) ve yeni satÄ±rlar (\\n) ile ayrÄ±lÄ±r.\n",
        "\n",
        "Bunu bilerek, Ã¶rneklerimizi gelecekteki makine Ã¶ÄŸrenimi modelimize eÄŸitim verileri olarak aktarmaya hazÄ±r hale getirmek iÃ§in yapmamÄ±z gereken birkaÃ§ adÄ±m var gibi gÃ¶rÃ¼nÃ¼yor.\n",
        "\n",
        "AÅŸaÄŸÄ±daki adÄ±mlarÄ± gerÃ§ekleÅŸtirmek iÃ§in bir iÅŸlev yazalÄ±m:\n",
        "\n",
        "- Ã–rneklerden oluÅŸan bir hedef dosya alÄ±n.\n",
        "- Hedef dosyadaki satÄ±rlarÄ± okuyun.\n",
        "- Hedef dosyadaki her satÄ±r iÃ§in:\n",
        "  - SatÄ±r ### ile baÅŸlÄ±yorsa, bunu soyut kimlik ve yeni bir Ã¶zetin baÅŸlangÄ±cÄ± olarak iÅŸaretleyin.\n",
        "    - Bir Ã¶rnekteki satÄ±r sayÄ±sÄ±nÄ±n sayÄ±sÄ±nÄ± koruyun.\n",
        "  - SatÄ±r \\n ile baÅŸlÄ±yorsa, bunu soyut bir Ã¶rneÄŸin sonu olarak iÅŸaretleyin.\n",
        "    - Bir Ã¶rnekteki toplam satÄ±rlarÄ±n sayÄ±sÄ±nÄ± koruyun.\n",
        "  - \\t'den Ã¶nceki metni satÄ±rÄ±n etiketi olarak kaydedin.\n",
        "  - \\t'den sonraki metni satÄ±rÄ±n metni olarak kaydedin.\n",
        "- Hedef metin dosyasÄ±ndaki tÃ¼m satÄ±rlarÄ± anahtar/deÄŸer Ã§iftlerini iÃ§eren sÃ¶zlÃ¼klerin bir listesi olarak dÃ¶ndÃ¼rÃ¼n:\n",
        "  - \"Line_number\" - Ã¶zetteki satÄ±rÄ±n konumu (Ã¶rn. 3).\n",
        "  - \"Hedef\" - Ã§izginin soyuttaki rolÃ¼ (Ã¶rn. AMAÃ‡).\n",
        "  - \"Metin\" - soyuttaki satÄ±rÄ±n metni.\n",
        "  - \"Total_lines\" - soyut bir Ã¶rnekteki toplam satÄ±r (Ã¶rn. 14).\n",
        "- Ã–zet kimlikleri ve yeni satÄ±rlar, dÃ¶ndÃ¼rÃ¼len Ã¶nceden iÅŸlenmiÅŸ verilerden atlanmalÄ±dÄ±r.\n",
        "\n",
        "Ã–rnek, Ã¶nceden iÅŸlenmiÅŸ numune dÃ¶ndÃ¼rdÃ¼ (Ã¶zetten tek bir satÄ±r):\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis.',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "  ```"
      ],
      "metadata": {
        "id": "rYAu1wbC64_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3. Veriyi Ã–n Ä°ÅŸleyecek Fonksiyon YazÄ±mÄ±**"
      ],
      "metadata": {
        "id": "aHulSXzmj5j3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Ã–zet satÄ±r verilerinin sÃ¶zlÃ¼klerinin listesini dÃ¶ndÃ¼rÃ¼r.\n",
        "\n",
        "  Dosya adÄ±nÄ± alÄ±r, iÃ§eriÄŸini okur ve her satÄ±ra gÃ¶re sÄ±ralar,\n",
        "  hedef etiketi, cÃ¼mlenin metni gibi ÅŸeyleri Ã§Ä±karmak,\n",
        "  gÃ¼ncel Ã¶zette kaÃ§ cÃ¼mle var ve cÃ¼mle numarasÄ± kaÃ§\n",
        "  hedef hattÄ±dÄ±r.\n",
        "\n",
        "  ArgÃ¼manlar:\n",
        "      dosya adÄ±: satÄ±r verilerini okumak ve Ã§Ä±karmak iÃ§in hedef metin dosyasÄ±nÄ±n bir dizesi\n",
        "      itibaren.\n",
        "\n",
        "  Return:\n",
        "      Her biri Ã¶zetten bir satÄ±r iÃ§eren sÃ¶zlÃ¼klerin listesi,\n",
        "      satÄ±r etiketi, Ã¶zetteki satÄ±r konumu ve toplam sayÄ±\n",
        "      Ã–zetteki satÄ±rlarÄ±n nereden geldiÄŸi. Ã–rneÄŸin:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # dosya adÄ±ndan tÃ¼m satÄ±rlarÄ± al\n",
        "  abstract_lines = \"\" # boÅŸ bir Ã¶zet oluÅŸtur\n",
        "  abstract_samples = [] # boÅŸ bir Ã¶zet listesi oluÅŸtur\n",
        "\n",
        "  # Hedef dosyadaki her satÄ±rda dÃ¶ngÃ¼ yapÄ±n\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # satÄ±rÄ±n kimlik satÄ±rÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol edin\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # Ã¶zet dizeyi sÄ±fÄ±rla\n",
        "    elif line.isspace(): # satÄ±rÄ±n yeni bir satÄ±r olup olmadÄ±ÄŸÄ±nÄ± kontrol edin\n",
        "      abstract_line_split = abstract_lines.splitlines() # Ã–zeti ayrÄ± satÄ±rlara bÃ¶lme\n",
        "\n",
        "      # Her satÄ±rÄ± Ã¶zet olarak yineleyin ve aynÄ± anda sayÄ±n\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # satÄ±rdaki verileri depolamak iÃ§in boÅŸ dict oluÅŸtur\n",
        "        target_text_split = abstract_line.split(\"\\t\") # hedef etiketi metinden ayÄ±r\n",
        "        line_data[\"target\"] = target_text_split[0] # hedef etiketi al\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # hedef metni alÄ±n ve indirin\n",
        "        line_data[\"line_number\"] = abstract_line_number # Ã¶zette Ã§izgi hangi sayÄ± doÄŸrusunda gÃ¶rÃ¼nÃ¼yor?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # Ã¶zette toplam kaÃ§ satÄ±r var? (0'dan baÅŸlayÄ±n)\n",
        "        abstract_samples.append(line_data) # Ã¶zet Ã¶rnekler listesine satÄ±r verileri ekleme\n",
        "\n",
        "    else: # YukarÄ±daki koÅŸullar yerine getirilmezse satÄ±r etiketli bir cÃ¼mle iÃ§erir\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "lA__qdJuRg8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def preprocess_text_with_line_numbers(filename):\n",
        "```\n",
        "Bu satÄ±rda, fonksiyonun adÄ± ve parametresi belirleniyor. `filename` parametresi, iÅŸlenecek dosyanÄ±n adÄ±nÄ± alÄ±r.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "input_lines = get_lines(filename)\n",
        "abstract_lines = \"\"\n",
        "abstract_samples = []\n",
        "```\n",
        "- `get_lines(filename)`: Bu fonksiyon, belirtilen dosyanÄ±n iÃ§eriÄŸini satÄ±r satÄ±r okur ve her satÄ±rÄ± bir liste halinde dÃ¶ndÃ¼rÃ¼r.\n",
        "- `abstract_lines`: Bu deÄŸiÅŸken, her bir Ã¶zetin metnini geÃ§ici olarak tutacak bir string deÄŸiÅŸkendir. BaÅŸlangÄ±Ã§ta boÅŸ olarak tanÄ±mlanÄ±r.\n",
        "- `abstract_samples`: Bu deÄŸiÅŸken, Ã¶zetin her bir satÄ±rÄ±nÄ± ve ilgili bilgileri iÃ§eren sÃ¶zlÃ¼klerin listesi olacak ÅŸekilde tanÄ±mlanÄ±r.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "for line in input_lines:\n",
        "```\n",
        "Bu dÃ¶ngÃ¼, dosyanÄ±n her bir satÄ±rÄ± Ã¼zerinde iÅŸlem yapacak ÅŸekilde baÅŸlar.\n",
        "\n",
        "```python\n",
        "if line.startswith(\"###\"):\n",
        "    abstract_id = line\n",
        "    abstract_lines = \"\"\n",
        "```\n",
        "- EÄŸer satÄ±r, \"###\" ile baÅŸlÄ±yorsa (yani bir kimlik satÄ±rÄ± ise), bu satÄ±rda genellikle bir Ã¶zetin kimliÄŸi yer alÄ±r.\n",
        "- `abstract_id = line`: Bu satÄ±rdaki kimlik bilgisini alÄ±r (ancak bu Ã¶rnekte `abstract_id` sadece bir kere atanÄ±yor, ilerleyen kodda kullanÄ±lmÄ±yor).\n",
        "- `abstract_lines = \"\"`: Yeni bir Ã¶zet baÅŸladÄ±ÄŸÄ±nda, geÃ§ici Ã¶zet metni sÄ±fÄ±rlanÄ±r.\n",
        "\n",
        "```python\n",
        "elif line.isspace():\n",
        "    abstract_line_split = abstract_lines.splitlines()\n",
        "```\n",
        "- `line.isspace()`: EÄŸer satÄ±r boÅŸsa (yani sadece boÅŸluk karakteri iÃ§eriyorsa), bir Ã¶zetin bittiÄŸini ve bir sonraki Ã¶zetin baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶sterir.\n",
        "- `abstract_lines.splitlines()`: BoÅŸ satÄ±r bulunduÄŸunda, birikmiÅŸ Ã¶zet metni satÄ±rlara ayrÄ±lÄ±r.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "    line_data = {}\n",
        "    target_text_split = abstract_line.split(\"\\t\")\n",
        "    line_data[\"target\"] = target_text_split[0]\n",
        "    line_data[\"text\"] = target_text_split[1].lower()\n",
        "    line_data[\"line_number\"] = abstract_line_number\n",
        "    line_data[\"total_lines\"] = len(abstract_line_split) - 1\n",
        "    abstract_samples.append(line_data)\n",
        "```\n",
        "Bu kÄ±sÄ±m, her bir Ã¶zet satÄ±rÄ±nÄ± iÅŸler:\n",
        "- `enumerate(abstract_line_split)`: Ã–zetteki her bir satÄ±rÄ± numaralandÄ±rarak iÅŸler.\n",
        "- `line_data = {}`: Bu satÄ±rdaki verileri tutacak bir sÃ¶zlÃ¼k oluÅŸturur.\n",
        "- `target_text_split = abstract_line.split(\"\\t\")`: SatÄ±r, tab karakteri ile iki kÄ±sÄ±mdan oluÅŸtuÄŸu iÃ§in, bu karakterle metni ikiye bÃ¶ler. Birinci kÄ±sÄ±m hedef etiketi (Ã¶rneÄŸin `OBJECTIVE`), ikinci kÄ±sÄ±m ise metin kÄ±smÄ±dÄ±r (Ã¶rneÄŸin, Ã¶zet metni).\n",
        "- `line_data[\"target\"]`: Etiket kÄ±smÄ±nÄ± alÄ±r.\n",
        "- `line_data[\"text\"]`: Metin kÄ±smÄ±nÄ± alÄ±r ve kÃ¼Ã§Ã¼k harflere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (`lower()` metodu ile), bÃ¶ylece metin bÃ¼yÃ¼k-kÃ¼Ã§Ã¼k harf duyarlÄ± olmadan iÅŸlenir.\n",
        "- `line_data[\"line_number\"]`: Bu satÄ±rÄ±n Ã¶zetin iÃ§inde hangi sÄ±rada olduÄŸunu belirler.\n",
        "- `line_data[\"total_lines\"]`: Ã–zetteki toplam satÄ±r sayÄ±sÄ±nÄ± (0'dan baÅŸladÄ±ÄŸÄ± iÃ§in 1 eksik) hesaplar.\n",
        "- `abstract_samples.append(line_data)`: Her bir satÄ±rdaki bilgileri `abstract_samples` listesine ekler.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "else:\n",
        "    abstract_lines += line\n",
        "```\n",
        "- EÄŸer satÄ±r boÅŸ deÄŸilse ve \"###\" ile baÅŸlamÄ±yorsa, bu satÄ±r bir Ã¶zet satÄ±rÄ±dÄ±r. Bu durumda satÄ±r, geÃ§ici `abstract_lines` deÄŸiÅŸkenine eklenir.\n",
        "\n",
        "```python\n",
        "return abstract_samples\n",
        "```\n",
        "Fonksiyon, Ã¶zetin her satÄ±rÄ±nÄ± iÃ§eren `abstract_samples` listesini dÃ¶ndÃ¼rÃ¼r. Bu liste, her satÄ±r iÃ§in etiket, metin, satÄ±r numarasÄ± ve toplam satÄ±r sayÄ±sÄ± gibi bilgileri iÃ§eren sÃ¶zlÃ¼klerden oluÅŸur.\n",
        "\n"
      ],
      "metadata": {
        "id": "MFYsAYZ-WICP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dosyadan veri alÄ±n ve Ã¶n iÅŸleme tabi tutun\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev, doÄŸrulama kÃ¼mesinin baÅŸka bir adÄ±dÄ±r\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "id": "Rx5waGT0XgBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a227b29-ee86-439d-e412-04e05449ab74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 656 ms, sys: 109 ms, total: 764 ms\n",
            "Wall time: 819 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim verilerimizin ilk Ã¶zetini kontrol edin\n",
        "train_samples[:14]"
      ],
      "metadata": {
        "id": "KNsylqUJXf62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d41a5b7-0b5f-412f-b5c1-e4d6b5ff77f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4. Verilerin Ä°ncelenmesi**"
      ],
      "metadata": {
        "id": "kpZRFc5Kj5h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "id": "cIoJuFaFXxVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "5005c187-0884-4afa-e2d5-c19b95bbc703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ca45f98-d1d2-4424-b7d5-4582b2f07da4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ca45f98-d1d2-4424-b7d5-4582b2f07da4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ca45f98-d1d2-4424-b7d5-4582b2f07da4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim verilerindeki etiketlerin daÄŸÄ±lÄ±mÄ±\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "id": "wheVa1cuXxE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "76624ea3-0799-4b3e-a94c-2dba41068994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>METHODS</th>\n",
              "      <td>59353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULTS</th>\n",
              "      <td>57953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONCLUSIONS</th>\n",
              "      <td>27168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BACKGROUND</th>\n",
              "      <td>21727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <td>13839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ¼mle uzunluklarÄ±nÄ±n daÄŸÄ±lÄ±mÄ±\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "id": "t5mfBu5WXxBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "60da2035-b246-481b-8d7c-074cc665078d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zet metin satÄ±rlarÄ±nÄ± listelere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)\n",
        "\n",
        "# tolist() bir veri penceresi iÃ§eriÄŸini Python list formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r\n",
        "# Ã–rn. her bir satÄ±rdaki cÃ¼mleler ['This is a test.', 'Another sentence.', 'Final sentence.'] olur"
      ],
      "metadata": {
        "id": "axcIJ2K-YHQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904c54bd-e7f4-4b47-de20-84f4814b1df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim cÃ¼mlelerinin ilk 10 satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼leyin\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "id": "RgVzk9iNYHNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4127d8f8-7a77-49a6-fde4-44c1f01a4c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.5. Tek SÄ±cak KodlayÄ±cÄ± Ä°le SayÄ±sal Etiketler**"
      ],
      "metadata": {
        "id": "q_t8PsIaj5fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow'un CategoricalCrossentropy kayÄ±p iÅŸlevi, one hpt encoding etikete sahip olmalÄ±.\n",
        "\n",
        "Etiketleri sayÄ±sal olarak kodlamak iÃ§in Scikit-Learn'in OneHotEncoder ve LabelEncoder sÄ±nÄ±flarÄ±nÄ± kullanacaÄŸÄ±z.\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
        "\n",
        "AÅŸaÄŸÄ±daki kod Ã¶bekleri iÃ§in;\n",
        "\n",
        "***Sparse*** yeni versiyonda gelen bir Ã¶zellik, varsayÄ±lan true'dir. False yaptÄ±ÄŸÄ±mÄ±zda hata vermedi, True olduÄŸunda matris uzunluÄŸu belirsiz uyarÄ±sÄ± alÄ±ndÄ±.\n",
        "\n",
        "Onehotencoder iki boyutludur, doÄŸru ÅŸekilde veri olmazsa ÅŸeklini (-1,1) yap uyarÄ±sÄ± alÄ±rsÄ±n. Bu yÃ¼zden kod satÄ±rÄ±na eklendi.\n",
        "\n",
        "val_labels_one_hot  --> DoÄŸrulama hedef etiketlerimizi aynÄ± ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in yalnÄ±zca dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ yÃ¶ntemi kullanmamÄ±z gerekiyor. Yani bulunan eÄŸitim veri Ã§erÃ§evesinden etiketlerin yapÄ±sÄ±nÄ± alÄ±nÄ±r ve doÄŸrulama veri Ã§erÃ§evesini aynÄ± ÅŸekilde kodlar."
      ],
      "metadata": {
        "id": "v9f-ILAwZMXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode etiketleri\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# EÄŸitim etiketlerinin nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ kontrol edin\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "id": "23iwEA9jZ8VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea1db84-00ef-4813-c014-4696b681d7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`One-hot encoding` (ya da bir diÄŸer adÄ±yla tek-sÄ±cak kodlama), kategorik deÄŸiÅŸkenlerin sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi iÃ§in yaygÄ±n olarak kullanÄ±lan bir tekniktir. Bu teknik, modelin kategorik verileri sayÄ±sal formatta anlamasÄ±nÄ± saÄŸlamak iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "`One-hot encoding`, kategorik verileri ikili (binary) bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemidir. Bu iÅŸlem, her bir kategori iÃ§in ayrÄ± bir sÃ¼tun oluÅŸturur ve sadece o kategoriye ait olan satÄ±rda 1 deÄŸeri, diÄŸer tÃ¼m kategorilerde ise 0 deÄŸeri bulunur. Yani, her kategori iÃ§in \"1\" bir yerleÅŸtirilir, geri kalan yerler \"0\" olur.\n",
        "\n",
        "Ã–rneÄŸin, bir etiket sÃ¼tununda aÅŸaÄŸÄ±daki kategoriler varsa:\n",
        "```\n",
        "[\"cat\", \"dog\", \"fish\", \"dog\", \"cat\"]\n",
        "```\n",
        "\n",
        "Bu, `One-hot encoding` uygulandÄ±ktan sonra ÅŸÃ¶yle bir yapÄ±ya dÃ¶nÃ¼ÅŸÃ¼r:\n",
        "```\n",
        "cat   -> [1, 0, 0]\n",
        "dog   -> [0, 1, 0]\n",
        "fish  -> [0, 0, 1]\n",
        "dog   -> [0, 1, 0]\n",
        "cat   -> [1, 0, 0]\n",
        "```\n",
        "\n",
        "Her kategori iÃ§in bir sÃ¼tun eklenir (Ã¶rneÄŸin, \"cat\", \"dog\", \"fish\") ve her satÄ±rda bu kategorilerden birine 1 deÄŸeri atanÄ±r, diÄŸerleri 0 olur.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "```\n",
        "\n",
        "1. **`OneHotEncoder`**: `sklearn.preprocessing` modÃ¼lÃ¼nden `OneHotEncoder` sÄ±nÄ±fÄ±nÄ± iÃ§eri aktarÄ±yoruz. Bu sÄ±nÄ±f, kategorik verileri one-hot encoding formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "   - **`sparse=False`**: Bu parametre, dÃ¶nÃ¼ÅŸÃ¼mÃ¼n **sparse matrix** (seyrek matris) yerine normal bir numpy dizisi (dense array) formatÄ±nda yapÄ±lmasÄ±nÄ± saÄŸlar. Sparse matrisler bellek tasarrufu saÄŸlasa da, burada genellikle dense (yoÄŸun) diziler tercih edilir.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "```\n",
        "\n",
        "2. **`fit_transform` ve `transform`**:\n",
        "   - **`fit_transform`**: Bu metod, eÄŸitim verisinde (train) `OneHotEncoder`'Ä± uygular ve aynÄ± zamanda bu verilerle yeni kodlamayÄ± Ã¶ÄŸrenir. `train_df[\"target\"]` etiketlerini one-hot encoding formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "   - **`transform`**: Bu metod, eÄŸitim verisiyle Ã¶ÄŸrenilen kodlamayÄ± kullanarak, doÄŸrulama (val) ve test (test) etiketlerine one-hot encoding uygular.\n",
        "\n",
        "3. **`to_numpy().reshape(-1, 1)`**:\n",
        "   - `train_df[\"target\"]`: Bu, `train_df` DataFrame'inin \"target\" adlÄ± etiket sÃ¼tununu alÄ±r.\n",
        "   - `.to_numpy()`: Pandas Series'i numpy dizisine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "   - `.reshape(-1, 1)`: Bu iÅŸlem, veriyi iki boyutlu bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (Ã¶rneÄŸin, 2D ÅŸekli `(n, 1)` yapar, burada `n` satÄ±r sayÄ±sÄ±nÄ± temsil eder). `OneHotEncoder` sadece 2D verilerle Ã§alÄ±ÅŸÄ±r, bu yÃ¼zden bu dÃ¶nÃ¼ÅŸÃ¼m gereklidir.\n",
        "\n",
        "---\n",
        "\n",
        "**EÄŸitim Etiketlerinin GÃ¶rÃ¼nÃ¼mÃ¼**\n",
        "\n",
        "```python\n",
        "train_labels_one_hot\n",
        "```\n",
        "Bu satÄ±r, eÄŸitim etiketlerinin one-hot encoding uygulanmÄ±ÅŸ halini gÃ¶sterir. Ã–rneÄŸin, eÄŸer `train_df[\"target\"]` 3 farklÄ± kategori iÃ§eriyorsa (Ã¶rneÄŸin, `[\"cat\", \"dog\", \"fish\"]`), `train_labels_one_hot` ÅŸu ÅŸekilde bir numpy array olabilir:\n",
        "\n",
        "```python\n",
        "array([[1., 0., 0.],  # cat\n",
        "       [0., 1., 0.],  # dog\n",
        "       [0., 0., 1.]]) # fish\n",
        "```\n",
        "\n",
        "Her satÄ±r, orijinal etiketin one-hot encoding karÅŸÄ±lÄ±ÄŸÄ±dÄ±r.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BQoKCcgQa5s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Etiketleri (\"hedef\" sÃ¼tunlar) Ã§Ä±karÄ±n ve bunlarÄ± tam sayÄ±lara kodlayÄ±n\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# EÄŸitim etiketlerinin nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ kontrol edin\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "id": "IrtErYtnZ8R0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d094a930-faa6-4422-8273-e59e1444e293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Label Encoding` (Etiket Kodlama), kategorik verilerin sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesinin bir baÅŸka yaygÄ±n yoludur. Bu, kategorik etiketlerin her birini tek bir sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r. Bu iÅŸlem, **sÄ±nÄ±flandÄ±rma problemlerinde** modelin sayÄ±sal verileri anlamasÄ± iÃ§in gereklidir.\n",
        "\n",
        "`Label Encoding`, her kategoriyi bir sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Ã–rneÄŸin, \"cat\", \"dog\", \"fish\" gibi etiketler sÄ±rasÄ±yla 0, 1, 2 gibi sayÄ±larla deÄŸiÅŸtirilir.\n",
        "\n",
        "Bu iÅŸlem genellikle **etiketlerin sÄ±ralÄ± olduÄŸu** durumlarda kullanÄ±lÄ±r. Yani, etiketler arasÄ±nda bir sÄ±ralama veya hiyerarÅŸi varsa, `Label Encoding` mantÄ±klÄ± olabilir. Ancak, sÄ±rasÄ±z etiketlerde de kullanÄ±labilir, ancak bu durumda sÄ±ralamanÄ±n modelin performansÄ±nÄ± etkilememesi iÃ§in dikkatli olunmasÄ± gerekir.\n",
        "\n",
        "Ã–rnek:\n",
        "- \"cat\" -> 0\n",
        "- \"dog\" -> 1\n",
        "- \"fish\" -> 2\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "```\n",
        "\n",
        "1. **`LabelEncoder`**: Bu sÄ±nÄ±f, **kategorik etiketleri** sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r. `LabelEncoder`, her farklÄ± kategoriyi (etiketi) bir sayÄ± ile eÅŸler.\n",
        "\n",
        "```python\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "```\n",
        "\n",
        "2. **`fit_transform`**:\n",
        "   - **`fit_transform`**: Bu metot, `train_df[\"target\"]` sÃ¼tunundaki tÃ¼m etiketleri (kategorik veriler) Ã¶ÄŸrenir (fit) ve her etiketi bir sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (transform).\n",
        "   - `train_df[\"target\"].to_numpy()`: Bu, `train_df` DataFrame'inin `target` adlÄ± sÃ¼tununu bir numpy dizisine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. `LabelEncoder`, numpy dizileri ile Ã§alÄ±ÅŸÄ±r, bu yÃ¼zden verinin bu formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi gereklidir.\n",
        "   - SonuÃ§ta, her etiketin sayÄ±sal karÅŸÄ±lÄ±ÄŸÄ± olan bir numpy dizisi elde edilir.\n",
        "\n",
        "```python\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "```\n",
        "\n",
        "3. **`transform`**:\n",
        "   - **`transform`**: Bu metod, eÄŸitim verisiyle (`fit`) Ã¶ÄŸrenilen kodlamayÄ± kullanarak **doÄŸrulama (val)** ve **test (test)** setlerindeki etiketleri sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "   - Burada Ã¶nemli olan, `fit_transform` sadece eÄŸitim verisinde yapÄ±lÄ±rken, doÄŸrulama ve test verisinde sadece `transform` kullanÄ±lÄ±r. Bu, modelin **gerÃ§ek test verisi**yle karÅŸÄ±laÅŸmadan Ã¶nce Ã¶ÄŸrenme iÅŸleminin bitmesini saÄŸlar.\n",
        "\n",
        "---\n",
        "\n",
        " `train_labels_encoded` NasÄ±l GÃ¶rÃ¼nÃ¼r?\n",
        "\n",
        "`train_labels_encoded` dizisi, `train_df[\"target\"]` etiketlerinin sayÄ±sal karÅŸÄ±lÄ±klarÄ±nÄ± iÃ§erir. Ã–rneÄŸin, eÄŸer `train_df[\"target\"]` ÅŸu etiketleri iÃ§eriyorsa:\n",
        "\n",
        "```\n",
        "[\"cat\", \"dog\", \"fish\", \"dog\", \"cat\"]\n",
        "```\n",
        "\n",
        "Ve `LabelEncoder` bunlarÄ± ÅŸu ÅŸekilde sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼rse:\n",
        "```\n",
        "cat -> 0\n",
        "dog -> 1\n",
        "fish -> 2\n",
        "```\n",
        "\n",
        "O zaman `train_labels_encoded` ÅŸu ÅŸekilde olur:\n",
        "\n",
        "```python\n",
        "array([0, 1, 2, 1, 0])\n",
        "```\n",
        "\n",
        "Burada her etiketin sayÄ±sal karÅŸÄ±lÄ±ÄŸÄ± gÃ¶sterilmektedir.\n",
        "\n",
        "---\n",
        "\n",
        "`Label Encoding` Ã§eÅŸitli sebeplerle kullanÄ±lÄ±r:\n",
        "\n",
        "1. **Makine Ã–ÄŸrenmesi Modellerinin SayÄ±sal Veri Ä°htiyacÄ±**: Ã‡oÄŸu makine Ã¶ÄŸrenmesi algoritmasÄ± (Ã¶zellikle doÄŸrusal modeller ve karar aÄŸaÃ§larÄ±) kategorik verileri doÄŸrudan iÅŸleyemez. Bu nedenle, kategorik etiketlerin sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi gerekir.\n",
        "\n",
        "2. **Kategorik DeÄŸiÅŸkenlerin KodlanmasÄ±**: EÄŸer verinizde kategorik etiketler varsa, bunlarÄ±n sayÄ±sal bir forma dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi gereklidir. `LabelEncoder`, her farklÄ± kategoriyi benzersiz bir sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "\n",
        "3. **SÄ±ralÄ± Veriler Ä°Ã§in**: EÄŸer etiketler sÄ±ralÄ± ise (Ã¶rneÄŸin, dÃ¼ÅŸÃ¼k, orta, yÃ¼ksek gibi), `Label Encoding` kullanmak anlamlÄ±dÄ±r Ã§Ã¼nkÃ¼ her kategoriye bir sÄ±ra numarasÄ± atar. Ã–rneÄŸin, bir mÃ¼ÅŸteri memnuniyetini 1, 2, 3 olarak kodlamak uygun olabilir.\n",
        "\n",
        "4. **Bellek ve Hesaplama VerimliliÄŸi**: `One-hot encoding`'de her kategori iÃ§in ayrÄ± bir sÃ¼tun oluÅŸturulurken, `Label Encoding` sadece tek bir sÃ¼tun kullanÄ±r. Bu, veri setinin boyutunu kÃ¼Ã§Ã¼ltÃ¼r ve bellek kullanÄ±mÄ± aÃ§Ä±sÄ±ndan daha verimli olabilir. Ancak, `Label Encoding` bazen etiketler arasÄ±ndaki iliÅŸkiyi yanlÄ±ÅŸ anlamaya yol aÃ§abilir.\n",
        "\n",
        "---\n",
        "\n",
        " `Label Encoding` ve `One-hot Encoding` FarkÄ±:\n",
        "\n",
        "- **`Label Encoding`**: Her kategoriyi bir sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Genellikle sÄ±ralÄ± verilerde kullanÄ±lÄ±r ve kategoriler arasÄ±nda gizli sÄ±ralama iliÅŸkileri oluÅŸturabilir.\n",
        "  \n",
        "  Ã–rnek:\n",
        "  ```\n",
        "  [\"cat\", \"dog\", \"fish\"]\n",
        "  --> [0, 1, 2]\n",
        "  ```\n",
        "\n",
        "- **`One-hot Encoding`**: Her kategoriyi ikili vektÃ¶rler ile temsil eder. Kategoriler arasÄ±ndaki iliÅŸkiyi temsil etmez ve her kategori baÄŸÄ±msÄ±z olarak iÅŸlenir.\n",
        "  \n",
        "  Ã–rnek:\n",
        "  ```\n",
        "  [\"cat\", \"dog\", \"fish\"]\n",
        "  --> [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "  ```"
      ],
      "metadata": {
        "id": "R4kbyMxmblct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelEncoder Ã¶rneÄŸinden sÄ±nÄ±f adlarÄ±nÄ± ve sÄ±nÄ±f sayÄ±sÄ±nÄ± alÄ±n\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "id": "VBxAPLplZ90E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572e3d70-b8df-403f-e117-086f6e6b0ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, **LabelEncoder** tarafÄ±ndan kodlanan sÄ±nÄ±f etiketlerini ve toplam sÄ±nÄ±f sayÄ±sÄ±nÄ± almak iÃ§in kullanÄ±lÄ±r. Åimdi kodu daha ayrÄ±ntÄ±lÄ± ÅŸekilde aÃ§Ä±klayalÄ±m:\n",
        "\n",
        "```python\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names\n",
        "```\n",
        "\n",
        "1. **`label_encoder.classes_`**:\n",
        "   - **`LabelEncoder`** sÄ±nÄ±fÄ±nÄ±n `.classes_` Ã¶zelliÄŸi, etiketlerin **sayÄ±sal formda** kodlanmÄ±ÅŸ hallerini, **orijinal kategorik etiketler** olarak iÃ§erir.\n",
        "   - Bu Ã¶zellik, eÄŸitim verisi Ã¼zerinde `fit()` metodu Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ktan sonra doldurulur ve her bir sÄ±nÄ±fÄ±n (etiketin) sÄ±rasÄ±yla **sÄ±fÄ±rdan baÅŸlayarak numaralandÄ±ÄŸÄ±** sÄ±nÄ±f adlarÄ±nÄ± iÃ§erir.\n",
        "   - Ã–rneÄŸin, `LabelEncoder` ile \"cat\", \"dog\", \"fish\" etiketlerini kodladÄ±ÄŸÄ±nÄ±zda, `label_encoder.classes_` ÅŸu ÅŸekilde olur:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "\n",
        "2. **`len(label_encoder.classes_)`**:\n",
        "   - Bu ifade, **`label_encoder.classes_`**'deki Ã¶ÄŸelerin sayÄ±sÄ±nÄ± dÃ¶ndÃ¼rÃ¼r. Yani, **kaÃ§ farklÄ± sÄ±nÄ±f** olduÄŸunu verir.\n",
        "   - Ã–rneÄŸin, eÄŸer `classes_` ÅŸÃ¶yleyse:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "     Burada 3 sÄ±nÄ±f olduÄŸu iÃ§in, `num_classes` deÄŸeri `3` olacaktÄ±r.\n",
        "\n",
        "3. **`class_names = label_encoder.classes_`**:\n",
        "   - Bu satÄ±r, **sÄ±nÄ±f adlarÄ±nÄ±** (`classes_`) bir deÄŸiÅŸkene atar. Yani, etiketlerin orijinal hallerini `class_names` deÄŸiÅŸkenine kaydeder.\n",
        "   - EÄŸer `classes_` array'Ä± ÅŸu ÅŸekildeyse:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "     O zaman `class_names` ÅŸu deÄŸeri alÄ±r:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "\n",
        "4. **`num_classes, class_names`**:\n",
        "   - Son olarak, bu iki deÄŸeri dÃ¶ndÃ¼rÃ¼r:\n",
        "     - `num_classes`: Toplam sÄ±nÄ±f sayÄ±sÄ±nÄ± verir.\n",
        "     - `class_names`: Etiketlerin orijinal, kategorik isimlerini verir.\n",
        "\n",
        "   Bu kodun Ã§Ä±ktÄ±sÄ± ÅŸu ÅŸekilde olur:\n",
        "\n",
        "   ```python\n",
        "   num_classes = 3\n",
        "   class_names = ['cat', 'dog', 'fish']\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "### Ã–rnek:\n",
        "\n",
        "VarsayalÄ±m ki etiketleriniz ÅŸu ÅŸekilde:\n",
        "```\n",
        "[\"cat\", \"dog\", \"fish\"]\n",
        "```\n",
        "\n",
        "`LabelEncoder` bunlarÄ± sÄ±rasÄ±yla ÅŸu ÅŸekilde kodlar:\n",
        "```\n",
        "0 -> cat\n",
        "1 -> dog\n",
        "2 -> fish\n",
        "```\n",
        "\n",
        "Kod Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda:\n",
        "- `num_classes` deÄŸeri `3` olur (Ã§Ã¼nkÃ¼ Ã¼Ã§ farklÄ± sÄ±nÄ±f var).\n",
        "- `class_names` deÄŸeri ÅŸu ÅŸekilde olur:\n",
        "  ```python\n",
        "  array(['cat', 'dog', 'fish'])\n",
        "  ```\n",
        "\n",
        "Bu sayede, modelin tahminlerinin geri dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi ve anlaÅŸÄ±labilir hale getirilmesi kolaylaÅŸÄ±r."
      ],
      "metadata": {
        "id": "GjGhG3EzcL1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Modelleme**"
      ],
      "metadata": {
        "id": "fLg5Opx7j5di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medikal Ã§alÄ±ÅŸmasÄ±nÄ±n kaynaÄŸÄ± --> https://arxiv.org/pdf/1612.05251"
      ],
      "metadata": {
        "id": "FSsiIcfHajv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1. Model 0 Temel Model YazÄ±mÄ± ve DeÄŸerlendirilmesi**"
      ],
      "metadata": {
        "id": "do7rBdEbj5ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ä°lk modelimiz, Scikit-Learn'in makine Ã¶ÄŸrenimi haritasÄ± tarafÄ±ndan Ã¶nerildiÄŸi gibi bir TF-IDF Multinomial Naive Bayes modelidir. https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "\n",
        "Bunu oluÅŸturmak iÃ§in, TF-IDF (terim frekansÄ±-ters belge frekansÄ±) algoritmasÄ±nÄ± kullanarak soyut cÃ¼mlelerimizi sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in TfidfVectorizer sÄ±nÄ±fÄ±nÄ± kullanan bir Scikit-Learn Pipeline oluÅŸturacaÄŸÄ±z ve ardÄ±ndan MultinomialNB agloritm'i kullanarak cÃ¼mlelerimizi sÄ±nÄ±flandÄ±rmayÄ± Ã¶ÄŸreneceÄŸiz.\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
      ],
      "metadata": {
        "id": "909wi9kJcY_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Boru hattÄ± oluÅŸtur\n",
        "model_0 = Pipeline([\n",
        "  (\"tf-idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# EÄŸitim verilerini boru hattÄ±na uydur\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded);"
      ],
      "metadata": {
        "id": "jkUJxnNf6qS6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "81c8d0a0-4949-46f6-df3a-3101829fd348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.05 s, sys: 39.5 ms, total: 3.09 s\n",
            "Wall time: 3.1 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DeÄŸerlerinde verileri Ã¼zerindeki bu modeli deÄŸerlendir\n",
        "model_0.score(\n",
        "    X = val_sentences,\n",
        "    y = val_labels_encoded\n",
        ")"
      ],
      "metadata": {
        "id": "mXAk9C2l8Dbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c28102-1de0-4f6a-bc77-3ee31ed83ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminler yap\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "id": "Lhf43dqp8HYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92706482-b3f4-4e0a-c621-80dd25f314e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, 2, 2, 2, 2, 2, 4, 4, 0, 4, 1, 1, 2, 2, 4, 1, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`from sklearn.feature_extraction.text import TfidfVectorizer`\n",
        "- **TfidfVectorizer**: Bu, metin verilerini sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼ren bir vektÃ¶rleÅŸtirici (vectorizer) sÄ±nÄ±fÄ±dÄ±r. \"TF-IDF\" (Term Frequency-Inverse Document Frequency) yÃ¶ntemi, her terimin Ã¶nemini hesaplarken, terimin bir belgedeki sÄ±klÄ±ÄŸÄ±nÄ± (TF) ve tÃ¼m koleksiyon iÃ§indeki nadirliÄŸini (IDF) gÃ¶z Ã¶nÃ¼nde bulundurur. Bu sayede Ã¶nemli ve nadir kelimelere yÃ¼ksek aÄŸÄ±rlÄ±k verilir.\n",
        "- **AmaÃ§**: DoÄŸal dildeki metni makine Ã¶ÄŸrenimi modelinin anlayacaÄŸÄ± sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek.\n",
        "\n",
        "`from sklearn.naive_bayes import MultinomialNB`\n",
        "- **MultinomialNB**: Bu, Naive Bayes sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±nÄ±n bir Ã§eÅŸididir. Ã–zellikle metin verileri gibi Ã§ok terimli (multinomial) verilerle Ã§alÄ±ÅŸmak iÃ§in uygundur. Her bir belgeyi, o belgenin hangi sÄ±nÄ±fa ait olduÄŸunu tahmin etmek iÃ§in kullanÄ±r.\n",
        "- **AmaÃ§**: Metin verilerini belirli bir kategoriye (sÄ±nÄ±fa) sÄ±nÄ±flandÄ±rmak. Ã–rneÄŸin, bir e-postanÄ±n spam olup olmadÄ±ÄŸÄ±nÄ± tahmin etmek.\n",
        "\n",
        "`from sklearn.pipeline import Pipeline`\n",
        "- **Pipeline**: Bu, bir dizi adÄ±mÄ± sÄ±rasÄ±yla birleÅŸtiren bir sÄ±nÄ±ftÄ±r. Bir boru hattÄ± (pipeline), veriyi iÅŸlemek iÃ§in gereken tÃ¼m adÄ±mlarÄ± (veya iÅŸlemleri) sÄ±ralÄ± ÅŸekilde organize eder. Yani, bu yapÄ±yÄ± kullanarak, veri hazÄ±rlÄ±k aÅŸamasÄ±ndan modelin eÄŸitilmesine kadar her ÅŸeyi bir arada tutabilirsiniz.\n",
        "- **AmaÃ§**: Veriyi ve modeli dÃ¼zenli bir ÅŸekilde iÅŸlemeyi saÄŸlayan bir \"boru hattÄ±\" oluÅŸturmak.\n",
        "\n",
        "`model_0 = Pipeline([(\"tf-idf\", TfidfVectorizer()), (\"clf\", MultinomialNB())])`\n",
        "- **Bu satÄ±rda**:\n",
        "  - Bir **pipeline** oluÅŸturuluyor. Bu boru hattÄ±, iki adÄ±m iÃ§eriyor:\n",
        "    1. **\"tf-idf\"**: Ä°lk adÄ±mda metin verilerini, `TfidfVectorizer` kullanarak sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek.\n",
        "    2. **\"clf\"**: Ä°kinci adÄ±mda, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ veriyi `MultinomialNB` sÄ±nÄ±flandÄ±rÄ±cÄ±sÄ±na vererek sÄ±nÄ±flandÄ±rmak.\n",
        "- **AmaÃ§**: Veriyi sayÄ±sal hale getirdikten sonra, bu sayÄ±sal veriyi kullanarak bir sÄ±nÄ±flandÄ±rma yapmak.\n",
        "\n",
        "`model_0.fit(X=train_sentences, y=train_labels_encoded)`\n",
        "- **fit**: Modeli eÄŸitim verileriyle (X) ve etiketleriyle (y) eÄŸitir. Bu adÄ±mda:\n",
        "  - `X` (train_sentences): EÄŸitim verisi, yani metinleri iÃ§eren bir liste veya dizi.\n",
        "  - `y` (train_labels_encoded): EÄŸitim verilerine karÅŸÄ±lÄ±k gelen etiketler. Bu, her bir metne hangi sÄ±nÄ±fÄ±n (etiketin) ait olduÄŸunu gÃ¶sterir. Ã–rneÄŸin, bir metnin \"spam\" veya \"ham\" (spam deÄŸil) olduÄŸunu belirten etiketler olabilir.\n",
        "  \n",
        "- **AmaÃ§**: Model, eÄŸitim verilerini kullanarak metinlerin hangi sÄ±nÄ±fa ait olduÄŸunu Ã¶ÄŸrenir. Ä°lk adÄ±mda metinleri sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, sonra ikinci adÄ±mda bu sayÄ±sal veriyi sÄ±nÄ±flandÄ±rÄ±cÄ±ya verir ve Ã¶ÄŸrenme iÅŸlemi baÅŸlar."
      ],
      "metadata": {
        "id": "6ivSrWnk-fpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2. YardÄ±mcÄ± Fonksiyonlar DosyasÄ±**"
      ],
      "metadata": {
        "id": "CYo03qcGj5XY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temel modelin tahminlerini deÄŸerlendirmek iÃ§in Ã¶nceden hazÄ±rlanmÄ±ÅŸ helper_functions.py komut dosyasÄ±nÄ± iÃ§eri aktaracaÄŸÄ±z. Bu dosya iÃ§erisinde calculate_results() iÅŸlevi ile deÄŸerlendirme yaparÄ±z.\n",
        "\n",
        "Daha spesifik olarak calculate_results() iÅŸlevi aÅŸaÄŸÄ±dakileri elde etmemize yardÄ±mcÄ± olacaktÄ±r:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 Score"
      ],
      "metadata": {
        "id": "cwtnvfmJ8dy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YardÄ±mcÄ± iÅŸlevler komut dosyasÄ±nÄ± indirin\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "iFnqZ32S9H7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77501a1a-6698-4203-a31e-e439ca36e638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-02 19:30:13--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: â€˜helper_functions.py.1â€™\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-02 19:30:13 (14.7 MB/s) - â€˜helper_functions.py.1â€™ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Ä°Ã§e aktarÄ±lmÄ±ÅŸ olan yardÄ±mcÄ± fonksiyonlarÄ±n detaylarÄ±\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "\n",
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's\n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n",
        "\n",
        "# Make a function to predict on images and plot them (works with multi-class)\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "\n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "# Create function to unzip a zipfile into current working directory\n",
        "# (since we're going to be downloading and unzipping a few files)\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "7_-HlRGI9H4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate_results'u yardÄ±mcÄ± fonksiyonlardan iÃ§eri aktarma\n",
        "from helper_functions import calculate_results\n",
        "\n",
        "# Temel modelin sonuÃ§larÄ± nedir?\n",
        "baseline_results = calculate_results(\n",
        "    y_true = val_labels_encoded,\n",
        "    y_pred = baseline_preds\n",
        ")\n",
        "\n",
        "baseline_results"
      ],
      "metadata": {
        "id": "zoFV1fOY9fcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f133b1f2-8ebc-4da8-c7da-1be3342702dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3. Derin Modelleme Ä°Ã§in Veri HazÄ±rlÄ±ÄŸÄ±**"
      ],
      "metadata": {
        "id": "5u6NpAHBj5U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etiketleri sayÄ±sal formatta hazÄ±rlamÄ±ÅŸtÄ±k, ÅŸimdi metinleri sayÄ±sal biÃ§ime dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in Ã§alÄ±ÅŸma yapmalÄ±yÄ±z, metin vektÃ¶rleÅŸtirme. Her bir token bir sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve bu birleÅŸtirilmiÅŸ kelimelere dayalÄ± bir embeddings oluÅŸturulur. Denemek ve geliÅŸtirmek iÃ§in Ã§alÄ±ÅŸma temelimiz var.\n",
        "\n",
        "Ancak daha derin modeller oluÅŸturmaya baÅŸlamadan Ã¶nce, vektÃ¶rleÅŸtirme ve katmanlarÄ± gÃ¶mme oluÅŸturmalÄ±yÄ±z.\n",
        "\n",
        "VektÃ¶rleÅŸtirme katmanÄ± metnimizi sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼recek ve gÃ¶mme katmanÄ± bu sayÄ±lar arasÄ±ndaki iliÅŸkileri yakalayacaktÄ±r.\n",
        "\n",
        "VektÃ¶rleÅŸtirme ve gÃ¶mme katmanlarÄ±mÄ±zÄ± oluÅŸturmaya baÅŸlamak iÃ§in uygun kitaplÄ±klarÄ± (yani TensorFlow ve NumPy) iÃ§e aktarmamÄ±z gerekecek.\n",
        "\n",
        "CÃ¼mlelerimizi sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼receÄŸimiz iÃ§in, her cÃ¼mlede kaÃ§ kelime olduÄŸunu bulmak gerekir.\n",
        "\n",
        "Modelimiz cÃ¼mlelerimizden geÃ§tiÄŸinde, hepsi aynÄ± uzunlukta olduÄŸunda en iyi ÅŸekilde Ã§alÄ±ÅŸÄ±r (bu, aynÄ± boyutta tensÃ¶rlerde gruplar oluÅŸturmak iÃ§in Ã¶nemlidir).\n",
        "\n",
        "Ã–rneÄŸin, bir cÃ¼mle sekiz kelime uzunluÄŸunda ve diÄŸeri 29 kelime uzunluÄŸundaysa, sekiz kelimelik cÃ¼mleyi sÄ±fÄ±rla doldurmak istiyoruz, bÃ¶ylece 29 kelimelik cÃ¼mle ile aynÄ± uzunlukta olur."
      ],
      "metadata": {
        "id": "X2jmqEBPi8Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Q8Ow2KOvjvxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Her cÃ¼mle ortalama ne kadar uzunlukta? DaÄŸÄ±lÄ±m hakkÄ±nda bilgimiz olmalÄ±\n",
        "# Bir cÃ¼mle 4 kelime iken diÄŸeri 90 kelime de olabilir\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "\n",
        "avg_sent_len # ortalama cÃ¼mle uzunluÄŸunu dÃ¶ndÃ¼r (belirteÃ§ cinsinden)"
      ],
      "metadata": {
        "id": "nUhtDwkyjzDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fa5220-09a0-4a34-c089-f40ffa8c8c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sent_lens = [len(sentence.split()) for sentence in train_sentences]`\n",
        "- Bu satÄ±rda, eÄŸitim verisindeki her cÃ¼mle iÃ§in kelime sayÄ±sÄ± hesaplanÄ±yor.\n",
        "- `train_sentences`: Bu, eÄŸitim verisindeki cÃ¼mlelerin bir listesidir. Her bir Ã¶ÄŸe bir cÃ¼mledir.\n",
        "- `sentence.split()`: Bu, her cÃ¼mleyi boÅŸluk karakterine gÃ¶re bÃ¶ler ve cÃ¼mledeki kelimeleri bir liste olarak dÃ¶ndÃ¼rÃ¼r. Ã–rneÄŸin, `\"Bu bir test cÃ¼mlesidir.\"` cÃ¼mlesi `[\"Bu\", \"bir\", \"test\", \"cÃ¼mlesidir.\"]` olarak bÃ¶lÃ¼nÃ¼r.\n",
        "- `len(sentence.split())`: Bu, her cÃ¼mlenin kelime sayÄ±sÄ±nÄ± hesaplar. Ã–rneÄŸin, `\"Bu bir test cÃ¼mlesidir.\"` cÃ¼mlesi 4 kelime iÃ§erdiÄŸi iÃ§in `len(sentence.split())` deÄŸeri 4 olacaktÄ±r.\n",
        "- **AmaÃ§**: Her cÃ¼mlenin kelime sayÄ±sÄ±nÄ± iÃ§eren bir liste (`sent_lens`) oluÅŸturmak.\n",
        "\n",
        "`avg_sent_len = np.mean(sent_lens)`\n",
        "- **`np.mean(sent_lens)`**: NumPy kÃ¼tÃ¼phanesinin `mean` fonksiyonu, `sent_lens` listesindeki tÃ¼m cÃ¼mlelerin kelime sayÄ±larÄ±nÄ±n ortalamasÄ±nÄ± hesaplar.\n",
        "- **AmaÃ§**: CÃ¼mlelerin ortalama kelime sayÄ±sÄ±nÄ± bulmak.\n",
        "\n",
        "Ã–rnek:\n",
        "- Diyelim ki `train_sentences` ÅŸÃ¶yle:\n",
        "  ```python\n",
        "  train_sentences = [\n",
        "      \"Merhaba.\",\n",
        "      \"BugÃ¼n Ã§ok gÃ¼zel bir gÃ¼n.\",\n",
        "      \"Yapay zeka, veri biliminde Ã¶nemli bir yer tutmaktadÄ±r. Ã‡eÅŸitli alanlarda kullanÄ±lmaktadÄ±r.\"\n",
        "  ]\n",
        "  ```\n",
        "- Ä°lk cÃ¼mlede 1 kelime var, ikinci cÃ¼mlede 5 kelime var, Ã¼Ã§Ã¼ncÃ¼ cÃ¼mlede ise 10 kelime var.\n",
        "- `sent_lens` listesi: `[1, 5, 10]`\n",
        "- Ortalama cÃ¼mle uzunluÄŸu (`avg_sent_len`) hesaplanÄ±r: `(1 + 5 + 10) / 3 = 5.33` (yaklaÅŸÄ±k)\n",
        "\n",
        "SonuÃ§ olarak, ortalama cÃ¼mle uzunluÄŸu yaklaÅŸÄ±k 5.33 kelime olacaktÄ±r."
      ],
      "metadata": {
        "id": "W6Chrg2d_Y0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DaÄŸÄ±lÄ±m nasÄ±l?\n",
        "plt.hist(sent_lens, bins = 7);"
      ],
      "metadata": {
        "id": "WLQnBg9Gkf5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "b528005f-e07f-4b4a-db16-0556940e01eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CÃ¼mlelerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸunun uzunluÄŸu 0 ile 50 token arasÄ±nda gibi gÃ¶rÃ¼nÃ¼yor.\n",
        "\n",
        "CÃ¼mle uzunluklarÄ±nÄ±n %95'ini kapsayan deÄŸeri bulmak iÃ§in NumPy'nin yÃ¼zdelik dilimini kullanabiliriz.\n",
        "\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.percentile.html\n",
        "\n",
        "ğŸ¤” Soru: Neden %95?\n",
        "\n",
        "EÄŸitim setindeki cÃ¼mlelerin maksimum cÃ¼mle uzunluÄŸunu kullanabiliriz.\n",
        "\n",
        "SonuÃ§ 55 Ã§Ä±kar (aÅŸaÄŸÄ±da). BelirteÃ§ katmanÄ±mÄ±zÄ± oluÅŸturduÄŸumuzda, tÃ¼m cÃ¼mlelerimizi aynÄ± uzunlukta dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in bu deÄŸeri kullanacaÄŸÄ±z. UzunluÄŸu 55'in altÄ±nda olan cÃ¼mleler sÄ±fÄ±rlarla doldurulur ve uzunluÄŸu 55'in Ã¼zerinde olan cÃ¼mleler kesilir (55'ten sonraki kelimeler kesilir)."
      ],
      "metadata": {
        "id": "VJtKueVokt7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bir cÃ¼mlenin uzunluÄŸu, uzunluklarÄ±n %95'ini kapsÄ±yor?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "\n",
        "output_seq_len # Ã§Ä±ktÄ±mÄ±zÄ±n uzunluÄŸunu dÃ¶ndÃ¼r"
      ],
      "metadata": {
        "id": "bucDAYY4kurv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdfccad-6cc5-4ab3-cc7c-ed04695f6b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim veri setindeki maksimum cÃ¼mle uzunluÄŸu\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "id": "e1fWyaeclVLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69063ee-2f0a-407a-9250-6e938fc2d7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”‘ Not: Bir NLP sorunu iÃ§in bir metin kÃ¼lliyatÄ± ile Ã§alÄ±ÅŸÄ±rken attÄ±ÄŸÄ±mÄ±z adÄ±mlar iyi bir uygulamadÄ±r. Numunelerinizin ne kadar uzun olduÄŸunu ve bunlarÄ±n daÄŸÄ±lÄ±mÄ±nÄ±n ne olduÄŸunu bilmek istiyorsunuz. Daha fazla Ã¶rnek iÃ§in bkz. bÃ¶lÃ¼m 4 PubMed 200k RCT makalesinin Veri Analizi. https://arxiv.org/pdf/1710.06071"
      ],
      "metadata": {
        "id": "odqGm6Klm0vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4. Metin VektÃ¶rleÅŸtirme**"
      ],
      "metadata": {
        "id": "mMFoavzfj5Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metinleri sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rmeliyiz, TensorFlow'dan TextVectorization katmanÄ±nÄ± kullanmalÄ±yÄ±z.\n",
        "\n",
        "Max_tokens (veri kÃ¼memizdeki benzersiz kelimelerin sayÄ±sÄ±) ve output_sequence_length (her vektÃ¶rleÅŸtirilmiÅŸ cÃ¼mle iÃ§in istediÄŸimiz Ã§Ä±ktÄ± uzunluÄŸu) hariÃ§ tÃ¼m parametreleri varsayÄ±lan tutacaÄŸÄ±z.\n",
        "\n",
        "PubMed 200k RCT makalesinin 3.2. BÃ¶lÃ¼mÃ¼, PubMed 20k veri kÃ¼mesinin kelime boyutunu 68.000 olarak belirtir. Yani bunu max_tokens parametremiz olarak kullanacaÄŸÄ±z. https://arxiv.org/pdf/1710.06071\n",
        "\n",
        "***Tokenization ile embedding arasÄ±ndaki fark, embedding daha zengin bir temsildir. Ã–rneÄŸin embedding, eÄŸitim verilerinden geÃ§erken her kelime iÃ§in Ã¼Ã§ boyutlu bir vektÃ¶r oluÅŸturulabilir. TÃ¼m bu deÄŸerler, metnimizdeki kelimelerin modelimiz olarak birbirleriyle nasÄ±l iliÅŸkili olduÄŸunu Ã¶ÄŸrenebilir.***\n",
        "\n",
        "***Tokenization, her kelime bir int rakam olabilir, one hot encoding ile 010, 100, 001 gibi matris olabilir. Embedingste 0-1 arasÄ± rakamlardan oluÅŸan 3x3 matris oluÅŸabilir.***"
      ],
      "metadata": {
        "id": "1CPRVK8em7f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kelime daÄŸarcÄ±ÄŸÄ±mÄ±zda kaÃ§ kelime var? (dokÃ¼man 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "mYkMj8Yrofcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektÃ¶rleÅŸtirici oluÅŸtur\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens = max_tokens,       # kelime hazinesindeki kelime sayÄ±sÄ±\n",
        "    output_sequence_length = 55    # vektÃ¶rleÅŸtirilmiÅŸ dizilerin istenen Ã§Ä±ktÄ± uzunluÄŸu\n",
        ")"
      ],
      "metadata": {
        "id": "GWdGp91Sos5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Modelin eÄŸitilmesi sÄ±rasÄ±nda daha kÃ¼Ã§Ã¼k max_tokens deÄŸerleri kullanmak, iÅŸlem gÃ¼cÃ¼nÃ¼ azaltabilir ve eÄŸitim sÃ¼resini hÄ±zlandÄ±rabilir. Ancak, Ã§ok dÃ¼ÅŸÃ¼k bir max_tokens deÄŸeri, Ã¶nemli kelimelerin kaybolmasÄ±na neden olabilir.\n",
        "* YaygÄ±n olarak, max_tokens deÄŸeri 10,000 ile 50,000 arasÄ±nda bir aralÄ±kta seÃ§ilir, ancak bu sayÄ±lar veri setinizin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ne baÄŸlÄ± olarak deÄŸiÅŸebilir.\n",
        "\n",
        "`max_tokens` DeÄŸerini Belirlemek iÃ§in YÃ¶ntemler\n",
        "\n",
        "1. **Kelime FrekansÄ±na DayalÄ± SeÃ§im**\n",
        "Bir yÃ¶ntem, eÄŸitim verinizdeki kelimelerin frekansÄ±nÄ± hesaplamak ve en sÄ±k kullanÄ±lan belirli sayÄ±da kelimeyi seÃ§mektir. Ã–rneÄŸin, `max_tokens`'Ä± eÄŸitim setinizdeki en sÄ±k 10,000 kelimeye sÄ±nÄ±rlayabilirsiniz.\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import numpy as np\n",
        "\n",
        "# Verinizin kelimelerini tokenize edin\n",
        "all_words = ' '.join(train_sentences)  # TÃ¼m cÃ¼mleleri birleÅŸtir\n",
        "word_list = all_words.split()  # TÃ¼m kelimelere ayÄ±r\n",
        "\n",
        "# Kelime sÄ±klÄ±ÄŸÄ±nÄ± hesapla\n",
        "word_counts = {word: word_list.count(word) for word in set(word_list)}\n",
        "\n",
        "# Kelime sÄ±klÄ±ÄŸÄ±na gÃ¶re en sÄ±k geÃ§en 10,000 kelimeyi seÃ§\n",
        "sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "most_common_words = sorted_words[:10000]\n",
        "\n",
        "# max_tokens olarak en sÄ±k geÃ§en kelimeler sayÄ±sÄ±nÄ± belirleyebilirsiniz\n",
        "max_tokens = len(most_common_words)\n",
        "```\n",
        "\n",
        "2. **Veri Setindeki Kelimeleri Sayarak**\n",
        "Veri setindeki kelimeleri sayarak doÄŸrudan `max_tokens` deÄŸerini hesaplayabilirsiniz. Ã–rneÄŸin, toplamda kaÃ§ farklÄ± kelime olduÄŸunu bulabilir ve bunun bir yÃ¼zdesi olarak `max_tokens` belirleyebilirsiniz.\n",
        "\n",
        "```python\n",
        "from collections import Counter\n",
        "\n",
        "# TÃ¼m metni birleÅŸtir\n",
        "all_words = ' '.join(train_sentences)\n",
        "words = all_words.split()\n",
        "\n",
        "# Kelime sayÄ±sÄ±nÄ± ve farklÄ± kelimelerin sayÄ±sÄ±nÄ± hesapla\n",
        "word_counts = Counter(words)\n",
        "unique_words = len(word_counts)\n",
        "\n",
        "# `max_tokens`'Ä± veri setindeki benzersiz kelimelerin sayÄ±sÄ±na gÃ¶re belirleyebilirsiniz\n",
        "max_tokens = unique_words  # Ã–rneÄŸin tÃ¼m benzersiz kelimeler kullanÄ±labilir\n",
        "```\n",
        "\n",
        "3. **Pratik Bir YaklaÅŸÄ±m**\n",
        "EÄŸer elinizde bÃ¼yÃ¼k bir veri seti varsa ve fazla iÅŸlem gÃ¼cÃ¼ harcamak istemiyorsanÄ±z, genel bir yaklaÅŸÄ±m olarak `max_tokens`'Ä± 10,000 ile 50,000 arasÄ±nda seÃ§ebilirsiniz. Bu, Ã§oÄŸu metin sÄ±nÄ±flandÄ±rma modelinde yeterince iyi bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.\n",
        "\n",
        "```python\n",
        "# Ã–rnek olarak max_tokens deÄŸeri\n",
        "max_tokens = 10000  # veya 5000, 20000 gibi\n",
        "```"
      ],
      "metadata": {
        "id": "4vrysMFvAM1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi metin vektÃ¶rleÅŸtiriciyi eÄŸitim verilerine uyarlayalÄ±m (eÄŸitim verilerini okusun ve hangi sayÄ±nÄ±n hangi kelimeyi temsil etmesi gerektiÄŸini bulsun) ve ardÄ±ndan test edelim.\n",
        "\n",
        "Bunu test verilerindeki doÄŸrulamaya uyarlarsak, bu veri kÃ¼melerinin gÃ¶rÃ¼nmemesi amaÃ§lanmÄ±ÅŸtÄ±r. BÃ¶ylece eÄŸitim verilerine uyum saÄŸladÄ±k ve daha sonra doÄŸrulama ve test verilerimize sÄ±ÄŸdÄ±rabiliriz."
      ],
      "metadata": {
        "id": "0G4PpWq1pb5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektÃ¶rleÅŸtiricisini eÄŸitim cÃ¼mlelerine uyarlayÄ±n\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "GAQ1JD5Tp-BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektÃ¶rleÅŸtiricisini test edin\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Metin:\\n{target_sentence}\")\n",
        "print(f\"\\nMetin UzunluÄŸu: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVektÃ¶rleÅŸmiÅŸ Metin:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "metadata": {
        "id": "WJ6zlnhAp97F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15161be2-b3c6-478b-abab-8ba1ec8650c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metin:\n",
            "among accord lipid trial participants , the occurrence of extremely low hdl-c ever during study follow-up was @ % higher among those randomized to fenofibrate ( @ % fenofibrate vs. @ % placebo , p < @ ) .\n",
            "\n",
            "Metin UzunluÄŸu: 39\n",
            "\n",
            "VektÃ¶rleÅŸmiÅŸ Metin:\n",
            "[[ 116 9495  864   32   60    2 1066    4 3945  220 2784 6099   52   17\n",
            "    94   10   82  116  125   29    6 7078 7078   44   48   14    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim sÃ¶zlÃ¼ÄŸÃ¼mÃ¼zde kaÃ§ kelime var?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"SÃ¶zlÃ¼kteki kelime sayÄ±sÄ±: {len(rct_20k_text_vocab)}\"),\n",
        "print(f\"SÃ¶zlÃ¼kteki en Ã§ok tekrar eden kelime: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"SÃ¶zlÃ¼kte en az tekrar eden kelime: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "Lz_ELzw4p92Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e154565c-ae04-4f5b-cf5c-4767ce675312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SÃ¶zlÃ¼kteki kelime sayÄ±sÄ±: 64841\n",
            "SÃ¶zlÃ¼kteki en Ã§ok tekrar eden kelime: ['', '[UNK]', 'the', 'and', 'of']\n",
            "SÃ¶zlÃ¼kte en az tekrar eden kelime: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektÃ¶rleÅŸtiricimizin yapÄ±landÄ±rmasÄ±nÄ± edinin\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "id": "i0GdDHHVp9xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d691713d-cd29-44ad-c910-fdc80a6c6af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization_1',\n",
              " 'trainable': True,\n",
              " 'dtype': {'module': 'keras',\n",
              "  'class_name': 'DTypePolicy',\n",
              "  'config': {'name': 'float32'},\n",
              "  'registered_name': None},\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5. GÃ¶mme HazÄ±rlama**"
      ],
      "metadata": {
        "id": "UYpH9jrvj5Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BelirteÃ§_vektÃ¶rleÅŸtirme katmanÄ±mÄ±z, metnimizdeki kelimeleri doÄŸrudan sayÄ±larla eÅŸler. Ancak, bu mutlaka bu sayÄ±lar arasÄ±ndaki iliÅŸkileri yakalamaz.\n",
        "\n",
        "Metnimizin daha zengin bir sayÄ±sal temsilini oluÅŸturmak iÃ§in bir gÃ¶mme kullanabiliriz. https://www.tensorflow.org/text/guide/word_embeddings?hl=tr\n",
        "\n",
        "Modelimiz Ã¶ÄŸrendikÃ§e (birÃ§ok farklÄ± soyut cÃ¼mle Ã¶rneÄŸini ve etiketlerini gÃ¶zden geÃ§irerek), kÃ¼lliyatÄ±mÄ±zdaki belirteÃ§ler arasÄ±ndaki iliÅŸkileri daha iyi temsil etmek iÃ§in gÃ¶mmesini gÃ¼ncelleyecektir.\n",
        "\n",
        "TensorFlow'un GÃ¶mme katmanÄ±nÄ± kullanarak eÄŸitilebilir bir gÃ¶mme katmanÄ± oluÅŸturabiliriz.\n",
        "\n",
        "Bir kez daha, burada ilgilendiÄŸimiz ana parametreler, GÃ¶mme katmanÄ±mÄ±zÄ±n giriÅŸ ve Ã§Ä±kÄ±ÅŸlarÄ±dÄ±r.\n",
        "\n",
        "Input_dim parametresi kelime daÄŸarcÄ±ÄŸÄ±mÄ±zÄ±n boyutunu tanÄ±mlar. Ve output_dim parametresi, gÃ¶mme Ã§Ä±ktÄ±sÄ±nÄ±n boyutunu tanÄ±mlar.\n",
        "\n",
        "Bir kez oluÅŸturulduktan sonra, gÃ¶mme katmanÄ±mÄ±z text_vectorization katmanÄ±mÄ±zÄ±n tamsayÄ± Ã§Ä±ktÄ±larÄ±nÄ± girdi olarak alacak ve bunlarÄ± output_dim boyutu vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼recektir."
      ],
      "metadata": {
        "id": "lG8pzvdLrVNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Genel Notlar**\n",
        "- output dim --> 32,64, 128'in gibi 8'in katlarÄ± olmalÄ±.\n",
        "- Her ne kadar bÃ¼yÃ¼k gÃ¶mÃ¼lÃ¼rse modelin eÄŸitmesi gereken parametre sayÄ±sÄ± o kadar fazla olur.\n",
        "- mask_zero: Boolean deÄŸerdir. input_value=0. Ã–zel bir padding. RNN kullanÄ±mÄ± Ã§eÅŸitli uzunlukta giriÅŸ verileri kullanÄ±lÄ±rken elveriÅŸlidir. EÄŸer true ise modeldeki tÃ¼m subsequent katmanlar maskelenmeli. Daha verimli hesaplama iÃ§in TRUE olmalÄ±.\n",
        "- Ã‡Ä±ktÄ±yÄ± incele, Ã§ok sÄ±fÄ±r var o zaman verimli bir model (one_hot benzeri).\n",
        "- token_embeding --> Token yerleÅŸtirme katmanÄ±na herhangi bir ÅŸey aktarmadan Ã¶nce bunun sayÄ±sal biÃ§imde olmasÄ± gerekli.\n",
        "- GÃ¶mÃ¼lÃ¼ cÃ¼mle ÅŸeklinde her bir dizi uzunluÄŸunda rakamlardan 55 adet var her biri 128 vektÃ¶r uzunluÄŸunda."
      ],
      "metadata": {
        "id": "4ERZ1fBqtMPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GÃ¶mme katmanÄ± oluÅŸtur (aslÄ±nda input_dim ve output_dim yeterli, listeyi uzatadabilirsin)\n",
        "token_embed = layers.Embedding(\n",
        "    input_dim = len(rct_20k_text_vocab), # kelime uzunluÄŸu\n",
        "    output_dim = 128,                    # farklÄ± yerleÅŸtirme boyutlarÄ±, eÄŸitilecek parametrelerin bÃ¼yÃ¼k Ã¶lÃ§Ã¼de farklÄ± olmasÄ±na neden olur\n",
        "    mask_zero = True,                    # DeÄŸiÅŸken dizi uzunluklarÄ±nÄ± iÅŸlemek iÃ§in maskelemeyi kullanÄ±n (yerden tasarruf edin)\n",
        "    name = \"token_embedding\"\n",
        ")\n",
        "\n",
        "# Ã–rnek gÃ¶mmelerin gÃ¶sterimi\n",
        "print(f\"VektÃ¶rleÅŸme Ã¶ncesi cÃ¼mleler:\\n{target_sentence}\\n\")\n",
        "\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"VektÃ¶rleÅŸme sonrasÄ± cÃ¼mle (gÃ¶mme Ã¶ncesi):\\n{vectorized_sentence}\\n\")\n",
        "\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"GÃ¶mme sonrasÄ± cÃ¼mle:\\n{embedded_sentence}\\n\")\n",
        "print(f\"GÃ¶mÃ¼lmÃ¼ÅŸ cÃ¼mle ÅŸekli: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "id": "SogevH0etatn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6390db14-d741-4157-a6f3-32cf1c261911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VektÃ¶rleÅŸme Ã¶ncesi cÃ¼mleler:\n",
            "among accord lipid trial participants , the occurrence of extremely low hdl-c ever during study follow-up was @ % higher among those randomized to fenofibrate ( @ % fenofibrate vs. @ % placebo , p < @ ) .\n",
            "\n",
            "VektÃ¶rleÅŸme sonrasÄ± cÃ¼mle (gÃ¶mme Ã¶ncesi):\n",
            "[[ 116 9495  864   32   60    2 1066    4 3945  220 2784 6099   52   17\n",
            "    94   10   82  116  125   29    6 7078 7078   44   48   14    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "GÃ¶mme sonrasÄ± cÃ¼mle:\n",
            "[[[ 0.0450269   0.03514195 -0.0080569  ...  0.00595022 -0.03892398\n",
            "    0.04339631]\n",
            "  [ 0.0489152   0.03578948  0.03945035 ... -0.03081435 -0.00316496\n",
            "    0.04754409]\n",
            "  [-0.00370265  0.04541652  0.04479161 ...  0.01556161  0.02524466\n",
            "    0.00633305]\n",
            "  ...\n",
            "  [-0.02776702 -0.03965263  0.04264294 ... -0.03421847  0.01198611\n",
            "   -0.02226293]\n",
            "  [-0.02776702 -0.03965263  0.04264294 ... -0.03421847  0.01198611\n",
            "   -0.02226293]\n",
            "  [-0.02776702 -0.03965263  0.04264294 ... -0.03421847  0.01198611\n",
            "   -0.02226293]]]\n",
            "\n",
            "GÃ¶mÃ¼lmÃ¼ÅŸ cÃ¼mle ÅŸekli: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`input_dim`**:\n",
        "   - **TanÄ±m**: GÃ¶mme katmanÄ±na giren veri boyutunu belirtir. Bu, kelime veya token sayÄ±sÄ±na eÅŸittir.\n",
        "   - **Ã–zellik**: Burada `len(rct_20k_text_vocab)` deÄŸeri, kelime daÄŸarcÄ±ÄŸÄ±ndaki toplam kelime sayÄ±sÄ±nÄ± temsil eder.\n",
        "\n",
        "2. **`output_dim`**:\n",
        "   - **TanÄ±m**: GÃ¶mme vektÃ¶rlerinin boyutu. Yani, her token iÃ§in kaÃ§ boyutlu bir vektÃ¶r elde edileceÄŸini belirtir.\n",
        "   - **Ã–zellik**: Bu Ã¶rnekte, her token iÃ§in 64 boyutlu bir vektÃ¶r kullanÄ±lacaktÄ±r.\n",
        "\n",
        "3. **`name`**:\n",
        "   - **TanÄ±m**: Katmana bir isim verir. Bu genellikle modelin Ã¶zelliklerini daha okunabilir hale getirmek iÃ§in kullanÄ±lÄ±r.\n",
        "   - **Ã–zellik**: Burada katmanÄ±n adÄ± `token_embedding` olarak belirlenmiÅŸ.\n",
        "\n",
        "4. **`mask_zero`**:\n",
        "   - **TanÄ±m**: Bu parametre, giriÅŸteki sÄ±fÄ±rlarÄ±n (yani genellikle padding token'larÄ±nÄ±n) gÃ¶z ardÄ± edilip edilmeyeceÄŸini belirtir. EÄŸer `True` ise sÄ±fÄ±r olan input deÄŸerleri maskelenir.\n",
        "   - **Ã–zellik**: Bu durumda, sÄ±fÄ±r olan deÄŸerler (padding) gÃ¶mme katmanÄ±na dahil edilmez.\n",
        "\n",
        "5. **`input_length`**:\n",
        "   - **TanÄ±m**: GÃ¶mme katmanÄ±na giren dizilerin uzunluÄŸunu belirtir. Bu, giriÅŸ verisinin sabit bir uzunluÄŸa sahip olduÄŸunu varsayar.\n",
        "   - **Ã–zellik**: Burada, her giriÅŸ dizisinin uzunluÄŸu 55 olarak belirlenmiÅŸ.\n",
        "\n",
        "6. **`embeddings_initializer`**:\n",
        "   - **TanÄ±m**: GÃ¶mme katmanÄ±ndaki vektÃ¶rlerin baÅŸlangÄ±Ã§ deÄŸerlerini belirler. `uniform`, deÄŸerlerin kÃ¼Ã§Ã¼k rastgele sayÄ±larla baÅŸlatÄ±lacaÄŸÄ± anlamÄ±na gelir.\n",
        "   - **Ã–zellik**: Bu, genellikle aÄŸÄ±rlÄ±klarÄ±n rastgele bir ÅŸekilde baÅŸlangÄ±Ã§ta daÄŸÄ±tÄ±lmasÄ± iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "7. **`trainable`**:\n",
        "   - **TanÄ±m**: GÃ¶mme katmanÄ±nÄ±n eÄŸitilebilir olup olmadÄ±ÄŸÄ±nÄ± belirtir. EÄŸer `True` ise, gÃ¶mme katmanÄ±ndaki aÄŸÄ±rlÄ±klar (embedding vektÃ¶rleri) eÄŸitilebilir (yani Ã¶ÄŸrenilebilir).\n",
        "   - **Ã–zellik**: Burada, gÃ¶mme katmanÄ± eÄŸitilebilir olarak ayarlanmÄ±ÅŸ.\n",
        "\n",
        "8. **`activity_regularizer`**:\n",
        "   - **TanÄ±m**: Aktivite dÃ¼zenleyici, katmanÄ±n Ã§Ä±ktÄ±larÄ±na uygulanan bir L2 ceza terimidir. Modelin daha az kompleks olmasÄ±nÄ± saÄŸlamak iÃ§in kullanÄ±lÄ±r.\n",
        "   - **Ã–zellik**: Bu, gÃ¶mme katmanÄ±nÄ±n Ã§Ä±ktÄ±sÄ±na L2 ceza uygulanacaÄŸÄ±nÄ± belirtir.\n",
        "\n",
        "9. **`embeddings_regularizer`**:\n",
        "   - **TanÄ±m**: GÃ¶mme katmanÄ±nÄ±n aÄŸÄ±rlÄ±klarÄ±na uygulanan dÃ¼zenleyicidir. Bu da L2 ceza terimi kullanarak aÄŸÄ±rlÄ±klarÄ±n bÃ¼yÃ¼klÃ¼ÄŸÃ¼nÃ¼ sÄ±nÄ±rlamaya yardÄ±mcÄ± olur.\n",
        "   - **Ã–zellik**: Bu, gÃ¶mme vektÃ¶rlerinin regularizasyonu iÃ§in L2 ceza uygulanÄ±r.\n",
        "\n",
        "10. **`update_embedding`**:\n",
        "    - **TanÄ±m**: Bu parametre TensorFlow'un eski sÃ¼rÃ¼mlerinde kullanÄ±labilir. GÃ¼nÃ¼mÃ¼zde bu parametre yerine `trainable=True` tercih edilmektedir.\n",
        "    - **Ã–zellik**: Bu, gÃ¶mme katmanÄ±nÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ±n gÃ¼ncellenip gÃ¼ncellenmeyeceÄŸini kontrol eder. Ancak bu parametre artÄ±k yaygÄ±n olarak kullanÄ±lmaz.\n",
        "\n",
        "11. **`input_shape`**:\n",
        "    - **TanÄ±m**: Katman iÃ§in giriÅŸ verisinin ÅŸekli. Burada `(None, 55)` kullanÄ±lmÄ±ÅŸ; `None` giriÅŸ batch boyutunun dinamik olduÄŸunu belirtir, `55` ise her dizinin uzunluÄŸunu belirtir.\n",
        "\n",
        "12. **`dtype`**:\n",
        "    - **TanÄ±m**: Katmandaki verinin veri tÃ¼rÃ¼nÃ¼ belirtir. Genellikle `float32` kullanÄ±lÄ±r.\n",
        "    - **Ã–zellik**: Burada, veri tÃ¼rÃ¼ olarak `float32` belirtilmiÅŸ.\n",
        "\n",
        "---\n",
        "\n",
        "- **`mask_zero=True`**: EÄŸer padding yapÄ±yorsanÄ±z, sÄ±fÄ±rlarÄ±n maskelenmesi Ã¶nemli olabilir.\n",
        "- **`embeddings_initializer`** ve **`trainable=True`**: GÃ¶mme katmanlarÄ±nÄ±n baÅŸlangÄ±Ã§ta rastgele baÅŸlatÄ±lmasÄ±nÄ± ve eÄŸitilebilir olmasÄ±nÄ± istiyorsanÄ±z bunlarÄ± kullanabilirsiniz.\n",
        "- **`activity_regularizer`** ve **`embeddings_regularizer`**: EÄŸer overfitting'i engellemek iÃ§in dÃ¼zenleme (regularization) yapmak istiyorsanÄ±z bu parametreleri kullanabilirsiniz."
      ],
      "metadata": {
        "id": "75OSI68AvunB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.6. Veri KÃ¼melerini hazÄ±rlama**"
      ],
      "metadata": {
        "id": "i1OzQJ3Nj5HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bir makine Ã¶ÄŸrenimi modeliyle kullanÄ±lmak Ã¼zere veri kÃ¼melerimizi Ã¶nceden iÅŸleme zahmetini yaÅŸadÄ±k, ancak modellerimizle daha hÄ±zlÄ± Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlamak iÃ§in kullanabileceÄŸimiz birkaÃ§ adÄ±m var.\n",
        "\n",
        "Yani, tf.data API, daha hÄ±zlÄ± veri yÃ¼klemesini saÄŸlayan yÃ¶ntemler saÄŸlar.\n",
        "\n",
        "ğŸ“– Kaynak: TensorFlow'da veri yÃ¼klemeyle ilgili en iyi uygulamalar iÃ§in aÅŸaÄŸÄ±dakilere gÃ¶z atÄ±n:\n",
        "\n",
        "- tf.data: TensorFlow giriÅŸ boru hatlarÄ± oluÅŸturun https://www.tensorflow.org/guide/data?hl=tr\n",
        "\n",
        "- tf.data API ile daha iyi performans https://www.tensorflow.org/guide/data_performance?hl=tr\n",
        "\n",
        "Verilerimizle kullanmak isteyeceÄŸimiz ana adÄ±mlar, onu bir PrefetchDataset gruplarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmektir.\n",
        "\n",
        "Bunu yaparak TensorFlow'un verilerimizi GPU'ya mÃ¼mkÃ¼n olduÄŸunca hÄ±zlÄ± bir ÅŸekilde yÃ¼klemesini ve daha hÄ±zlÄ± eÄŸitim sÃ¼resine yol aÃ§masÄ±nÄ± saÄŸlayacaÄŸÄ±z.\n",
        "\n",
        "Toplu bir PrefetchDataset oluÅŸturmak iÃ§in batch() ve prefetch() yÃ¶ntemlerini kullanabiliriz, tf.data.AUTOTUNE parametresi ayrÄ±ca TensorFlow'un veri kÃ¼melerini hazÄ±rlamak iÃ§in kullanÄ±lacak en uygun iÅŸlem miktarÄ±nÄ± belirlemesine izin verecektir.\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch\n",
        "* https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch\n",
        "* https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE"
      ],
      "metadata": {
        "id": "KKq_Uw1-waSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verilerimizi TensorFlow Veri KÃ¼melerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset\n",
        "\n",
        "# Hepsi etiket dizesidir.\n",
        "# EÄŸitim veri seti, veri setini dilimleme eÄŸilimindedir. Yani artÄ±k test veri kÃ¼melerindeki eÄŸitim doÄŸrulamalarÄ±ndaki Ã¶rneklerin her biri artÄ±k veri kÃ¼melerini dilimleme eÄŸiliminde\n",
        "# Ã‡Ä±ktÄ±daki ÅŸekil (None, (5)) tuple tarzÄ±ndadÄ±r. One hot eÄŸitim verisi bir Ã¼st ÅŸekli etiketler"
      ],
      "metadata": {
        "id": "iyH936Vcw_u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178cac1e-4a02-459d-e8d1-ec2188436407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, **TensorFlow veri kÃ¼mesi (dataset)** oluÅŸturma sÃ¼recini gÃ¶sterir ve **TensorFlow'un `tf.data` API'si** kullanÄ±larak verilerin model eÄŸitimi iÃ§in uygun bir formatta sunulmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "```python\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "```\n",
        "\n",
        "- **`train_labels_one_hot`, eÄŸitim, doÄŸrulama ve test setlerindeki etiketlerin one-hot kodlanmÄ±ÅŸ** haliyle temsil edilen deÄŸerlerdir. **One-hot kodlama**, her etiketin bir dizi elemanÄ± olarak temsil edilmesini saÄŸlar. Ã–rneÄŸin, 3 sÄ±nÄ±flÄ± bir problemde \"2. sÄ±nÄ±f\" iÃ§in `[0, 1, 0]` ÅŸeklinde bir kodlama yapÄ±lÄ±r.\n",
        "\n",
        "`tf.data.Dataset.from_tensor_slices()` Fonksiyonu:\n",
        "\n",
        "- **`from_tensor_slices()`**: Bu fonksiyon, **tensÃ¶rler** veya **numpy dizileri** gibi veri yapÄ±larÄ±nÄ± alÄ±r ve bunlarÄ± **TensorFlow veri kÃ¼mesine** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Her bir eleman (Ã¶rneÄŸin bir cÃ¼mle veya etiket), verisetindeki bir **Ã¶rnek** (sample) olur.\n",
        "  \n",
        "- Bu fonksiyonun temel amacÄ±, verileri **efektif bir ÅŸekilde batchâ€™lemek**, **karÄ±ÅŸtÄ±rmak (shuffle)**, **Ã¶nceden iÅŸleme uygulamak** (Ã¶rneÄŸin, tokenize etmek) ve modelin eÄŸitim sÃ¼recine uygun hale getirmektir.\n",
        "\n",
        "Ã–rneÄŸin:\n",
        "\n",
        "```python\n",
        "train_sentences = [\"Bu bir cÃ¼mledir.\", \"Bu baÅŸka bir cÃ¼mledir.\"]\n",
        "train_labels_one_hot = [[1, 0], [0, 1]]\n",
        "```\n",
        "\n",
        "Bu verileri `from_tensor_slices()` ile dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼ÄŸÃ¼mÃ¼zde, her cÃ¼mle ve etiket bir Ã§ift (sentence, label) olarak gruplanÄ±r ve verisetinin bir parÃ§asÄ± haline gelir.\n",
        "\n",
        "```python\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "```\n",
        "\n",
        "Bu iÅŸlem, her cÃ¼mle ve etiketin bir arada olduÄŸu bir **`tf.data.Dataset`** nesnesi oluÅŸturur. Bu nesne, eÄŸitim sÃ¼reci iÃ§in daha sonra kullanÄ±labilir.\n",
        "\n",
        "TensorFlow Veri KÃ¼mesi Nedir? Ne Ä°ÅŸe Yarar?\n",
        "\n",
        "**TensorFlow Veri KÃ¼mesi (Dataset)**, bÃ¼yÃ¼k ve karmaÅŸÄ±k veri kÃ¼melerinin **verimli bir ÅŸekilde** iÅŸlenmesine olanak tanÄ±r. Bu nesne, modelin eÄŸitim sÃ¼recinde Ã§eÅŸitli iÅŸlevler sunar:\n",
        "\n",
        "1. **Veri YÃ¼kleme**: BÃ¼yÃ¼k veri kÃ¼melerinin belleÄŸe sÄ±ÄŸmayan kÄ±sÄ±mlarÄ±nÄ± verimli bir ÅŸekilde yÃ¼kler.\n",
        "  \n",
        "2. **Batches (Gruplama)**: Verileri kÃ¼Ã§Ã¼k gruplara ayÄ±rarak modelin her seferinde sadece bir kÄ±smÄ± ile Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar. Bu, bellek kullanÄ±mÄ±nÄ± optimize eder.\n",
        "\n",
        "3. **Shuffle (KarÄ±ÅŸtÄ±rma)**: EÄŸitim verilerini karÄ±ÅŸtÄ±rarak, modelin sÄ±ralamadan baÄŸÄ±msÄ±z olarak Ã¶ÄŸrenmesini saÄŸlar ve overfitting (aÅŸÄ±rÄ± Ã¶ÄŸrenme) riskini azaltÄ±r.\n",
        "\n",
        "4. **Prefetch (Ã–nceden YÃ¼kleme)**: Veriler bir batch iÅŸlemi iÃ§in hazÄ±r olduÄŸunda, bir sonraki batch'in yÃ¼klenmesine baÅŸlar. Bu, CPU ve GPU arasÄ±nda zaman kaybÄ±nÄ± azaltÄ±r ve modelin daha hÄ±zlÄ± eÄŸitilmesini saÄŸlar.\n",
        "\n",
        "5. **Transformations (DÃ¶nÃ¼ÅŸtÃ¼rme)**: Veri Ã¼zerinde dÃ¶nÃ¼ÅŸÃ¼mler (Ã¶rneÄŸin, normalizasyon, augmentation, veri temizleme) yapabilirsiniz.\n",
        "\n",
        "KullanÄ±mda Neden Gerekli?\n",
        "\n",
        "TensorFlow veri kÃ¼mesi, veriyi **yÃ¼ksek performansla iÅŸlemek** iÃ§in Ã§ok Ã¶nemlidir Ã§Ã¼nkÃ¼:\n",
        "\n",
        "- **Veri AkÄ±ÅŸÄ±nÄ± YÃ¶netir**: `tf.data.Dataset`, veri setinin akÄ±ÅŸÄ±nÄ± yÃ¶netir ve veri Ã¼zerinde yapÄ±lan iÅŸlemleri (Ã¶rneÄŸin, batch'leme, karÄ±ÅŸtÄ±rma, dÃ¶nÃ¼ÅŸtÃ¼rme) kolayca uygular.\n",
        "  \n",
        "- **Bellek VerimliliÄŸi**: BÃ¼yÃ¼k veri kÃ¼meleriyle Ã§alÄ±ÅŸÄ±rken, `Dataset` nesnesi belleÄŸe tÃ¼m veriyi yÃ¼klemek yerine, veriyi parÃ§a parÃ§a iÅŸler ve belleÄŸi verimli kullanÄ±r.\n",
        "  \n",
        "- **Paralel Ä°ÅŸlem**: TensorFlow, verisetini paralel iÅŸlem yapacak ÅŸekilde optimize edebilir, yani birden fazla iÅŸ parÃ§acÄ±ÄŸÄ±yla verileri iÅŸleyebilir. Bu, eÄŸitim sÃ¼resini hÄ±zlandÄ±rÄ±r.\n",
        "\n",
        "- **Pipelines (Veri Boru HatlarÄ±)**: `tf.data.Dataset` ile veriyi doÄŸrudan modelle beslemeden Ã¶nce bir dizi iÅŸlem (tokenization, padding, vb.) uygulayabilirsiniz. Bu iÅŸlemleri dÃ¼zenli ve yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde yapmanÄ±za olanak tanÄ±r.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fQIGWGp3y0hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorSliceDataset'leri alÄ±n ve bunlarÄ± Ã¶nceden getirilmiÅŸ gruplara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "bcLnSjss0B9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a758bcae-fc31-4da1-cf82-9c28a1d32b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, daha Ã¶nce oluÅŸturduÄŸunuz **`train_dataset`, `valid_dataset`,** ve **`test_dataset`** veri kÃ¼melerine iki Ã¶nemli iÅŸlem uygular: **batch'leme** ve **prefetching**. Bu iÅŸlemler, eÄŸitim sÃ¼recini daha verimli hale getirmek ve sistem kaynaklarÄ±nÄ± optimize etmek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "```python\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "1. **Batch'leme (`batch(32)`)**\n",
        "- **`batch(32)`**: Bu, veri kÃ¼mesindeki verileri kÃ¼Ã§Ã¼k gruplara (batch'lere) ayÄ±rÄ±r. Buradaki `32`, her batch'teki Ã¶rnek sayÄ±sÄ±nÄ± belirtir. Yani, model her seferinde **32 Ã¶rneÄŸi** (cÃ¼mleyi, resimleri, vb.) aynÄ± anda iÅŸler. Bu, eÄŸitim sÄ±rasÄ±nda iÅŸlem verimliliÄŸini artÄ±rÄ±r ve aynÄ± zamanda GPU'nun paralel iÅŸlem kapasitesinden daha fazla yararlanmanÄ±za yardÄ±mcÄ± olur.\n",
        "  \n",
        "  - **Batch'leme** avantajlarÄ±:\n",
        "    - EÄŸitimde veri kÃ¼melerini daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rarak belleÄŸi verimli kullanÄ±r.\n",
        "    - Modelin her bir batch iÃ§in daha verimli bir ÅŸekilde optimizasyon yapmasÄ±nÄ± saÄŸlar.\n",
        "    - Hesaplamalar Ã¼zerinde paralellik saÄŸlanarak daha hÄ±zlÄ± eÄŸitim yapÄ±lmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "  Ã–rneÄŸin, eÄŸer veri kÃ¼meniz 1000 Ã¶rnekten oluÅŸuyorsa ve batch boyutunu 32 olarak belirlediyseniz, eÄŸitim sÃ¼recinde model 1000 Ã¶rneÄŸi iÅŸlemek yerine, 32'lik batch'ler halinde Ã§alÄ±ÅŸacak ve toplamda 32 batch ile tÃ¼m veriyi iÅŸleyecektir.\n",
        "\n",
        "2. **Prefetching (`prefetch(tf.data.AUTOTUNE)`)**\n",
        "- **`prefetch(tf.data.AUTOTUNE)`**: Prefetching, verinin eÄŸitim sÄ±rasÄ±nda Ã¶nceden yÃ¼klenmesini saÄŸlayarak eÄŸitim sÃ¼recinin hÄ±zlanmasÄ±na yardÄ±mcÄ± olur. Bu, verilerin **GPU'nun veya iÅŸlemcinin** boÅŸta olduÄŸu zamanlarda yÃ¼klenmesini saÄŸlar. BÃ¶ylece model veriyi iÅŸlerken bir sonraki batch'in verileri, iÅŸlemci veya GPU tarafÄ±ndan iÅŸlenmeden Ã¶nce yÃ¼klenmiÅŸ olur.\n",
        "\n",
        "  - **`AUTOTUNE`**: `AUTOTUNE`, TensorFlow'a, verinin ne kadar hÄ±zlÄ± yÃ¼klenmesi gerektiÄŸini **otomatik olarak** ayarlamasÄ±nÄ± sÃ¶yleyen bir mekanizmadÄ±r. Bu, TensorFlow'un veriyi yÃ¼klerken ve iÅŸlerken en verimli yolu bulmasÄ±nÄ± saÄŸlar.\n",
        "  \n",
        "  - **Prefetching** avantajlarÄ±:\n",
        "    - EÄŸitim sÄ±rasÄ±nda veri yÃ¼kleme sÃ¼resi minimize edilir.\n",
        "    - CPU ve GPU arasÄ±ndaki boÅŸluklar doldurulur ve paralel iÅŸlem yapÄ±labilir, bÃ¶ylece eÄŸitim hÄ±zlanÄ±r.\n",
        "    - Verinin eÄŸitim sÄ±rasÄ±nda daha hÄ±zlÄ± ve verimli bir ÅŸekilde sunulmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "---\n",
        "\n",
        "Neden Bunlar KullanÄ±lÄ±yor?\n",
        "\n",
        "1. **Veri AkÄ±ÅŸÄ± ve Bellek YÃ¶netimi**:\n",
        "   - EÄŸitim sÄ±rasÄ±nda veri kÃ¼meleri genellikle Ã§ok bÃ¼yÃ¼k olabilir. `batch(32)` kullanmak, verileri kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rarak belleÄŸi daha verimli kullanÄ±r. AyrÄ±ca, her batch ile ayrÄ± ayrÄ± Ã§alÄ±ÅŸmak, daha iyi eÄŸitim saÄŸlar.\n",
        "   - `prefetch(tf.data.AUTOTUNE)` ile, verinin yÃ¼klenmesi sÄ±rasÄ±nda modelin eÄŸitimi devam eder. Bu, **I/O (Input/Output) gecikmelerini** azaltarak eÄŸitim sÃ¼recini hÄ±zlandÄ±rÄ±r.\n",
        "\n",
        "2. **Paralel Ä°ÅŸlem**:\n",
        "   - Bu iki iÅŸlem, veriyi paralel olarak yÃ¼kler ve iÅŸler, yani CPU ve GPU arasÄ±ndaki etkileÅŸim daha verimli hale gelir. GPU'nun iÅŸlediÄŸi veriler yÃ¼klenirken, CPU bir sonraki batch'i hazÄ±rlamaya devam eder. Bu paralellik, eÄŸitim sÃ¼resini Ã¶nemli Ã¶lÃ§Ã¼de kÄ±saltabilir.\n",
        "\n",
        "### Ã–rnek Senaryo:\n",
        "\n",
        "EÄŸer `train_dataset`'inizde 1000 Ã¶rnek varsa ve batch boyutunu 32 olarak belirlediyseniz, aÅŸaÄŸÄ±daki iÅŸlemler gerÃ§ekleÅŸir:\n",
        "\n",
        "1. Model, ilk batch (32 Ã¶rnek) ile eÄŸitim yapmaya baÅŸlar.\n",
        "2. AynÄ± anda, **bir sonraki batch** (32 Ã¶rnek) **GPU'nun boÅŸta olduÄŸu zamanlarda** CPU tarafÄ±ndan yÃ¼klenir.\n",
        "3. Ä°lk batch iÅŸlemi tamamlandÄ±ÄŸÄ±nda, model ikinci batch'e geÃ§er ve aynÄ± sÃ¼reÃ§ devam eder.\n",
        "   \n",
        "Bu sayede **verinin hazÄ±rlanmasÄ±** ile **modelin eÄŸitilmesi** paralel hale gelir ve eÄŸitim sÃ¼reci daha hÄ±zlÄ± ilerler."
      ],
      "metadata": {
        "id": "J6tgohcg0UYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.7. Kelime DÃ¼zeyinde Conv1D Ä°le Modelleme ve DeÄŸerlendirme**"
      ],
      "metadata": {
        "id": "fqb4KprBj5FJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TÃ¼m derin modellerimiz benzer bir yapÄ± izleyecektir:\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "\n",
        "BaÅŸtan sona deÄŸiÅŸtireceÄŸimiz ana bileÅŸen Katmanlar bileÅŸenidir. Ã‡Ã¼nkÃ¼ herhangi bir modern derin NLP modeli, iÃ§inde anlamlÄ± kalÄ±plar keÅŸfedilmeden Ã¶nce metnin bir gÃ¶mmeye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesini gerektirir.\n",
        "\n",
        "Ä°nÅŸa edeceÄŸimiz ilk model, 1 boyutlu bir EvriÅŸimli Sinir AÄŸÄ±dÄ±r."
      ],
      "metadata": {
        "id": "IZmzYQSf03g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Dizileri iÅŸlemek iÃ§in 1 boyutlu evriÅŸimli model oluÅŸturun\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\", activation = \"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x)  # Ã¶zellik vektÃ¶rÃ¼mÃ¼zÃ¼n Ã§Ä±ktÄ±sÄ±nÄ± yoÄŸunlaÅŸtÄ±rÄ±n\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model_1.compile(\n",
        "    loss = \"categorical_crossentropy\", # eÄŸer etiketleriniz tamsayÄ± biÃ§imindeyse (tek bir sÄ±cak deÄŸil) sparse_categorical_crossentropy kullanÄ±n\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Modelin uydurulmasÄ±\n",
        "model_1_history = model_1.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch = int(0.1 * len(train_dataset)),  # daha hÄ±zlÄ± eÄŸitim sÃ¼resi iÃ§in partilerin yalnÄ±zca %10'una sÄ±ÄŸdÄ±r\n",
        "    epochs = 5,\n",
        "    validation_data = valid_dataset,\n",
        "    validation_steps = int(0.1 * len(valid_dataset))  # gruplarÄ±n yalnÄ±zca %10'unu doÄŸrulayÄ±n\n",
        ")\n",
        "\n",
        "# Model Ã¶zeti\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "YCjXH3pw3ACE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "f5365342-f437-4a1e-a8bc-8aa1140f069a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5246 - loss: 1.1679 - val_accuracy: 0.7434 - val_loss: 0.6891\n",
            "Epoch 2/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7473 - loss: 0.6815 - val_accuracy: 0.7733 - val_loss: 0.6248\n",
            "Epoch 3/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7705 - loss: 0.6218 - val_accuracy: 0.7886 - val_loss: 0.5906\n",
            "Epoch 4/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7861 - loss: 0.5952 - val_accuracy: 0.8022 - val_loss: 0.5655\n",
            "Epoch 5/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7905 - loss: 0.5868 - val_accuracy: 0.7955 - val_loss: 0.5651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ text_vectorization_1                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mTextVectorization\u001b[0m)                  â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_embedding (\u001b[38;5;33mEmbedding\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)             â”‚       \u001b[38;5;34m8,299,648\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)              â”‚          \u001b[38;5;34m41,024\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   â”‚             \u001b[38;5;34m325\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ text_vectorization_1                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,299,648</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling1d_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,022,993\u001b[0m (95.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,022,993</span> (95.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,340,997\u001b[0m (31.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,340,997</span> (31.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,681,996\u001b[0m (63.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,681,996</span> (63.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30.2 s, sys: 1.99 s, total: 32.2 s\n",
            "Wall time: 42.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Ã¶zetini kontrol ederken, eÄŸitilebilir parametrelerin Ã§oÄŸunun gÃ¶mme katmanÄ± iÃ§inde olduÄŸunu fark edeceksiniz. GÃ¶mmenin boyutunu artÄ±racak olsaydÄ±k (GÃ¶mme katmanÄ±nÄ±n output_dim parametresini artÄ±rarak), eÄŸitilebilir parametrelerin sayÄ±sÄ± Ã¶nemli Ã¶lÃ§Ã¼de artardÄ±.\n",
        "\n",
        "EÄŸitim verilerimiz yaklaÅŸÄ±k 200.000 cÃ¼mle iÃ§erdiÄŸinden, bir GPU ile bile derin bir modele uyum biraz zaman alabilir. Bu nedenle, deneylerimizi hÄ±zlÄ± tutmak iÃ§in onlarÄ± eÄŸitim veri kÃ¼mesinin bir alt kÃ¼mesinde Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z.\n",
        "\n",
        "Daha spesifik olarak, eÄŸitilecek eÄŸitim setinin yalnÄ±zca ilk %10'unu (yaklaÅŸÄ±k 18.000 Ã¶rnek) ve doÄŸrulamak iÃ§in doÄŸrulama setindeki partilerin ilk %10'unu kullanacaÄŸÄ±z.\n",
        "\n",
        "ğŸ”‘ Not: Modellerinizi daha bÃ¼yÃ¼k miktarda veriye Ã¶lÃ§eklendirmeden Ã¶nce Ã§alÄ±ÅŸtÄ±klarÄ±ndan emin olmak iÃ§in Ã¶nce daha kÃ¼Ã§Ã¼k veri alt kÃ¼meleri Ã¼zerinde test etmek makine Ã¶ÄŸreniminde standart bir uygulamadÄ±r. Sadece bir avuÃ§ bÃ¼yÃ¼k deney yerine Ã§ok sayÄ±da kÃ¼Ã§Ã¼k deney yapmayÄ± hedeflemelisiniz. Ve zamanÄ±nÄ±z sÄ±nÄ±rlÄ± olduÄŸundan, daha kÃ¼Ã§Ã¼k deneyler yÃ¼rÃ¼tmenin en iyi yollarÄ±ndan biri, Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z veri miktarÄ±nÄ± azaltmaktÄ±r (benzer bir daÄŸÄ±lÄ±mÄ± kapsadÄ±ÄŸÄ± sÃ¼rece, tam veri kÃ¼mesinin %10'u genellikle iyi bir miktardÄ±r).\n",
        "\n",
        "- Veri kÃ¼mesini zaten sÄ±ÄŸacak ÅŸekilde Ã¶nceden biÃ§imlendirmiÅŸtik.\n",
        "- Her dÃ¶nem iÃ§in adÄ±mlarÄ±n %10'unu atarÄ±z. Yani modelin partilerin yalnÄ±zca %10'una bakmasÄ±nÄ± istedik.\n",
        "- HÄ±zlÄ± yapmak iÃ§in bunu yaptÄ±k. Sonuca bakÄ±p hatanÄ±n nerede olduÄŸunu anlamak iÃ§in mÃ¼mkÃ¼n olduÄŸunca baÅŸtan modeli kÄ±sa tuttuk. Denemeleri beÅŸ dk altÄ±nda yapmaya Ã§alÄ±ÅŸtÄ±k."
      ],
      "metadata": {
        "id": "XX2o4Q8I5dJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "```\n",
        "\n",
        "- **`layers.Input()`**: Modelin giriÅŸ katmanÄ±nÄ± tanÄ±mlar.\n",
        "  - **`shape=(1,)`**: GiriÅŸ verisi bir **dizi** olacaÄŸÄ± iÃ§in, burada her Ã¶rnek **tek bir metin dizisi** (string) olacaktÄ±r. Bu durumda her Ã¶rnek, tek bir metin satÄ±rÄ±nÄ± (ya da cÃ¼mleyi) temsil eder.\n",
        "  - **`dtype=tf.string`**: GiriÅŸ veri tÃ¼rÃ¼, metin verisi olduÄŸu iÃ§in `tf.string` olarak belirtilmiÅŸtir.\n",
        "\n",
        "Bu katman, modelin aldÄ±ÄŸÄ± ilk veriyi tanÄ±mlar. Buradaki `shape=(1,)`, her giriÅŸ Ã¶rneÄŸinin **tek bir metin dizisi** olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "```\n",
        "\n",
        "- **`text_vectorizer`**: Bu, muhtemelen metni sayÄ±sal bir formata dÃ¶nÃ¼ÅŸtÃ¼ren bir katmandÄ±r. Ã–rneÄŸin, metni **token'lar** veya **kelime gÃ¶mme vektÃ¶rleri** (word embeddings) gibi sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼ren bir katman olabilir.\n",
        "  - Bu katman, metin verisini **vektÃ¶rlere** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. EÄŸer `text_vectorizer` bir `TextVectorization` katmanÄ± ise, metni tokenize edip sabit boyutlu sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "```\n",
        "\n",
        "- **`token_embed`**: Burada, **gÃ¶mme (embedding)** katmanÄ± kullanÄ±larak, kelimeler ya da token'lar, sÃ¼rekli (dense) vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.\n",
        "  - **`token_embed`** daha Ã¶nce tanÄ±mladÄ±ÄŸÄ±nÄ±z gÃ¶mme katmanÄ±dÄ±r ve burada `text_vectors`'Ä± alÄ±r ve her token'Ä± sabit boyutlu bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r (Ã¶rneÄŸin, 64 boyutlu).\n",
        "  \n",
        "---\n",
        "\n",
        "```python\n",
        "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\", activation = \"relu\")(token_embeddings)\n",
        "```\n",
        "\n",
        "- **`Conv1D`**: 1D evriÅŸimsel (convolutional) katman, metin verisiyle Ã§alÄ±ÅŸÄ±rken, kelime veya token sÄ±rasÄ±ndaki iliÅŸkileri Ã¶ÄŸrenmek iÃ§in kullanÄ±lÄ±r.\n",
        "  - **`64`**: Ã‡Ä±kÄ±ÅŸ (feature) sayÄ±sÄ±dÄ±r. Bu, katmandan Ã§Ä±kan her bir **Ã¶zellik haritasÄ±** (feature map) sayÄ±sÄ±nÄ± belirtir.\n",
        "  - **`kernel_size=5`**: EvriÅŸim iÃ§in kullanÄ±lan Ã§ekirdek (kernel) boyutudur. Burada 5, her bir evriÅŸim iÅŸleminde 5 token'lÄ±k bir pencere boyutunu ifade eder.\n",
        "  - **`padding=\"same\"`**: Ã‡Ä±ktÄ± uzunluÄŸunun giriÅŸ uzunluÄŸuna eÅŸit olmasÄ±nÄ± saÄŸlar (yani giriÅŸ ve Ã§Ä±kÄ±ÅŸ boyutlarÄ± eÅŸit olur). Bu, **sÄ±fÄ±r dolgusu (zero padding)** ekler.\n",
        "  - **`activation=\"relu\"`**: Aktivasyon fonksiyonu olarak **ReLU** (Rectified Linear Unit) kullanÄ±lÄ±r. ReLU, evriÅŸimsel katmandan sonra doÄŸrusal olmayan bir aktivasyon saÄŸlar.\n",
        "\n",
        "Bu katman, metin verisindeki Ã¶zellikleri Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r. Her token (veya token dizisi) Ã¼zerinde kaydÄ±rÄ±larak (sliding window) evriÅŸim yapÄ±lÄ±r ve metnin Ã¶nemli Ã¶zelliklerini Ã§Ä±karÄ±r.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "```\n",
        "\n",
        "- **`GlobalAveragePooling1D`**: Bu katman, **evriÅŸimsel katman** Ã§Ä±ktÄ±sÄ±nÄ± **yoÄŸunlaÅŸtÄ±rarak** (sÄ±kÄ±ÅŸtÄ±rarak) tek bir vektÃ¶r haline getirir.\n",
        "  - 1D veride, her bir Ã¶zellik haritasÄ±ndaki tÃ¼m zaman adÄ±mlarÄ±nÄ±n (token'lar) ortalamasÄ±nÄ± alÄ±r. Yani, evriÅŸimsel katmandan Ã§Ä±kan her Ã¶zellik haritasÄ± (feature map) Ã¼zerinde ortalama hesaplanÄ±r ve bu, her harita iÃ§in bir deÄŸer verir.\n",
        "  - Bu iÅŸlem, modelin Ã§Ä±kÄ±ÅŸÄ±nÄ± daha kÃ¼Ã§Ã¼k boyutlu bir **Ã¶zellik vektÃ¶rÃ¼** haline getirir, bu sayede modelin genel Ã¶zelliklerini temsil eden bir vektÃ¶r elde edilir.\n",
        "\n",
        "Global Average Pooling, **evriÅŸimsel katmandan Ã§Ä±kan tÃ¼m Ã¶zelliklerin** Ã¶zetini alarak, modelin daha genel bir temsilini Ã§Ä±karmaya yardÄ±mcÄ± olur.\n",
        "\n",
        "---\n",
        "\n",
        "Tam BaÄŸlantÄ±lÄ± Katman:\n",
        "\n",
        "```python\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "```\n",
        "\n",
        "- **`Dense(num_classes, activation=\"softmax\")`**: Bu, son katmandÄ±r ve modelin **sÄ±nÄ±flandÄ±rma** yapmasÄ±nÄ± saÄŸlar.\n",
        "  - **`num_classes`**: Modelin tahmin edeceÄŸi sÄ±nÄ±f sayÄ±sÄ±nÄ± belirtir. Ã–rneÄŸin, 3 sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma problemi iÃ§in `num_classes = 3`.\n",
        "  - **`activation=\"softmax\"`**: **Softmax aktivasyonu**, Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma problemleri iÃ§in yaygÄ±n olarak kullanÄ±lÄ±r. Ã‡Ä±ktÄ±, her sÄ±nÄ±f iÃ§in bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± dÃ¶ndÃ¼rÃ¼r ve tÃ¼m sÄ±nÄ±flarÄ±n olasÄ±lÄ±klarÄ± 1'e eÅŸit olur.\n",
        "\n",
        "Bu katman, modelin Ã§Ä±ktÄ±sÄ±nÄ± oluÅŸturur ve verilen giriÅŸ metni iÃ§in hangi sÄ±nÄ±fa ait olduÄŸunu tahmin eder.\n",
        "\n",
        "---\n",
        "\n",
        "Modeli TanÄ±mlama:\n",
        "\n",
        "```python\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "```\n",
        "\n",
        "- **`tf.keras.Model()`**: Keras API'sinde, `inputs` ve `outputs` parametreleriyle modelin son halini oluÅŸturur. Bu, modelin **giriÅŸ** ve **Ã§Ä±kÄ±ÅŸ** katmanlarÄ±nÄ± belirler ve modelin tamamlanmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "Ã–zetle:\n",
        "\n",
        "Bu kod, bir **1D evriÅŸimli model** oluÅŸturur ve metin verisini sÄ±nÄ±flandÄ±rmak iÃ§in kullanÄ±lÄ±r. AdÄ±m adÄ±m aÃ§Ä±klanacak olursak:\n",
        "\n",
        "1. **GiriÅŸ katmanÄ±**: Metin verisini (string) alÄ±r.\n",
        "2. **Metin vektÃ¶rlemesi**: `text_vectorizer` kullanÄ±larak metin, sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.\n",
        "3. **GÃ¶mme katmanÄ±**: `token_embed` ile kelimeler veya token'lar gÃ¶mme (embedding) vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r.\n",
        "4. **EvriÅŸim katmanÄ±**: `Conv1D` ile metin Ã¼zerindeki Ã¶nemli Ã¶zellikler Ã¶ÄŸrenilir.\n",
        "5. **Global Average Pooling**: EvriÅŸimsel katmanÄ±n Ã§Ä±kÄ±ÅŸÄ±nÄ± sÄ±kÄ±ÅŸtÄ±rarak bir Ã¶zet vektÃ¶r elde edilir.\n",
        "6. **YoÄŸun (Dense) katman**: Son olarak, `softmax` aktivasyonu kullanÄ±larak sÄ±nÄ±flandÄ±rma yapÄ±lÄ±r.\n",
        "\n",
        "SonuÃ§ olarak, bu model **metin verilerini** sÄ±nÄ±flandÄ±rmak amacÄ±yla 1D evriÅŸim kullanarak Ã¶ÄŸrenme yapar."
      ],
      "metadata": {
        "id": "IqOsN9VH6zdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras'ta, modelleri oluÅŸturmanÄ±n iki ana yolu vardÄ±r:\n",
        "\n",
        "1. **Dizisel API**: Bu, modelin katmanlarÄ±nÄ± sÄ±rayla ekleyerek inÅŸa edilen, daha basit ve genellikle daha kÃ¼Ã§Ã¼k modeller iÃ§in uygundur. Bu model tÃ¼rÃ¼ `Sequential()` sÄ±nÄ±fÄ± kullanÄ±larak oluÅŸturulur.\n",
        "   \n",
        "   Ã–rnek:\n",
        "   ```python\n",
        "   model = tf.keras.Sequential([\n",
        "       layers.Input(shape=(1,), dtype=tf.string),\n",
        "       text_vectorizer,\n",
        "       token_embed,\n",
        "       layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
        "       layers.GlobalAveragePooling1D(),\n",
        "       layers.Dense(num_classes, activation=\"softmax\")\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "2. **Fonksiyonel API**: Daha karmaÅŸÄ±k, esnek ve modÃ¼ler modeller oluÅŸturmak iÃ§in kullanÄ±lÄ±r. Katmanlar, girdi ve Ã§Ä±ktÄ± baÄŸlantÄ±larÄ± arasÄ±nda doÄŸrudan baÄŸlantÄ±lar kurularak model tanÄ±mlanÄ±r. Fonksiyonel API ile daha karmaÅŸÄ±k yapÄ±daki aÄŸlar, paylaÅŸÄ±lan katmanlar, Ã§ok giriÅŸli ve Ã§ok Ã§Ä±kÄ±ÅŸlÄ± aÄŸlar ve daha fazlasÄ± tasarlanabilir.\n",
        "\n",
        "Bu kodda **Fonksiyonel API** kullanÄ±lmÄ±ÅŸ Ã§Ã¼nkÃ¼ modelde daha esnek bir yapÄ± tercih edilmiÅŸtir. Birden fazla girdi, Ã§Ä±ktÄ±, dallanma veya katman paylaÅŸÄ±mÄ± gibi iÅŸlemler yapÄ±labilir. Ancak, burada sadece bir girdi ve bir Ã§Ä±ktÄ± olsa da, Fonksiyonel API daha modÃ¼ler bir tasarÄ±m saÄŸlar.\n",
        "\n",
        "**Fonksiyonel API'nin Temel Ã–zellikleri**:\n",
        "- Girdi ve Ã§Ä±ktÄ± katmanlarÄ± aÃ§Ä±kÃ§a tanÄ±mlanÄ±r.\n",
        "- Katmanlar doÄŸrudan birbirine baÄŸlanÄ±r.\n",
        "- Katmanlar arasÄ±nda dallanma yapÄ±labilir (Ã¶rneÄŸin, bir girdi birden fazla katmana yÃ¶nlendirilebilir veya bir katman birden fazla Ã§Ä±ktÄ± verebilir).\n",
        "- Modelin yapÄ±sÄ± daha esnektir ve genellikle karmaÅŸÄ±k mimariler iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "**Birinci x KatmanÄ±nda Hangi DeÄŸiÅŸkenler Eklenebilirdi?**\n",
        "\n",
        "Ä°lk **`x`** katmanÄ± ÅŸu ÅŸekilde tanÄ±mlanmÄ±ÅŸ:\n",
        "\n",
        "```python\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "```\n",
        "\n",
        "Ä°lk `Conv1D` katmanÄ±nda eklenebilecek bazÄ± deÄŸiÅŸkenler ÅŸunlar olabilir:\n",
        "\n",
        "- **`filters`**: Bu parametre, Ã§Ä±kÄ±ÅŸ kanal sayÄ±sÄ±nÄ± belirtir. Yani, kaÃ§ tane konvolÃ¼syonel filtre uygulanacaÄŸÄ±. Burada `64` olarak verilmiÅŸ, ancak bu sayÄ± arttÄ±rÄ±labilir veya azaltÄ±labilir. Ã–rneÄŸin, daha bÃ¼yÃ¼k bir modelde `128` veya `256` gibi deÄŸerler kullanÄ±labilir.\n",
        "  \n",
        "- **`kernel_size`**: KonvolÃ¼syonel filtrelerin boyutunu belirtir. Burada `5` olarak belirlenmiÅŸ, ancak daha bÃ¼yÃ¼k veya kÃ¼Ã§Ã¼k bir kernel (`3`, `7`, `9`, vb.) seÃ§ilebilir. Kernel boyutunun bÃ¼yÃ¼klÃ¼ÄŸÃ¼, modelin nasÄ±l Ã¶ÄŸrenme yapacaÄŸÄ±nÄ± etkiler.\n",
        "\n",
        "- **`strides`**: KonvolÃ¼syon iÅŸleminin adÄ±m boyutudur. VarsayÄ±lan olarak `1`'dir, ancak daha bÃ¼yÃ¼k bir deÄŸer (Ã¶rneÄŸin `2`) kullanarak daha bÃ¼yÃ¼k adÄ±mlarla Ã¶zelliklerin Ã§Ä±karÄ±lmasÄ± saÄŸlanabilir.\n",
        "\n",
        "- **`dilation_rate`**: KonvolÃ¼syon filtresinin geniÅŸliÄŸi. Bu parametre, filtrelerin girdi Ã¼zerinde ne kadar geniÅŸ bir aralÄ±ÄŸa yayÄ±ldÄ±ÄŸÄ±nÄ± belirler. EÄŸer dilasyon kullanÄ±lÄ±rsa, daha geniÅŸ aralÄ±klar Ã¼zerinden Ã¶zellik Ã§Ä±karÄ±mÄ± yapÄ±labilir.\n",
        "\n",
        "- **`activation`**: Burada `relu` aktivasyon fonksiyonu kullanÄ±lmÄ±ÅŸ. Fakat baÅŸka aktivasyon fonksiyonlarÄ± da kullanÄ±labilir: `tanh`, `sigmoid`, `leaky_relu` vb.\n",
        "\n",
        "- **`use_bias`**: Bu parametre, konvolÃ¼syonel katmanda bias (Ã¶nyargÄ±) terimi kullanÄ±lÄ±p kullanÄ±lmayacaÄŸÄ±nÄ± belirler. VarsayÄ±lan olarak `True` olarak gelir, ancak `False` yapÄ±labilir.\n",
        "\n",
        "- **`kernel_initializer` ve `bias_initializer`**: KatmanÄ±n aÄŸÄ±rlÄ±klarÄ±nÄ±n ve bias terimlerinin baÅŸlangÄ±Ã§ deÄŸerlerini belirleyebilirsiniz. Ã–rneÄŸin, `kernel_initializer='he_normal'` gibi.\n",
        "\n",
        "- **`trainable`**: KatmanÄ±n eÄŸitilebilir olup olmadÄ±ÄŸÄ±na karar veririz. Burada varsayÄ±lan olarak tÃ¼m katmanlar eÄŸitilebilir, ancak `trainable=False` yaparak bir katmanÄ±n eÄŸitim sÄ±rasÄ±nda gÃ¼ncellenmesini engelleyebilirsiniz.\n",
        "\n",
        "Ã–rneÄŸin:\n",
        "```python\n",
        "x = layers.Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=3,\n",
        "    padding=\"same\",\n",
        "    activation=\"relu\",\n",
        "    strides=1,\n",
        "    dilation_rate=1,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='he_normal'\n",
        ")(token_embeddings)\n",
        "```"
      ],
      "metadata": {
        "id": "3Ueihj11CdTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DoÄŸrulama veri kÃ¼mesinin tamamÄ±nÄ± deÄŸerlendirin (eÄŸitim sÄ±rasÄ±nda gruplarÄ±n yalnÄ±zca %10'unu doÄŸruladÄ±k)\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "sjfkts8A5zf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c54192-0107-4037-f423-bed704004d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.5583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5608068704605103, 0.800973117351532]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminlerde bulunun (modelimiz her sÄ±nÄ±f iÃ§in tahmin olasÄ±lÄ±klarÄ±nÄ±n Ã§Ä±ktÄ±sÄ±nÄ± verir)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs[:10]\n",
        "\n",
        "# 5 Ã§Ä±kÄ±ÅŸ nÃ¶ronlu Ã§Ä±kÄ±ÅŸ katmanÄ±nÄ± olduÄŸuna dikkat!"
      ],
      "metadata": {
        "id": "8rTphKEQ5zZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e88a23e-85b1-4c29-fb4a-bb873f54a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.3424037e-01, 1.6922709e-01, 4.2627126e-02, 1.9663626e-01,\n",
              "        5.7269096e-02],\n",
              "       [4.1625068e-01, 3.8065371e-01, 2.2781698e-02, 1.4178574e-01,\n",
              "        3.8528230e-02],\n",
              "       [1.6555984e-01, 5.2355202e-03, 1.7712441e-03, 8.2736790e-01,\n",
              "        6.5479027e-05],\n",
              "       [3.3826491e-05, 1.9337595e-04, 9.9888712e-01, 8.3502484e-05,\n",
              "        8.0219854e-04],\n",
              "       [7.5173406e-03, 1.0930215e-01, 5.1702136e-01, 4.9837832e-03,\n",
              "        3.6117539e-01],\n",
              "       [1.6721189e-02, 2.0874046e-02, 6.7839271e-01, 7.6261815e-03,\n",
              "        2.7638587e-01],\n",
              "       [1.1944027e-03, 3.2180697e-03, 6.3765353e-01, 7.2400115e-04,\n",
              "        3.5720989e-01],\n",
              "       [4.7482975e-02, 4.4579227e-02, 5.4065734e-01, 2.0480020e-02,\n",
              "        3.4680042e-01],\n",
              "       [2.4076807e-10, 9.4810110e-07, 1.6741293e-06, 7.8157598e-11,\n",
              "        9.9999738e-01],\n",
              "       [1.0809563e-02, 7.8868288e-01, 8.0670901e-02, 3.5253469e-02,\n",
              "        8.4583230e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pred problarÄ±nÄ± sÄ±nÄ±flara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis = 1)\n",
        "model_1_preds[:10] # her bir dizideki maks. deÄŸeri verir"
      ],
      "metadata": {
        "id": "UM8d1V5R5zTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84f003e-77eb-49ca-856b-c757e0a4131e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 2, 2, 2, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.argmax()` fonksiyonu, TensorFlow'da, verilen tensÃ¶rdeki en bÃ¼yÃ¼k deÄŸeri bulur ve bu deÄŸerin **indeksini** dÃ¶ndÃ¼rÃ¼r. Bu, genellikle modelin tahminlerinde kullanÄ±lan ve **sÄ±nÄ±flandÄ±rma** problemlerinde kullanÄ±lan bir fonksiyondur.\n",
        "\n",
        "1. **`model_1_pred_probs`**:\n",
        "   - Bu, modelin sÄ±nÄ±flandÄ±rma tahminlerinin olasÄ±lÄ±klarÄ±nÄ± iÃ§eren bir tensÃ¶rdÃ¼r. Model, **softmax aktivasyonu** ile her sÄ±nÄ±f iÃ§in bir olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ± dÃ¶ndÃ¼rÃ¼r. Ã–rneÄŸin, 3 sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rma problemi iÃ§in modelin Ã§Ä±ktÄ±sÄ± ÅŸu ÅŸekilde olabilir:\n",
        "     ```python\n",
        "     model_1_pred_probs = [[0.1, 0.7, 0.2],\n",
        "                           [0.4, 0.4, 0.2],\n",
        "                           [0.9, 0.05, 0.05]]\n",
        "     ```\n",
        "     Burada, her satÄ±r bir Ã¶rneÄŸin (Ã¶rneÄŸin bir metnin) olasÄ±lÄ±k daÄŸÄ±lÄ±mÄ±nÄ± temsil eder ve her sÃ¼tun bir sÄ±nÄ±fÄ±n olasÄ±lÄ±ÄŸÄ±nÄ± gÃ¶sterir.\n",
        "\n",
        "2. **`tf.argmax(model_1_pred_probs, axis=1)`**:\n",
        "   - **`tf.argmax()`** fonksiyonu, her satÄ±rdaki **en yÃ¼ksek olasÄ±lÄ±ÄŸÄ±** (veya deÄŸeri) bulur ve bu deÄŸerin **indeksini** dÃ¶ndÃ¼rÃ¼r.\n",
        "   - **`axis=1`**: Bu, `tf.argmax()` fonksiyonunun her satÄ±rdaki en bÃ¼yÃ¼k deÄŸeri bulmasÄ±nÄ± saÄŸlar. Yani, **her Ã¶rnek iÃ§in** (her satÄ±r) en yÃ¼ksek olasÄ±lÄ±ÄŸa sahip sÄ±nÄ±fÄ±n indeksini seÃ§er.\n",
        "     - **`axis=0`** olsaydÄ±, `tf.argmax()` her sÃ¼tun iÃ§in en yÃ¼ksek deÄŸeri seÃ§erdi, yani tÃ¼m Ã¶rnekler iÃ§in her bir sÄ±nÄ±fÄ±n en yÃ¼ksek olasÄ±lÄ±ÄŸÄ±nÄ± bulurdu. Ancak burada `axis=1` kullanÄ±ldÄ±ÄŸÄ± iÃ§in **her Ã¶rnek** iÃ§in (yani her satÄ±rda) en yÃ¼ksek olasÄ±lÄ±ÄŸÄ± buluruz.\n",
        "\n",
        "### Ã–rnek:\n",
        "\n",
        "Diyelim ki, modelinizin Ã§Ä±ktÄ±sÄ± ÅŸu ÅŸekilde:\n",
        "\n",
        "```python\n",
        "model_1_pred_probs = [[0.1, 0.7, 0.2],  # 1. Ã¶rnek iÃ§in sÄ±nÄ±f olasÄ±lÄ±klarÄ±\n",
        "                       [0.4, 0.4, 0.2],  # 2. Ã¶rnek iÃ§in sÄ±nÄ±f olasÄ±lÄ±klarÄ±\n",
        "                       [0.9, 0.05, 0.05]]  # 3. Ã¶rnek iÃ§in sÄ±nÄ±f olasÄ±lÄ±klarÄ±\n",
        "```\n",
        "\n",
        "Burada:\n",
        "- 1. Ã¶rneÄŸin olasÄ±lÄ±klarÄ± `[0.1, 0.7, 0.2]`. En yÃ¼ksek olasÄ±lÄ±k **0.7** ile **2. sÄ±nÄ±f**.\n",
        "- 2. Ã¶rneÄŸin olasÄ±lÄ±klarÄ± `[0.4, 0.4, 0.2]`. Burada en yÃ¼ksek olasÄ±lÄ±k **0.4** ile 1. veya 2. sÄ±nÄ±f. Ancak, `tf.argmax()` ilk bulduÄŸu en bÃ¼yÃ¼k deÄŸeri alacaÄŸÄ± iÃ§in **1. sÄ±nÄ±f** dÃ¶necektir.\n",
        "- 3. Ã¶rneÄŸin olasÄ±lÄ±klarÄ± `[0.9, 0.05, 0.05]`. En yÃ¼ksek olasÄ±lÄ±k **0.9** ile **1. sÄ±nÄ±f**.\n",
        "\n",
        "SonuÃ§ olarak:\n",
        "\n",
        "```python\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "```\n",
        "\n",
        "**`model_1_preds`** ÅŸu ÅŸekilde olacaktÄ±r:\n",
        "\n",
        "```python\n",
        "model_1_preds = [1, 0, 0]\n",
        "```\n",
        "\n",
        "Bu, modelin her bir Ã¶rnek iÃ§in tahmin ettiÄŸi sÄ±nÄ±f indeksleridir:\n",
        "- 1. Ã¶rnek iÃ§in **2. sÄ±nÄ±f** (indeks 1),\n",
        "- 2. Ã¶rnek iÃ§in **1. sÄ±nÄ±f** (indeks 0),\n",
        "- 3. Ã¶rnek iÃ§in **1. sÄ±nÄ±f** (indeks 0)."
      ],
      "metadata": {
        "id": "K8ggCgzg7nj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1 sonuÃ§larÄ±nÄ± hesapla\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "tR2ZzxEh5zOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "424a83d9-3d5f-40fe-ccbe-97f404d30303",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-10fbecc56d17>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model_1 sonuÃ§larÄ±nÄ± hesapla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_1_results = calculate_results(y_true=val_labels_encoded,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                     y_pred=model_1_preds)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_1_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \"\"\"\n\u001b[1;32m    280\u001b[0m   \u001b[0;31m# Calculate model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m   \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;31m# Calculate model precision, recall and f1 score using \"weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mmodel_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mget_namespace_and_device\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0marrays_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mdevice_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_array_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdevice_other\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;34mf\"Input arrays use different devices: {str(device_)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;34mf\"{str(device_other)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.8. Tensorflow Hub Ä°le Modelleme ve DeÄŸerlendirme**"
      ],
      "metadata": {
        "id": "ye8SznEVj5DE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TÄ±bbi KaÄŸÄ±t Ã–zetlerinde Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ±ndaki model mimarisini Ã§oÄŸaltmaya doÄŸru ilerlediÄŸimiz iÃ§in, belirteÃ§ gÃ¶mmelerini baÅŸlatmanÄ±n bir yolu olarak Ã¶nceden eÄŸitilmiÅŸ bir GloVe gÃ¶mme kullandÄ±klarÄ±ndan bahseder.\n",
        "* https://arxiv.org/pdf/1612.05251\n",
        "* https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Bunu taklit etmek iÃ§in, TensorFlow Hub'dan Ã¶nceden eÄŸitilmiÅŸ Evrensel CÃ¼mle KodlayÄ±cÄ± gÃ¶mmeleriyle hangi sonuÃ§larÄ± alabileceÄŸimizi gÃ¶relim. https://www.kaggle.com/models/google/universal-sentence-encoder/tensorFlow2/universal-sentence-encoder/2?tfhub-redirect=true\n",
        "\n",
        "ğŸ”‘ Not: GloVe gÃ¶mmelerini kaÄŸÄ±da gÃ¶re kullanabiliriz, ancak TensorFlow ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in TensorFlow Hub'da bulunanlarÄ± kullanacaÄŸÄ±z (GloVe gÃ¶mmeleri deÄŸil). Ã–nceden eÄŸitilmiÅŸ GloVe gÃ¶mmelerini uzantÄ± olarak kullanarak tasarruf edeceÄŸiz. https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "\n",
        "Model yapÄ±sÄ± ÅŸÃ¶yle gÃ¶rÃ¼necektir:\n",
        "\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "\n",
        "Ã–nceki bir modelde kullandÄ±ÄŸÄ±mÄ±z tokenizasyon katmanÄ±nÄ±n eksikliÄŸini fark edeceksiniz. Bunun nedeni, Evrensel CÃ¼mle KodlayÄ±cÄ±sÄ±nÄ±n (USE) bizim iÃ§in tokenizasyonla ilgilenmesidir.\n",
        "\n",
        "Bu tÃ¼r bir modele transfer Ã¶ÄŸrenimi veya daha spesifik olarak Ã¶zellik Ã§Ä±karma transfer Ã¶ÄŸrenimi denir. BaÅŸka bir deyiÅŸle, bir modelin baÅŸka bir yerde Ã¶ÄŸrendiÄŸi kalÄ±plarÄ± almak ve bunu kendi sorunumuza uygulamak.\n",
        "\n",
        "TensorFlow Hub'dan Ã¶nceden eÄŸitilmiÅŸ bir gÃ¶mme kullanarak oluÅŸturduÄŸumuz Ã¶zellik Ã§Ä±karÄ±cÄ± modeli.\n",
        "\n",
        "Ã–nceden eÄŸitilmiÅŸ USE'Ä± modelimizde kullanabileceÄŸimiz bir katmana indirmek iÃ§in hub.KerasLayer sÄ±nÄ±fÄ±nÄ± kullanabiliriz.\n",
        "\n",
        "Ã–nceden eÄŸitilmiÅŸ gÃ¶mmeleri donmuÅŸ tutacaÄŸÄ±z (eÄŸitilebilir=YanlÄ±ÅŸ ayarlayarak) ve model Ã§Ä±ktÄ±larÄ±nÄ± kendi verilerimize gÃ¶re uyarlamak iÃ§in Ã¼ste eÄŸitilebilir birkaÃ§ katman ekleyeceÄŸiz.\n",
        "\n",
        "ğŸ”‘ Not: Nispeten bÃ¼yÃ¼k bir modeli (~916MB) indirmek zorunda kaldÄ±ÄŸÄ±ndan, aÅŸaÄŸÄ±daki hÃ¼crenin Ã§alÄ±ÅŸmasÄ± biraz zaman alabilir. https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer"
      ],
      "metadata": {
        "id": "5jOVZBqm9Lga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–nceden eÄŸitilmiÅŸ TensorFlow Hub'Ä± indirin KULLANIM\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "_Sc2k-Pv-aNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rastgele cÃ¼mlelerde gÃ¶mmeyi test etme\n",
        "\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Rastgele eÄŸitim cÃ¼mlesi:\\n{random_training_sentence}\\n\")\n",
        "\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"GÃ¶mme sonrasÄ± cÃ¼mle:\\n{use_embedded_sentence[0][:30]} (kesilmiÅŸ Ã§Ä±ktÄ±)...\\n\")\n",
        "print(f\"GÃ¶mÃ¼lmÃ¼ÅŸ cÃ¼mlenin uzunluÄŸu:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "id": "HyKY8GNL-aKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e8723c-b76e-4e73-bce4-ea928df65849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rastgele eÄŸitim cÃ¼mlesi:\n",
            "we evaluated angiogenesis-targeted sunitinib therapy in a randomized , double-blind trial of metastatic castration-resistant prostate cancer ( mcrpc ) .\n",
            "\n",
            "GÃ¶mme sonrasÄ± cÃ¼mle:\n",
            "[-0.0332844   0.00323283 -0.07341916 -0.04258213 -0.04985864 -0.07613482\n",
            " -0.02224037 -0.04262499  0.03884448 -0.01723633  0.0887475  -0.06006488\n",
            "  0.01688014  0.08200955  0.05170288 -0.04839861 -0.08894092  0.05455948\n",
            "  0.04898502  0.00801988 -0.03343721  0.00720054 -0.03504387 -0.00383746\n",
            "  0.06791933 -0.03750411  0.02844876  0.00618231  0.05129638  0.06099223] (kesilmiÅŸ Ã§Ä±ktÄ±)...\n",
            "\n",
            "GÃ¶mÃ¼lmÃ¼ÅŸ cÃ¼mlenin uzunluÄŸu:\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daha Ã¶nce de belirttiÄŸimiz gibi, TensorFlow Hub'Ä±n Ã¶nceden eÄŸitilmiÅŸ USE modÃ¼lÃ¼, metnimizi bizim iÃ§in belirteÃ§lemeye Ã¶zen gÃ¶sterir ve 512 boyutlu bir gÃ¶mme vektÃ¶rÃ¼ Ã§Ä±karÄ±r."
      ],
      "metadata": {
        "id": "TzkJ03j3--BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorflow Hub'dan bir NLP Ã¶zellik Ã§Ä±karma modeli kullanÄ±mÄ±**\n",
        "- GiriÅŸler katman ÅŸeklinde Ã§Ã¼nkÃ¼ giriÅŸ ÅŸekli boÅŸ bir liste. SimgeleÅŸtirilmiÅŸ bir yerleÅŸtirme katmanÄ± oluÅŸturduÄŸumuzda, simge dÃ¼zeyinde bir yerleÅŸtirme var ve her token 128'e Ã§evirdik. Bu da tÃ¼m diziyi tek uzun vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rdÃ¼.\n",
        "- relu --> Lineer olmayan aktivasyon ...\n",
        "- Modeli iyileÅŸtirme yollarÄ±ndan birisi de araya katman koymaktÄ±r. Girdilerden gÃ¶mme oluÅŸturulabilir. GÃ¶mme arasÄ±na bir grup katman eklenebilir.\n",
        "- Deney yaptÄ±ÄŸÄ±mÄ±z iÃ§in bu Ã§alÄ±ÅŸmada bÃ¼yÃ¼k bir katman oluÅŸturmadÄ±k. KarmaÅŸÄ±klÄ±k her zaman arttÄ±rÄ±labilir.\n",
        "- EÄŸitilebilir parametreler yoÄŸun katmandadÄ±r. EÄŸitilebiliri aÃ§arsan modelin daha Ã§ok kalÄ±p bulmasÄ± gerektiÄŸi anlamÄ±na gelir.\n",
        "- Ã–zellik Ã§Ä±karmada katman sayÄ±sÄ± arttÄ±kÃ§a deney uzun sÃ¼rer. TÃ¼m parametreler dondurulmuÅŸ olduÄŸu iÃ§in hÄ±zlÄ± eÄŸitim oldu.\n"
      ],
      "metadata": {
        "id": "EOJkymuo_DJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "\n",
        "# Define the custom layer for the Universal Sentence Encoder\n",
        "class UniversalSentenceEncoderLayer(layers.Layer):\n",
        "    def __init__(self, hub_layer):\n",
        "        super().__init__()\n",
        "        self.encoder = hub_layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.encoder(inputs)\n",
        "\n",
        "use_layer = UniversalSentenceEncoderLayer(tf_hub_embedding_layer)\n",
        "\n",
        "# Create the model\n",
        "inputs = layers.Input(shape=(), dtype=tf.string)\n",
        "pretrained_embedding = use_layer(inputs)\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_USE_feature_extractor\")\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model_2.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "ywHdAJV3doAG",
        "outputId": "4533cb3d-b362-489b-9dd0-2f063dc36143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_2_USE_feature_extractor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2_USE_feature_extractor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m)                      â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ universal_sentence_encoder_layer_2   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mUniversalSentenceEncoderLayer\u001b[0m)      â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚          \u001b[38;5;34m65,664\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   â”‚             \u001b[38;5;34m645\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                      â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ universal_sentence_encoder_layer_2   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UniversalSentenceEncoderLayer</span>)      â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,309\u001b[0m (259.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,309</span> (259.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,309\u001b[0m (259.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,309</span> (259.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zellik Ã§Ä±karÄ±cÄ± modelini 3 dÃ¶nem iÃ§in uygun hale getirin\n",
        "model_2.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=valid_dataset,\n",
        "    validation_steps=int(0.1 * len(valid_dataset))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SydjPxThi8V9",
        "outputId": "e2ecf9cb-fc41-4ae9-bd81-ac81a88cfa5c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_49214[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-91-1a024b239fec>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_49214[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_49615]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-1a024b239fec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ã–zellik Ã§Ä±karÄ±cÄ± modelini 3 dÃ¶nem iÃ§in uygun hale getirin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_2.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_49214[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-91-1a024b239fec>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_49214[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_49615]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin Ã¶zetini kontrol ederek Ã§ok sayÄ±da toplam parametre olduÄŸunu gÃ¶rebiliriz, ancak bunlarÄ±n Ã§oÄŸu eÄŸitilemez. Bunun nedeni, USE Ã¶zellik Ã§Ä±karÄ±cÄ± katmanÄ±mÄ±zÄ± yerleÅŸtirdiÄŸimizde training=False'i ayarlamamÄ±zdÄ±r.\n",
        "\n",
        "Bu nedenle, modelimizi eÄŸittiÄŸimizde, yalnÄ±zca en iyi iki Ã§Ä±kÄ±ÅŸ katmanÄ± eÄŸitilecektir."
      ],
      "metadata": {
        "id": "vaLEK50lBShK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DoÄŸrulama veri kÃ¼mesinin tamamÄ±nÄ± deÄŸerlendirin\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "-cBt8TNc_gRj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "896f7c45-ba49-44fb-8468-13511e4fa1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_50115[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-92-80b67b28824a>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 433, in evaluate\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_50115[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_50496]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-80b67b28824a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# DoÄŸrulama veri kÃ¼mesinin tamamÄ±nÄ± deÄŸerlendirin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_50115[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-92-80b67b28824a>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 433, in evaluate\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_50115[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_50496]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zellik Ã§Ä±karma modeliyle tahminler yapÄ±n\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "id": "oV575nLT_gOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zellik Ã§Ä±karma modeliyle tahminleri sÄ±nÄ±flara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis = 1)\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "id": "VpvF9Oig_gHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DoÄŸrulama kÃ¼mesindeki TF Hub Ã¶nceden eÄŸitilmiÅŸ yerleÅŸtirme sonuÃ§larÄ±ndan sonuÃ§larÄ± hesaplayÄ±n\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "NgG6ck4b_f48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.9. Karakter DÃ¼zeyinde Conv1D Ä°le Modelleme ve DeÄŸerlendirme**"
      ],
      "metadata": {
        "id": "vLOtWFSJj5Ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medical Paper Abstracts makalesinde Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ±, modellerinin belirteÃ§ ve karakter gÃ¶mmelerinin bir karÄ±ÅŸÄ±mÄ±nÄ± kullandÄ±ÄŸÄ±ndan bahseder. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "Ã–zel bir belirteÃ§ gÃ¶mme ve Ã¶nceden eÄŸitilmiÅŸ bir belirteÃ§ gÃ¶mme ile modeller oluÅŸturduk, bir karakter gÃ¶mme kullanarak bir tane oluÅŸturmaya ne dersiniz?\n",
        "\n",
        "Bir karakter ve belirteÃ§ gÃ¶mme arasÄ±ndaki fark, karakter gÃ¶mmenin karakterlere bÃ¶lÃ¼nmÃ¼ÅŸ diziler kullanÄ±larak oluÅŸturulmasÄ±dÄ±r (Ã¶rneÄŸin, merhaba -> [h, e, l, l, o]), burada bir belirteÃ§ gÃ¶mme, belirteÃ§lere bÃ¶lÃ¼nmÃ¼ÅŸ diziler Ã¼zerinde oluÅŸturulur.\n",
        "\n",
        "BelirteÃ§ seviyesi, dizileri belirteÃ§lere (kelimelere) bÃ¶ler ve her birini gÃ¶mer, karakter gÃ¶mer, dizileri karakterlere bÃ¶ler ve her biri iÃ§in bir Ã¶zellik vektÃ¶rÃ¼ oluÅŸturur.\n",
        "\n",
        "TextVectorization sÄ±nÄ±fÄ±nÄ± kullanarak Ã¶nce dizilerimizi (karakterlere ayrÄ±ldÄ±ktan sonra) vektÃ¶rleÅŸtirerek ve ardÄ±ndan bu vektÃ¶rleÅŸtirilmiÅŸ dizileri bir GÃ¶mme katmanÄ±ndan geÃ§irerek karakter dÃ¼zeyinde bir gÃ¶mme oluÅŸturabiliriz.\n",
        "\n",
        "Dizilerimizi bir karakter dÃ¼zeyinde vektÃ¶rleÅŸtirmeden Ã¶nce onlarÄ± karakterlere ayÄ±rmamÄ±z gerekecek. Bunu yapmak iÃ§in bir iÅŸlev yazalÄ±m.\n",
        "\n",
        "- belirteÃ§ = token...\n",
        "- karakter embedding --> her bir hard feature vector'e dÃ¶nÃ¼ÅŸÃ¼r.\n",
        "- **YukarÄ±da oluÅŸturduÄŸumuz vektÃ¶rler kelime iÃ§indi. Bu Ã§alÄ±ÅŸma iÃ§in verileri karakter olarakbiÃ§imlendirme gerekli.**\n",
        "- Her karakteri, harfi bir tam sayÄ±ya dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r."
      ],
      "metadata": {
        "id": "okrK5qhkCwbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ¼mleleri karakterlere bÃ¶lme iÅŸlevi yapÄ±n\n",
        "def split_chars(text):\n",
        "  return\" \".join(list(text))\n",
        "\n",
        "# Karakter dÃ¼zeyinde olmayan diziyi karakterlere bÃ¶lmeyi test edin\n",
        "split_chars(random_training_sentence)"
      ],
      "metadata": {
        "id": "NHHfexcbDTtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "4c481759-7180-45be-e777-e6c54784269a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r e s u l t s   w e r e   r o b u s t   t o   e x t e n s i v e   s e n s i t i v i t y   a n a l y s e s   ,   i n c l u d i n g   v a r i a t i o n s   i n   c l o p i d o g r e l   c o s t   ,   e x c l u s i o n   o f   c o s t s   i n   e x t e n d e d   y e a r s   o f   l i f e   ,   a n d   a   r e c a l i b r a t e d   e s t i m a t e   o f   s u r v i v a l   r e f l e c t i n g   a   l o w e r   u n d e r l y i n g   m o r t a l i t y   r i s k   i n   t h e   u n i t e d   s t a t e s   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SÄ±ra dÃ¼zeyindeki verileri karakter dÃ¼zeyindeki veri bÃ¶lmelerine bÃ¶lme\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "metadata": {
        "id": "ubehHG1BDTq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3d6524-222c-408c-e02c-5f210fe3bf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ortalama karakter uzunluÄŸu nedir?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "id": "XK66ddldDTlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771f17c8-29a0-43c2-d6c5-f9d4060b3f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dizilerimizin karakter dÃ¼zeyinde daÄŸÄ±lÄ±mÄ±nÄ± kontrol edin\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "metadata": {
        "id": "ctl0cUqUDTjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "46074bab-fd86-4a99-f544-46519281247e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAGdCAYAAAD+JxxnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz6UlEQVR4nO3df3BU9b3/8VdCyA/Q3fCjybI1QG7L5UdJQYmEINI67BBLtDeVtgRTpJrC1SZKDPJLMGKrDcZrBfxBSntbmCkUZEZSDRhMgxKVGCAQIUginSKgdBP7DdmVKBDI+f7h5FwWEMRuiMnn+Zg5M+75vM/nfD6fMdnXnJxzCLEsyxIAAICBQjt6AAAAAB2FIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMFZYRw/g66y1tVXHjh3Ttddeq5CQkI4eDgAA+BIsy9Inn3wit9ut0NBLX/MhCF3CsWPHFBcX19HDAAAAX8HRo0d13XXXXbKGIHQJ1157raTPF9LhcHTwaAAAwJfh9/sVFxdnf49fCkHoEtr+HOZwOAhCAAB0Ml/mthZulgYAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgrCsOQuXl5br99tvldrsVEhKioqKiL6y99957FRISoqVLlwbsb2xsVEZGhhwOh6Kjo5WZmakTJ04E1Ozdu1c333yzIiMjFRcXp4KCggv637Bhg4YMGaLIyEglJCRo8+bNAe2WZSkvL0/9+vVTVFSUPB6PDh48eKVTBgAAXVTYlR7Q3NysESNG6J577tEdd9zxhXUbN27UO++8I7fbfUFbRkaG/vnPf6q0tFQtLS26++67NXPmTK1du1aS5Pf7NXHiRHk8HhUWFmrfvn265557FB0drZkzZ0qStm/frqlTpyo/P1+33Xab1q5dq7S0NO3evVvDhw+XJBUUFGj58uVavXq14uPj9cgjjyglJUXvvfeeIiMjr3TqQTdw/qaOHkKH+mBJakcPAQBguBDLsqyvfHBIiDZu3Ki0tLSA/R999JGSkpK0ZcsWpaamKicnRzk5OZKkAwcOaNiwYdq5c6cSExMlSSUlJZo0aZI+/PBDud1urVixQgsXLpTX61V4eLgkaf78+SoqKlJtba0kacqUKWpublZxcbF93jFjxmjkyJEqLCyUZVlyu92aPXu2HnroIUmSz+dTbGysVq1apfT09MvOz+/3y+l0yufzyeFwfNVl+kIEIYIQACD4ruT7O+j3CLW2tmratGmaM2eOvvOd71zQXlFRoejoaDsESZLH41FoaKgqKyvtmvHjx9shSJJSUlJUV1en48eP2zUejyeg75SUFFVUVEiSDh06JK/XG1DjdDqVlJRk15zv1KlT8vv9ARsAAOi6gh6EnnzySYWFhemBBx64aLvX61VMTEzAvrCwMPXu3Vter9euiY2NDahp+3y5mnPbzz3uYjXny8/Pl9PptLe4uLjLzhcAAHReQQ1CVVVVWrZsmVatWqWQkJBgdn1VLFiwQD6fz96OHj3a0UMCAADtKKhB6M0331RDQ4P69++vsLAwhYWF6fDhw5o9e7YGDhwoSXK5XGpoaAg47syZM2psbJTL5bJr6uvrA2raPl+u5tz2c4+7WM35IiIi5HA4AjYAANB1BTUITZs2TXv37lV1dbW9ud1uzZkzR1u2bJEkJScnq6mpSVVVVfZxW7duVWtrq5KSkuya8vJytbS02DWlpaUaPHiwevXqZdeUlZUFnL+0tFTJycmSpPj4eLlcroAav9+vyspKuwYAAJjtih+fP3HihP7+97/bnw8dOqTq6mr17t1b/fv3V58+fQLqu3fvLpfLpcGDB0uShg4dqltvvVUzZsxQYWGhWlpalJ2drfT0dPtR+zvvvFOPPfaYMjMzNW/ePNXU1GjZsmV65pln7H5nzZql733ve3r66aeVmpqqdevWadeuXVq5cqWkz59oy8nJ0eOPP65BgwbZj8+73e4LnnIDAABmuuIgtGvXLt1yyy3259zcXEnS9OnTtWrVqi/Vx5o1a5Sdna0JEyYoNDRUkydP1vLly+12p9Op1157TVlZWRo1apT69u2rvLw8+x1CkjR27FitXbtWixYt0sMPP6xBgwapqKjIfoeQJM2dO1fNzc2aOXOmmpqaNG7cOJWUlHwt3iEEAAA63r/1HqGujvcItS/eIwQAaA8d+h4hAACAzoIgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGCsKw5C5eXluv322+V2uxUSEqKioiK7raWlRfPmzVNCQoJ69uwpt9utu+66S8eOHQvoo7GxURkZGXI4HIqOjlZmZqZOnDgRULN3717dfPPNioyMVFxcnAoKCi4Yy4YNGzRkyBBFRkYqISFBmzdvDmi3LEt5eXnq16+foqKi5PF4dPDgwSudMgAA6KKuOAg1NzdrxIgRev755y9o+/TTT7V792498sgj2r17t1566SXV1dXphz/8YUBdRkaG9u/fr9LSUhUXF6u8vFwzZ8602/1+vyZOnKgBAwaoqqpKTz31lBYvXqyVK1faNdu3b9fUqVOVmZmpPXv2KC0tTWlpaaqpqbFrCgoKtHz5chUWFqqyslI9e/ZUSkqKTp48eaXTBgAAXVCIZVnWVz44JEQbN25UWlraF9bs3LlTo0eP1uHDh9W/f38dOHBAw4YN086dO5WYmChJKikp0aRJk/Thhx/K7XZrxYoVWrhwobxer8LDwyVJ8+fPV1FRkWprayVJU6ZMUXNzs4qLi+1zjRkzRiNHjlRhYaEsy5Lb7dbs2bP10EMPSZJ8Pp9iY2O1atUqpaenX3Z+fr9fTqdTPp9PDofjqy7TFxo4f1PQ++xMPliS2tFDAAB0QVfy/d3u9wj5fD6FhIQoOjpaklRRUaHo6Gg7BEmSx+NRaGioKisr7Zrx48fbIUiSUlJSVFdXp+PHj9s1Ho8n4FwpKSmqqKiQJB06dEherzegxul0Kikpya4536lTp+T3+wM2AADQdbVrEDp58qTmzZunqVOn2onM6/UqJiYmoC4sLEy9e/eW1+u1a2JjYwNq2j5frubc9nOPu1jN+fLz8+V0Ou0tLi7uiucMAAA6j3YLQi0tLfrpT38qy7K0YsWK9jpNUC1YsEA+n8/ejh492tFDAgAA7SisPTptC0GHDx/W1q1bA/4+53K51NDQEFB/5swZNTY2yuVy2TX19fUBNW2fL1dzbnvbvn79+gXUjBw58qLjjoiIUERExJVOFwAAdFJBvyLUFoIOHjyov/3tb+rTp09Ae3JyspqamlRVVWXv27p1q1pbW5WUlGTXlJeXq6Wlxa4pLS3V4MGD1atXL7umrKwsoO/S0lIlJydLkuLj4+VyuQJq/H6/Kisr7RoAAGC2Kw5CJ06cUHV1taqrqyV9flNydXW1jhw5opaWFv34xz/Wrl27tGbNGp09e1Zer1der1enT5+WJA0dOlS33nqrZsyYoR07dujtt99Wdna20tPT5Xa7JUl33nmnwsPDlZmZqf3792v9+vVatmyZcnNz7XHMmjVLJSUlevrpp1VbW6vFixdr165dys7OlvT5E205OTl6/PHH9fLLL2vfvn2666675Ha7L/mUGwAAMMcVPz7/xhtv6JZbbrlg//Tp07V48WLFx8df9LjXX39d3//+9yV9/kLF7OxsvfLKKwoNDdXkyZO1fPlyXXPNNXb93r17lZWVpZ07d6pv3766//77NW/evIA+N2zYoEWLFumDDz7QoEGDVFBQoEmTJtntlmXp0Ucf1cqVK9XU1KRx48bphRde0H/+539+qbny+Hz74vF5AEB7uJLv73/rPUJdHUGofRGEAADt4Wv1HiEAAICvK4IQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLGuOAiVl5fr9ttvl9vtVkhIiIqKigLaLctSXl6e+vXrp6ioKHk8Hh08eDCgprGxURkZGXI4HIqOjlZmZqZOnDgRULN3717dfPPNioyMVFxcnAoKCi4Yy4YNGzRkyBBFRkYqISFBmzdvvuKxAAAAc11xEGpubtaIESP0/PPPX7S9oKBAy5cvV2FhoSorK9WzZ0+lpKTo5MmTdk1GRob279+v0tJSFRcXq7y8XDNnzrTb/X6/Jk6cqAEDBqiqqkpPPfWUFi9erJUrV9o127dv19SpU5WZmak9e/YoLS1NaWlpqqmpuaKxAAAAc4VYlmV95YNDQrRx40alpaVJ+vwKjNvt1uzZs/XQQw9Jknw+n2JjY7Vq1Sqlp6frwIEDGjZsmHbu3KnExERJUklJiSZNmqQPP/xQbrdbK1as0MKFC+X1ehUeHi5Jmj9/voqKilRbWytJmjJlipqbm1VcXGyPZ8yYMRo5cqQKCwu/1Fgux+/3y+l0yufzyeFwfNVl+kID528Kep+dyQdLUjt6CACALuhKvr+Deo/QoUOH5PV65fF47H1Op1NJSUmqqKiQJFVUVCg6OtoOQZLk8XgUGhqqyspKu2b8+PF2CJKklJQU1dXV6fjx43bNuedpq2k7z5cZy/lOnTolv98fsAEAgK4rqEHI6/VKkmJjYwP2x8bG2m1er1cxMTEB7WFhYerdu3dAzcX6OPccX1RzbvvlxnK+/Px8OZ1Oe4uLi/sSswYAAJ0VT42dY8GCBfL5fPZ29OjRjh4SAABoR0ENQi6XS5JUX18fsL++vt5uc7lcamhoCGg/c+aMGhsbA2ou1se55/iimnPbLzeW80VERMjhcARsAACg6wpqEIqPj5fL5VJZWZm9z+/3q7KyUsnJyZKk5ORkNTU1qaqqyq7ZunWrWltblZSUZNeUl5erpaXFriktLdXgwYPVq1cvu+bc87TVtJ3ny4wFAACY7YqD0IkTJ1RdXa3q6mpJn9+UXF1drSNHjigkJEQ5OTl6/PHH9fLLL2vfvn2666675Ha77SfLhg4dqltvvVUzZszQjh079Pbbbys7O1vp6elyu92SpDvvvFPh4eHKzMzU/v37tX79ei1btky5ubn2OGbNmqWSkhI9/fTTqq2t1eLFi7Vr1y5lZ2dL0pcaCwAAMFvYlR6wa9cu3XLLLfbntnAyffp0rVq1SnPnzlVzc7NmzpyppqYmjRs3TiUlJYqMjLSPWbNmjbKzszVhwgSFhoZq8uTJWr58ud3udDr12muvKSsrS6NGjVLfvn2Vl5cX8K6hsWPHau3atVq0aJEefvhhDRo0SEVFRRo+fLhd82XGAgAAzPVvvUeoq+M9Qu2L9wgBANpDh71HCAAAoDMhCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYK+hB6OzZs3rkkUcUHx+vqKgofetb39Kvf/1rWZZl11iWpby8PPXr109RUVHyeDw6ePBgQD+NjY3KyMiQw+FQdHS0MjMzdeLEiYCavXv36uabb1ZkZKTi4uJUUFBwwXg2bNigIUOGKDIyUgkJCdq8eXOwpwwAADqpoAehJ598UitWrNBzzz2nAwcO6Mknn1RBQYGeffZZu6agoEDLly9XYWGhKisr1bNnT6WkpOjkyZN2TUZGhvbv36/S0lIVFxervLxcM2fOtNv9fr8mTpyoAQMGqKqqSk899ZQWL16slStX2jXbt2/X1KlTlZmZqT179igtLU1paWmqqakJ9rQBAEAnFGKde6kmCG677TbFxsbqf//3f+19kydPVlRUlP785z/Lsiy53W7Nnj1bDz30kCTJ5/MpNjZWq1atUnp6ug4cOKBhw4Zp586dSkxMlCSVlJRo0qRJ+vDDD+V2u7VixQotXLhQXq9X4eHhkqT58+erqKhItbW1kqQpU6aoublZxcXF9ljGjBmjkSNHqrCw8LJz8fv9cjqd8vl8cjgcQVujNgPnbwp6n53JB0tSO3oIAIAu6Eq+v4N+RWjs2LEqKyvT+++/L0l699139dZbb+kHP/iBJOnQoUPyer3yeDz2MU6nU0lJSaqoqJAkVVRUKDo62g5BkuTxeBQaGqrKykq7Zvz48XYIkqSUlBTV1dXp+PHjds2552mraTvP+U6dOiW/3x+wAQCAriss2B3Onz9ffr9fQ4YMUbdu3XT27Fk98cQTysjIkCR5vV5JUmxsbMBxsbGxdpvX61VMTEzgQMPC1Lt374Ca+Pj4C/poa+vVq5e8Xu8lz3O+/Px8PfbYY19l2gAAoBMK+hWhF198UWvWrNHatWu1e/durV69Wv/zP/+j1atXB/tUQbdgwQL5fD57O3r0aEcPCQAAtKOgXxGaM2eO5s+fr/T0dElSQkKCDh8+rPz8fE2fPl0ul0uSVF9fr379+tnH1dfXa+TIkZIkl8ulhoaGgH7PnDmjxsZG+3iXy6X6+vqAmrbPl6tpaz9fRESEIiIivsq0AQBAJxT0K0KffvqpQkMDu+3WrZtaW1slSfHx8XK5XCorK7Pb/X6/KisrlZycLElKTk5WU1OTqqqq7JqtW7eqtbVVSUlJdk15eblaWlrsmtLSUg0ePFi9evWya849T1tN23kAAIDZgh6Ebr/9dj3xxBPatGmTPvjgA23cuFG//e1v9aMf/UiSFBISopycHD3++ON6+eWXtW/fPt11111yu91KS0uTJA0dOlS33nqrZsyYoR07dujtt99Wdna20tPT5Xa7JUl33nmnwsPDlZmZqf3792v9+vVatmyZcnNz7bHMmjVLJSUlevrpp1VbW6vFixdr165dys7ODva0AQBAJxT0P409++yzeuSRR/TLX/5SDQ0Ncrvd+u///m/l5eXZNXPnzlVzc7NmzpyppqYmjRs3TiUlJYqMjLRr1qxZo+zsbE2YMEGhoaGaPHmyli9fbrc7nU699tprysrK0qhRo9S3b1/l5eUFvGto7NixWrt2rRYtWqSHH35YgwYNUlFRkYYPHx7saQMAgE4o6O8R6kp4j1D74j1CAID20KHvEQIAAOgsCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjNUuQeijjz7Sz372M/Xp00dRUVFKSEjQrl277HbLspSXl6d+/fopKipKHo9HBw8eDOijsbFRGRkZcjgcio6OVmZmpk6cOBFQs3fvXt18882KjIxUXFycCgoKLhjLhg0bNGTIEEVGRiohIUGbN29ujykDAIBOKOhB6Pjx47rpppvUvXt3vfrqq3rvvff09NNPq1evXnZNQUGBli9frsLCQlVWVqpnz55KSUnRyZMn7ZqMjAzt379fpaWlKi4uVnl5uWbOnGm3+/1+TZw4UQMGDFBVVZWeeuopLV68WCtXrrRrtm/frqlTpyozM1N79uxRWlqa0tLSVFNTE+xpAwCATijEsiwrmB3Onz9fb7/9tt58882LtluWJbfbrdmzZ+uhhx6SJPl8PsXGxmrVqlVKT0/XgQMHNGzYMO3cuVOJiYmSpJKSEk2aNEkffvih3G63VqxYoYULF8rr9So8PNw+d1FRkWprayVJU6ZMUXNzs4qLi+3zjxkzRiNHjlRhYeFl5+L3++V0OuXz+eRwOP6tdbmYgfM3Bb3PzuSDJakdPQQAQBd0Jd/fQb8i9PLLLysxMVE/+clPFBMTo+uvv16///3v7fZDhw7J6/XK4/HY+5xOp5KSklRRUSFJqqioUHR0tB2CJMnj8Sg0NFSVlZV2zfjx4+0QJEkpKSmqq6vT8ePH7Zpzz9NW03YeAABgtqAHoX/84x9asWKFBg0apC1btui+++7TAw88oNWrV0uSvF6vJCk2NjbguNjYWLvN6/UqJiYmoD0sLEy9e/cOqLlYH+ee44tq2trPd+rUKfn9/oANAAB0XWHB7rC1tVWJiYn6zW9+I0m6/vrrVVNTo8LCQk2fPj3Ypwuq/Px8PfbYYx09DAAAcJUE/YpQv379NGzYsIB9Q4cO1ZEjRyRJLpdLklRfXx9QU19fb7e5XC41NDQEtJ85c0aNjY0BNRfr49xzfFFNW/v5FixYIJ/PZ29Hjx79cpMGAACdUtCD0E033aS6urqAfe+//74GDBggSYqPj5fL5VJZWZnd7vf7VVlZqeTkZElScnKympqaVFVVZdds3bpVra2tSkpKsmvKy8vV0tJi15SWlmrw4MH2E2rJyckB52mraTvP+SIiIuRwOAI2AADQdQU9CD344IN655139Jvf/EZ///vftXbtWq1cuVJZWVmSpJCQEOXk5Ojxxx/Xyy+/rH379umuu+6S2+1WWlqapM+vIN16662aMWOGduzYobffflvZ2dlKT0+X2+2WJN15550KDw9XZmam9u/fr/Xr12vZsmXKzc21xzJr1iyVlJTo6aefVm1trRYvXqxdu3YpOzs72NMGAACdUNDvEbrxxhu1ceNGLViwQL/61a8UHx+vpUuXKiMjw66ZO3eumpubNXPmTDU1NWncuHEqKSlRZGSkXbNmzRplZ2drwoQJCg0N1eTJk7V8+XK73el06rXXXlNWVpZGjRqlvn37Ki8vL+BdQ2PHjtXatWu1aNEiPfzwwxo0aJCKioo0fPjwYE8bAAB0QkF/j1BXwnuE2hfvEQIAtIcOfY8QAABAZ0EQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADBWuwehJUuWKCQkRDk5Ofa+kydPKisrS3369NE111yjyZMnq76+PuC4I0eOKDU1VT169FBMTIzmzJmjM2fOBNS88cYbuuGGGxQREaFvf/vbWrVq1QXnf/755zVw4EBFRkYqKSlJO3bsaI9pAgCATqhdg9DOnTv1u9/9Tt/97ncD9j/44IN65ZVXtGHDBm3btk3Hjh3THXfcYbefPXtWqampOn36tLZv367Vq1dr1apVysvLs2sOHTqk1NRU3XLLLaqurlZOTo5+8YtfaMuWLXbN+vXrlZubq0cffVS7d+/WiBEjlJKSooaGhvacNgAA6CRCLMuy2qPjEydO6IYbbtALL7ygxx9/XCNHjtTSpUvl8/n0jW98Q2vXrtWPf/xjSVJtba2GDh2qiooKjRkzRq+++qpuu+02HTt2TLGxsZKkwsJCzZs3Tx9//LHCw8M1b948bdq0STU1NfY509PT1dTUpJKSEklSUlKSbrzxRj333HOSpNbWVsXFxen+++/X/PnzLzsHv98vp9Mpn88nh8MR7CXSwPmbgt5nZ/LBktSOHgIAoAu6ku/vdrsilJWVpdTUVHk8noD9VVVVamlpCdg/ZMgQ9e/fXxUVFZKkiooKJSQk2CFIklJSUuT3+7V//3675vy+U1JS7D5Onz6tqqqqgJrQ0FB5PB67BgAAmC2sPTpdt26ddu/erZ07d17Q5vV6FR4erujo6ID9sbGx8nq9ds25Iaitva3tUjV+v1+fffaZjh8/rrNnz160pra29qLjPnXqlE6dOmV/9vv9X2K2AACgswr6FaGjR49q1qxZWrNmjSIjI4PdfbvKz8+X0+m0t7i4uI4eEgAAaEdBD0JVVVVqaGjQDTfcoLCwMIWFhWnbtm1avny5wsLCFBsbq9OnT6upqSnguPr6erlcLkmSy+W64Cmyts+Xq3E4HIqKilLfvn3VrVu3i9a09XG+BQsWyOfz2dvRo0e/8joAAICvv6AHoQkTJmjfvn2qrq62t8TERGVkZNj/3b17d5WVldnH1NXV6ciRI0pOTpYkJScna9++fQFPd5WWlsrhcGjYsGF2zbl9tNW09REeHq5Ro0YF1LS2tqqsrMyuOV9ERIQcDkfABgAAuq6g3yN07bXXavjw4QH7evbsqT59+tj7MzMzlZubq969e8vhcOj+++9XcnKyxowZI0maOHGihg0bpmnTpqmgoEBer1eLFi1SVlaWIiIiJEn33nuvnnvuOc2dO1f33HOPtm7dqhdffFGbNv3fk1i5ubmaPn26EhMTNXr0aC1dulTNzc26++67gz1tAADQCbXLzdKX88wzzyg0NFSTJ0/WqVOnlJKSohdeeMFu79atm4qLi3XfffcpOTlZPXv21PTp0/WrX/3KromPj9emTZv04IMPatmyZbruuuv0hz/8QSkpKXbNlClT9PHHHysvL09er1cjR45USUnJBTdQAwAAM7Xbe4S6At4j1L54jxAAoD18Ld4jBAAA8HXXIX8aAySuiElcFQOAjsYVIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGCnoQys/P14033qhrr71WMTExSktLU11dXUDNyZMnlZWVpT59+uiaa67R5MmTVV9fH1Bz5MgRpaamqkePHoqJidGcOXN05syZgJo33nhDN9xwgyIiIvTtb39bq1atumA8zz//vAYOHKjIyEglJSVpx44dwZ4yAADopIIehLZt26asrCy98847Ki0tVUtLiyZOnKjm5ma75sEHH9Qrr7yiDRs2aNu2bTp27JjuuOMOu/3s2bNKTU3V6dOntX37dq1evVqrVq1SXl6eXXPo0CGlpqbqlltuUXV1tXJycvSLX/xCW7ZssWvWr1+v3NxcPfroo9q9e7dGjBihlJQUNTQ0BHvaAACgEwqxLMtqzxN8/PHHiomJ0bZt2zR+/Hj5fD594xvf0Nq1a/XjH/9YklRbW6uhQ4eqoqJCY8aM0auvvqrbbrtNx44dU2xsrCSpsLBQ8+bN08cff6zw8HDNmzdPmzZtUk1NjX2u9PR0NTU1qaSkRJKUlJSkG2+8Uc8995wkqbW1VXFxcbr//vs1f/78y47d7/fL6XTK5/PJ4XAEe2k0cP6moPeJzuWDJakdPQQA6HKu5Pu73e8R8vl8kqTevXtLkqqqqtTS0iKPx2PXDBkyRP3791dFRYUkqaKiQgkJCXYIkqSUlBT5/X7t37/frjm3j7aatj5Onz6tqqqqgJrQ0FB5PB675nynTp2S3+8P2AAAQNfVrkGotbVVOTk5uummmzR8+HBJktfrVXh4uKKjowNqY2Nj5fV67ZpzQ1Bbe1vbpWr8fr8+++wz/etf/9LZs2cvWtPWx/ny8/PldDrtLS4u7qtNHAAAdArtGoSysrJUU1OjdevWtedpgmbBggXy+Xz2dvTo0Y4eEgAAaEdh7dVxdna2iouLVV5eruuuu87e73K5dPr0aTU1NQVcFaqvr5fL5bJrzn+6q+2psnNrzn/SrL6+Xg6HQ1FRUerWrZu6det20Zq2Ps4XERGhiIiIrzZhAADQ6QT9ipBlWcrOztbGjRu1detWxcfHB7SPGjVK3bt3V1lZmb2vrq5OR44cUXJysiQpOTlZ+/btC3i6q7S0VA6HQ8OGDbNrzu2jraatj/DwcI0aNSqgprW1VWVlZXYNAAAwW9CvCGVlZWnt2rX661//qmuvvda+H8fpdCoqKkpOp1OZmZnKzc1V79695XA4dP/99ys5OVljxoyRJE2cOFHDhg3TtGnTVFBQIK/Xq0WLFikrK8u+YnPvvffqueee09y5c3XPPfdo69atevHFF7Vp0/89iZWbm6vp06crMTFRo0eP1tKlS9Xc3Ky777472NMGAACdUNCD0IoVKyRJ3//+9wP2/+lPf9LPf/5zSdIzzzyj0NBQTZ48WadOnVJKSopeeOEFu7Zbt24qLi7Wfffdp+TkZPXs2VPTp0/Xr371K7smPj5emzZt0oMPPqhly5bpuuuu0x/+8AelpKTYNVOmTNHHH3+svLw8eb1ejRw5UiUlJRfcQA0AAMzU7u8R6sx4jxDaG+8RAoDg+1q9RwgAAODriiAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAwFkEIAAAYiyAEAACMRRACAADGIggBAABjEYQAAICxCEIAAMBYBCEAAGAsghAAADAWQQgAABiLIAQAAIxFEAIAAMYiCAEAAGMRhAAAgLEIQgAAwFgEIQAAYKywjh7A1fD888/rqaeektfr1YgRI/Tss89q9OjRHT0sQAPnb+roIXSoD5akdvQQABiuy18RWr9+vXJzc/Xoo49q9+7dGjFihFJSUtTQ0NDRQwMAAB2syweh3/72t5oxY4buvvtuDRs2TIWFherRo4f++Mc/dvTQAABAB+vSfxo7ffq0qqqqtGDBAntfaGioPB6PKioqLqg/deqUTp06ZX/2+XySJL/f3y7jaz31abv0C3QW7fWzBcBsbb9bLMu6bG2XDkL/+te/dPbsWcXGxgbsj42NVW1t7QX1+fn5euyxxy7YHxcX125jBEzmXNrRIwDQlX3yySdyOp2XrOnSQehKLViwQLm5ufbn1tZWNTY2qk+fPgoJCQnqufx+v+Li4nT06FE5HI6g9t1ZsAasgcQaSKyBxBpIrIEUvDWwLEuffPKJ3G73ZWu7dBDq27evunXrpvr6+oD99fX1crlcF9RHREQoIiIiYF90dHR7DlEOh8PY/+HbsAasgcQaSKyBxBpIrIEUnDW43JWgNl36Zunw8HCNGjVKZWVl9r7W1laVlZUpOTm5A0cGAAC+Drr0FSFJys3N1fTp05WYmKjRo0dr6dKlam5u1t13393RQwMAAB2sywehKVOm6OOPP1ZeXp68Xq9GjhypkpKSC26gvtoiIiL06KOPXvCnOJOwBqyBxBpIrIHEGkisgdQxaxBifZlnywAAALqgLn2PEAAAwKUQhAAAgLEIQgAAwFgEIQAAYCyCUAd4/vnnNXDgQEVGRiopKUk7duzo6CEFTX5+vm688UZde+21iomJUVpamurq6gJqTp48qaysLPXp00fXXHONJk+efMFLL48cOaLU1FT16NFDMTExmjNnjs6cOXM1pxIUS5YsUUhIiHJycux9psz/o48+0s9+9jP16dNHUVFRSkhI0K5du+x2y7KUl5enfv36KSoqSh6PRwcPHgzoo7GxURkZGXI4HIqOjlZmZqZOnDhxtafylZw9e1aPPPKI4uPjFRUVpW9961v69a9/HfBvH3W1NSgvL9ftt98ut9utkJAQFRUVBbQHa7579+7VzTffrMjISMXFxamgoKC9p/alXWoNWlpaNG/ePCUkJKhnz55yu9266667dOzYsYA+uvIanO/ee+9VSEiIli5dGrD/qq6Bhatq3bp1Vnh4uPXHP/7R2r9/vzVjxgwrOjraqq+v7+ihBUVKSor1pz/9yaqpqbGqq6utSZMmWf3797dOnDhh19x7771WXFycVVZWZu3atcsaM2aMNXbsWLv9zJkz1vDhwy2Px2Pt2bPH2rx5s9W3b19rwYIFHTGlr2zHjh3WwIEDre9+97vWrFmz7P0mzL+xsdEaMGCA9fOf/9yqrKy0/vGPf1hbtmyx/v73v9s1S5YssZxOp1VUVGS9++671g9/+EMrPj7e+uyzz+yaW2+91RoxYoT1zjvvWG+++ab17W9/25o6dWpHTOmKPfHEE1afPn2s4uJi69ChQ9aGDRusa665xlq2bJld09XWYPPmzdbChQutl156yZJkbdy4MaA9GPP1+XxWbGyslZGRYdXU1Fh/+ctfrKioKOt3v/vd1ZrmJV1qDZqamiyPx2OtX7/eqq2ttSoqKqzRo0dbo0aNCuijK6/BuV566SVrxIgRltvttp555pmAtqu5BgShq2z06NFWVlaW/fns2bOW2+228vPzO3BU7aehocGSZG3bts2yrM9/EXTv3t3asGGDXXPgwAFLklVRUWFZ1uc/RKGhoZbX67VrVqxYYTkcDuvUqVNXdwJf0SeffGINGjTIKi0ttb73ve/ZQciU+c+bN88aN27cF7a3trZaLpfLeuqpp+x9TU1NVkREhPWXv/zFsizLeu+99yxJ1s6dO+2aV1991QoJCbE++uij9ht8kKSmplr33HNPwL477rjDysjIsCyr66/B+V+AwZrvCy+8YPXq1SvgZ2HevHnW4MGD23lGV+5SIaDNjh07LEnW4cOHLcsyZw0+/PBD65vf/KZVU1NjDRgwICAIXe014E9jV9Hp06dVVVUlj8dj7wsNDZXH41FFRUUHjqz9+Hw+SVLv3r0lSVVVVWppaQlYgyFDhqh///72GlRUVCghISHgpZcpKSny+/3av3//VRz9V5eVlaXU1NSAeUrmzP/ll19WYmKifvKTnygmJkbXX3+9fv/739vthw4dktfrDVgHp9OppKSkgHWIjo5WYmKiXePxeBQaGqrKysqrN5mvaOzYsSorK9P7778vSXr33Xf11ltv6Qc/+IEkM9bgXMGab0VFhcaPH6/w8HC7JiUlRXV1dTp+/PhVmk3w+Hw+hYSE2P+upQlr0NraqmnTpmnOnDn6zne+c0H71V4DgtBV9K9//Utnz5694K3WsbGx8nq9HTSq9tPa2qqcnBzddNNNGj58uCTJ6/UqPDz8gn/M9tw18Hq9F12jtravu3Xr1mn37t3Kz8+/oM2E+UvSP/7xD61YsUKDBg3Sli1bdN999+mBBx7Q6tWrJf3fPC71s+D1ehUTExPQHhYWpt69e3eKdZg/f77S09M1ZMgQde/eXddff71ycnKUkZEhyYw1OFew5tsVfj7anDx5UvPmzdPUqVPtf2DUhDV48sknFRYWpgceeOCi7Vd7Dbr8P7GBjpOVlaWamhq99dZbHT2Uq+bo0aOaNWuWSktLFRkZ2dHD6TCtra1KTEzUb37zG0nS9ddfr5qaGhUWFmr69OkdPLqr48UXX9SaNWu0du1afec731F1dbVycnLkdruNWQN8sZaWFv30pz+VZVlasWJFRw/nqqmqqtKyZcu0e/duhYSEdPRwJHFF6Krq27evunXrdsETQvX19XK5XB00qvaRnZ2t4uJivf7667ruuuvs/S6XS6dPn1ZTU1NA/blr4HK5LrpGbW1fZ1VVVWpoaNANN9ygsLAwhYWFadu2bVq+fLnCwsIUGxvbpeffpl+/fho2bFjAvqFDh+rIkSOS/m8el/pZcLlcamhoCGg/c+aMGhsbO8U6zJkzx74qlJCQoGnTpunBBx+0rxSasAbnCtZ8u8LPR1sIOnz4sEpLS+2rQVLXX4M333xTDQ0N6t+/v/078vDhw5o9e7YGDhwo6eqvAUHoKgoPD9eoUaNUVlZm72ttbVVZWZmSk5M7cGTBY1mWsrOztXHjRm3dulXx8fEB7aNGjVL37t0D1qCurk5Hjhyx1yA5OVn79u0L+EFo+2Vx/pfr182ECRO0b98+VVdX21tiYqIyMjLs/+7K829z0003XfDahPfff18DBgyQJMXHx8vlcgWsg9/vV2VlZcA6NDU1qaqqyq7ZunWrWltblZSUdBVm8e/59NNPFRoa+Cu2W7duam1tlWTGGpwrWPNNTk5WeXm5Wlpa7JrS0lINHjxYvXr1ukqz+eraQtDBgwf1t7/9TX369Alo7+prMG3aNO3duzfgd6Tb7dacOXO0ZcsWSR2wBld8ezX+LevWrbMiIiKsVatWWe+99541c+ZMKzo6OuAJoc7svvvus5xOp/XGG29Y//znP+3t008/tWvuvfdeq3///tbWrVutXbt2WcnJyVZycrLd3vb4+MSJE63q6mqrpKTE+sY3vtGpHh8/17lPjVmWGfPfsWOHFRYWZj3xxBPWwYMHrTVr1lg9evSw/vznP9s1S5YssaKjo62//vWv1t69e63/+q//uuij1Ndff71VWVlpvfXWW9agQYO+to+On2/69OnWN7/5Tfvx+Zdeesnq27evNXfuXLumq63BJ598Yu3Zs8fas2ePJcn67W9/a+3Zs8d+IioY821qarJiY2OtadOmWTU1Nda6deusHj16fG0eHb/UGpw+fdr64Q9/aF133XVWdXV1wO/Ic59+6sprcDHnPzVmWVd3DQhCHeDZZ5+1+vfvb4WHh1ujR4+23nnnnY4eUtBIuuj2pz/9ya757LPPrF/+8pdWr169rB49elg/+tGPrH/+858B/XzwwQfWD37wAysqKsrq27evNXv2bKulpeUqzyY4zg9Cpsz/lVdesYYPH25FRERYQ4YMsVauXBnQ3traaj3yyCNWbGysFRERYU2YMMGqq6sLqPl//+//WVOnTrWuueYay+FwWHfffbf1ySefXM1pfGV+v9+aNWuW1b9/fysyMtL6j//4D2vhwoUBX3hdbQ1ef/31i/78T58+3bKs4M333XfftcaNG2dFRERY3/zmN60lS5ZcrSle1qXW4NChQ1/4O/L111+3++jKa3AxFwtCV3MNQizrnNecAgAAGIR7hAAAgLEIQgAAwFgEIQAAYCyCEAAAMBZBCAAAGIsgBAAAjEUQAgAAxiIIAQAAYxGEAACAsQhCAADAWAQhAABgLIIQAAAw1v8HDbjRMJahj4MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hangi karakter uzunluÄŸunun dizilerin %95'ini kapsadÄ±ÄŸÄ±nÄ± bulun\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "id": "rBNo-3h2DTgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f497a4a-95d3-48ab-c27f-c554076cc669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BÃ¶ylece dizilerin %95'ini kapsayan dizi uzunluÄŸunu biliyoruz, bunu TextVectorization katmanÄ±mÄ±zda output_sequence_length parametresi olarak kullanacaÄŸÄ±z.\n",
        "\n",
        "ğŸ”‘ Not: En uygun output_sequence_length'in ne olmasÄ± gerektiÄŸini bulmak iÃ§in burada deney yapabilirsiniz, belki de ortalama sonuÃ§larÄ± %95 yÃ¼zdelik dilim kullanmak kadar iyi sonuÃ§lar elde edebilirsiniz.\n",
        "\n",
        "Max_tokens'i (dizilerimizdeki farklÄ± karakterlerin toplam sayÄ±sÄ±) 28, baÅŸka bir deyiÅŸle, alfabenin 26 harfi + boÅŸluk + OOV (kelime daÄŸarcÄ±ÄŸÄ± dÄ±ÅŸÄ±nda veya bilinmeyen) belirteÃ§leri olarak ayarlayacaÄŸÄ±z."
      ],
      "metadata": {
        "id": "Gj_nX7_w1JHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter dÃ¼zeyinde yerleÅŸtirme iÃ§in tÃ¼m klavye karakterlerini alÄ±n\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet\n",
        "\n",
        "# ascii --> tÃ¼m kÃ¼Ã§Ã¼k harfleri kullanmak iÃ§in"
      ],
      "metadata": {
        "id": "hCtaNLf1DTbz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bce5502f-475b-4281-e774-e516cf241e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `string.ascii_lowercase`: KÃ¼Ã§Ã¼k harflerden oluÅŸan bir sabit (a'dan z'ye kadar olan harfler).\n",
        "  \n",
        "- `string.digits`: SayÄ±lardan oluÅŸan bir sabit (0'dan 9'a kadar olan rakamlar).\n",
        "  \n",
        "- `string.punctuation`: TÃ¼m yaygÄ±n noktalama iÅŸaretlerini iÃ§eren bir sabit (Ã¶rn. `!\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~`).\n",
        "\n",
        "Bu Ã¼Ã§ sabitin birleÅŸimi, kÃ¼Ã§Ã¼k harfler, rakamlar ve noktalama iÅŸaretlerinin birleÅŸtirilmesinden oluÅŸan **alfabe**yi oluÅŸturur."
      ],
      "metadata": {
        "id": "mNV1LItTFg2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter dÃ¼zeyinde belirteÃ§ vektÃ¶rleÅŸtirici Ã¶rneÄŸi oluÅŸturun\n",
        "\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 #alfabedeki karakter sayÄ±sÄ± + boÅŸluk + OOV belirteci\n",
        "\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Karakter vektÃ¶rleÅŸtiricisini eÄŸitim karakterlerine uyarlayÄ±n\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "ALCNGOABzUHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "standardizasyon None olsaydÄ±, Ã§Ä±ktÄ±;\n",
        "\n",
        "- 57\n",
        "- '', [UNK], 'e', 't', 'i'\n",
        "- 'I', '\"', ']', '//', ...olurdu.\n",
        "\n",
        "Yani none ile noktalama iÅŸaretlerini terketmiÅŸ olursunuz.\n",
        "\n",
        "`standardize` parametresi, `TextVectorization` katmanÄ±nÄ±n nasÄ±l bir **Ã¶n iÅŸleme** yapacaÄŸÄ±na karar verir. Bu parametre, metni modelin giriÅŸine uygun hale getirmeden Ã¶nce uygulanan iÅŸlemleri kontrol eder.\n",
        "\n",
        "`TextVectorization` katmanÄ±, metin verisini bir sayÄ±sal temsile dÃ¶nÃ¼ÅŸtÃ¼rmeden Ã¶nce bazÄ± metin Ã¶n iÅŸleme adÄ±mlarÄ± uygular. Bu iÅŸlem, metnin formatÄ±nÄ± ve biÃ§imini standart hale getirmeye yardÄ±mcÄ± olur. `standardize` parametresi, bu Ã¶n iÅŸleme iÅŸleminin nasÄ±l yapÄ±lacaÄŸÄ±nÄ± belirler.\n",
        "\n",
        "**KullanÄ±labilecek `standardize` seÃ§enekleri:**\n",
        "\n",
        "1. **`\"lower_and_strip_punctuation\"`**:\n",
        "   - Bu seÃ§enek, metni **kÃ¼Ã§Ã¼k harfe** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve **noktalama iÅŸaretlerini** temizler. Yani, metni kÃ¼Ã§Ã¼k harflerle yazacak ve noktalama iÅŸaretlerini kaldÄ±racaktÄ±r.\n",
        "   \n",
        "   Ã–rneÄŸin:\n",
        "   ```python\n",
        "   \"Merhaba, dÃ¼nya!\" -> \"merhaba dunya\"\n",
        "   ```\n",
        "\n",
        "2. **`\"lower\"`**:\n",
        "   - Sadece metni **kÃ¼Ã§Ã¼k harfe** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.\n",
        "   \n",
        "   Ã–rneÄŸin:\n",
        "   ```python\n",
        "   \"Merhaba, dÃ¼nya!\" -> \"merhaba, dÃ¼nya!\"\n",
        "   ```\n",
        "\n",
        "3. **`\"strip_punctuation\"`**:\n",
        "   - YalnÄ±zca **noktalama iÅŸaretlerini kaldÄ±rÄ±r**, ama bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf farkÄ±nÄ± korur.\n",
        "   \n",
        "   Ã–rneÄŸin:\n",
        "   ```python\n",
        "   \"Merhaba, dÃ¼nya!\" -> \"Merhaba dÃ¼nya\"\n",
        "   ```\n",
        "\n",
        "4. **`None` (VarsayÄ±lan)**:\n",
        "   - HiÃ§bir standartlaÅŸtÄ±rma yapÄ±lmaz. Yani, metin olduÄŸu gibi kalÄ±r.\n",
        "   \n",
        "   Ã–rneÄŸin:\n",
        "   ```python\n",
        "   \"Merhaba, dÃ¼nya!\" -> \"Merhaba, dÃ¼nya!\"\n",
        "   ```\n",
        "\n",
        "5. **Ã–zel Fonksiyon**:\n",
        "   - Kendi Ã¶zel standardizasyon fonksiyonunuzu yazabilirsiniz. Ã–rneÄŸin, belirli kelimeleri deÄŸiÅŸtirmek veya bazÄ± karakterleri silmek gibi.\n",
        "\n",
        "`char_vectorizer.adapt(train_chars)`\n",
        "\n",
        "Son olarak, `char_vectorizer.adapt(train_chars)` satÄ±rÄ±, `train_chars` adlÄ± eÄŸitim verisi Ã¼zerinde bu vektÃ¶rleÅŸtiriciyi **uyarlamak** iÃ§in kullanÄ±lÄ±r. Bu iÅŸlem sÄ±rasÄ±nda, `train_chars` verisindeki karakterler gÃ¶zlemlenir ve model, her karakterin sayÄ±sal bir temsilini oluÅŸturmak iÃ§in uygun parametreleri Ã¶ÄŸrenir."
      ],
      "metadata": {
        "id": "JkHlH_262aoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter sÃ¶zlÃ¼ÄŸÃ¼ Ã¶zelliklerini kontrol edin\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Karakter sÃ¶zlÃ¼ÄŸÃ¼ndeki farklÄ± karakterlerin sayÄ±sÄ±: {len(char_vocab)}\")\n",
        "print(f\"En yaygÄ±n 5 karakter: {char_vocab[:5]}\")\n",
        "print(f\"En az yaygÄ±n olan 5 karakter: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "3_skzRjfzb5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86569f5-037a-4e3c-a21b-92cffd3d8583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Karakter sÃ¶zlÃ¼ÄŸÃ¼ndeki farklÄ± karakterlerin sayÄ±sÄ±: 28\n",
            "En yaygÄ±n 5 karakter: ['', '[UNK]', 'e', 't', 'i']\n",
            "En az yaygÄ±n olan 5 karakter: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter vektÃ¶rleÅŸtiricisini test edin\n",
        "\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "id": "gnG-A9Fzzb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0809b5-3e0c-421b-848a-fbb3ff11fdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            "b e f o r e   t r e a t m e n t   ,   t h e r e   w a s   n o   s i g n i f i c a n t   d i f f e r e n c e   b e t w e e n   t w o   g r o u p s   i n   e a c h   i n d e x   (   p   >   @   )   .\n",
            "\n",
            "Length of chars: 80\n",
            "\n",
            "Vectorized chars:\n",
            "[[22  2 17  7  8  2  3  8  2  5  3 15  2  6  3  3 13  2  8  2 20  5  9  6\n",
            "   7  9  4 18  6  4 17  4 11  5  6  3 10  4 17 17  2  8  2  6 11  2 22  2\n",
            "   3 20  2  2  6  3 20  7 18  8  7 16 14  9  4  6  2  5 11 13  4  6 10  2\n",
            "  24 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "UzunluÄŸu 290'dan (output_seq_char_length) daha kÄ±sa olan dizilerin sonunda sÄ±fÄ±rlarla doldurulduÄŸunu fark edeceksiniz, bu da modelimize geÃ§irilen tÃ¼m dizilerin aynÄ± uzunlukta olmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "AyrÄ±ca, TextVectorization'Ä±n standartlaÅŸtÄ±rma parametresinin \"lower_and_strip_punctuation\" ve bÃ¶lÃ¼nmÃ¼ÅŸ parametrenin varsayÄ±lan olarak \"whitespace\" olmasÄ± nedeniyle, semboller (@ gibi) ve boÅŸluklar kaldÄ±rÄ±lÄ±r.\n",
        "\n",
        "ğŸ”‘ Not: Noktalama iÅŸaretlerinin kaldÄ±rÄ±lmasÄ±nÄ± istemediyseniz (@, % vb. tutun), Ã¶zel bir standardizasyon Ã§aÄŸrÄ±labilir oluÅŸturabilir ve bunu standartlaÅŸtÄ±rma parametresi olarak geÃ§irebilirsiniz. Daha fazla bilgi iÃ§in TextVectorization katmanÄ± belgelerine bakÄ±n."
      ],
      "metadata": {
        "id": "egnMTV7E3zRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Karakter dÃ¼zeyinde bir gÃ¶mme oluÅŸturma**\n",
        "\n",
        "Karakter dÃ¼zeyindeki dizilerimizi vektÃ¶rleÅŸtirmenin bir yolu var, ÅŸimdi bir karakter dÃ¼zeyinde gÃ¶mme oluÅŸturma zamanÄ±.\n",
        "\n",
        "TÄ±pkÄ± Ã¶zel belirteÃ§ gÃ¶mmemiz gibi, bunu tensorflow.keras.layers.Embedding sÄ±nÄ±fÄ±nÄ± kullanarak yapabiliriz. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "Karakter dÃ¼zeyinde gÃ¶mme katmanÄ±mÄ±z bir giriÅŸ boyutu ve Ã§Ä±kÄ±ÅŸ boyutu gerektirir.\n",
        "\n",
        "GiriÅŸ boyutu (input_dim), char_vocab'Ä±mÄ±zdaki (28) farklÄ± karakterlerin sayÄ±sÄ±na eÅŸit olacaktÄ±r. Ve TÄ±bbi KaÄŸÄ±t Ã–zetlerinde Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ± Åekil 1'deki modelin yapÄ±sÄ±nÄ± takip ettiÄŸimizden, karakter gÃ¶mmenin (output_dim) Ã§Ä±ktÄ± boyutu 25 olacaktÄ±r. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "dokÃ¼manda, input_dim --> int. Kelime haznesidir. Ã–rneÄŸin max tamsayÄ± indexi +1 gibi.\n",
        "\n",
        "output_dim --> int. YoÄŸun gÃ¶mmenin ÅŸekilsel boyutu."
      ],
      "metadata": {
        "id": "BmIAWK9f313t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter gÃ¶mmesi katmanÄ± oluÅŸtur\n",
        "char_embed = layers.Embedding(\n",
        "    input_dim = NUM_CHAR_TOKENS,  # farklÄ± karakter sayÄ±sÄ±\n",
        "    output_dim = 25,              # her karakterin yerleÅŸtirme boyutu (Figure 1 ile aynÄ± https://arxiv.org/pdf/1612.05251.pdf)\n",
        "    mask_zero = True,             # maske kullanmayÄ±n (True olarak ayarlanÄ±rsa bu model_5'i bozar)\n",
        "    name = \"char_embedding\"\n",
        ")\n",
        "\n",
        "# Karakter yerleÅŸtirme katmanÄ±nÄ± test edin\n",
        "print(f\"Charified metin (vektÃ¶rleÅŸtirme ve yerleÅŸtirmeden Ã¶nce):\\n{random_train_chars}\\n\")\n",
        "\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "\n",
        "print(f\"GÃ¶mÃ¼lÃ¼ karakterler (vektÃ¶rleÅŸtirme ve yerleÅŸtirmeden sonra):\\n{char_embed_example}\\n\")\n",
        "\n",
        "print(f\"Karakter yerleÅŸtirme ÅŸekli: {char_embed_example.shape}\")"
      ],
      "metadata": {
        "id": "nPSTWmFNzb0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeee8d06-0614-4606-bb96-cdd0ae8e71c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified metin (vektÃ¶rleÅŸtirme ve yerleÅŸtirmeden Ã¶nce):\n",
            "b e f o r e   t r e a t m e n t   ,   t h e r e   w a s   n o   s i g n i f i c a n t   d i f f e r e n c e   b e t w e e n   t w o   g r o u p s   i n   e a c h   i n d e x   (   p   >   @   )   .\n",
            "\n",
            "GÃ¶mÃ¼lÃ¼ karakterler (vektÃ¶rleÅŸtirme ve yerleÅŸtirmeden sonra):\n",
            "[[[ 0.0394259   0.02469474 -0.04906693 ... -0.03765197 -0.01020537\n",
            "    0.04477144]\n",
            "  [-0.028685    0.01803899  0.01715585 ... -0.03201541  0.01884799\n",
            "    0.04072127]\n",
            "  [-0.04388865  0.00688157 -0.02571483 ... -0.02481255  0.00622012\n",
            "    0.0067553 ]\n",
            "  ...\n",
            "  [-0.02440536  0.0424017  -0.02214311 ...  0.01463326  0.03493572\n",
            "   -0.0461356 ]\n",
            "  [-0.02440536  0.0424017  -0.02214311 ...  0.01463326  0.03493572\n",
            "   -0.0461356 ]\n",
            "  [-0.02440536  0.0424017  -0.02214311 ...  0.01463326  0.03493572\n",
            "   -0.0461356 ]]]\n",
            "\n",
            "Karakter yerleÅŸtirme ÅŸekli: (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dizilerimizdeki karakterlerin her biri 25 boyutlu bir gÃ¶mmeye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r. Her bir harf Ã¶zellik vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼.\n",
        "\n",
        "290 uzunluÄŸa kadar sÄ±fÄ±rlarla doldurulur. 1 dizi var, 290 karakter var (char vectorizer kaÃ§ harf olursa olsun 290'a kadar padding yapar), 25 gÃ¶mme karakteri.\n",
        "\n",
        "Åimdi karakter dÃ¼zeyindeki dizilerimizi sayÄ±lara (char_vectorizer) dÃ¶nÃ¼ÅŸtÃ¼rmenin ve onlarÄ± bir gÃ¶mme (char_embed) olarak sayÄ±sal olarak temsil etmenin bir yolu var, karakter dÃ¼zeyinde bir dizi modeli oluÅŸturarak dizilerimizdeki bilgileri kodlamada ne kadar etkili olduklarÄ±nÄ± test edelim.\n",
        "\n",
        "Model, Ã¶zel belirteÃ§ yerleÅŸtirme modelimizle (model_1) aynÄ± yapÄ±ya sahip olacaktÄ±r, ancak belirteÃ§ dÃ¼zeyinde diziler yerine karakter dÃ¼zeyinde diziler giriÅŸ olarak alacaktÄ±r.\n",
        "\n",
        "Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)"
      ],
      "metadata": {
        "id": "DavlQQnd5nA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Karakterler iÃ§in (harf) Conv1D hazÄ±rlama\n",
        "inputs = layers.Input(shape = (1,), dtype = \"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\", activation = \"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "model_3 = tf.keras.Model(\n",
        "    inputs = inputs,\n",
        "    outputs = outputs,\n",
        "    name = \"model_3_conv1D_char_embedding\"\n",
        ")\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model_3.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Modelimizi verilere sÄ±ÄŸdÄ±rmadan Ã¶nce, karakter dÃ¼zeyinde toplu PrefetchedDataset'ler oluÅŸturmalÄ±yÄ±z\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(train_char_dataset)\n",
        "\n",
        "# Modeli uydur\n",
        "model_3_history = model_3.fit(\n",
        "    train_char_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=val_char_dataset,\n",
        "    validation_steps=int(0.1 * len(val_char_dataset))\n",
        "    )\n",
        "\n",
        "# Model Ã¶zeti\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "dT_aU8T96Srn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "693a612a-6e61-4ddd-88f2-bd774ca7601c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>\n",
            "Epoch 1/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4197 - loss: 1.3969 - val_accuracy: 0.5814 - val_loss: 1.0622\n",
            "Epoch 2/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5800 - loss: 1.0410 - val_accuracy: 0.6316 - val_loss: 0.9509\n",
            "Epoch 3/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6223 - loss: 0.9517 - val_accuracy: 0.6446 - val_loss: 0.8973\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_3_conv1D_char_embedding\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_3_conv1D_char_embedding\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ char_vectorizer (\u001b[38;5;33mTextVectorization\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ char_embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m25\u001b[0m)             â”‚           \u001b[38;5;34m1,750\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m8,064\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pooling1d                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   â”‚             \u001b[38;5;34m325\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ char_vectorizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ char_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,750</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_max_pooling1d                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 â”‚                             â”‚                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,419\u001b[0m (118.83 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,419</span> (118.83 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,139\u001b[0m (39.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,139</span> (39.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,280\u001b[0m (79.22 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,280</span> (79.22 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.5 s, sys: 1.33 s, total: 14.8 s\n",
            "Wall time: 12.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_3'Ã¼ tÃ¼m doÄŸrulama karakteri veri kÃ¼mesinde deÄŸerlendirin\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "metadata": {
        "id": "bkJ0W9pP8kQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e890422-2797-4dd2-bec3-8128c0323304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6505 - loss: 0.8906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8938198089599609, 0.6496756076812744]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YalnÄ±zca karakter modeliyle tahminlerde bulunun\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "id": "WM6TFX0o8kMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c21ff1c-4cbf-486e-f063-94cc4f385c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.168758  , 0.16304976, 0.23900391, 0.32760364, 0.10158475],\n",
              "       [0.11768349, 0.60637593, 0.011198  , 0.1211826 , 0.14355993],\n",
              "       [0.0998732 , 0.31029567, 0.33654052, 0.21033841, 0.04295219],\n",
              "       ...,\n",
              "       [0.02575635, 0.03783292, 0.37089068, 0.09197588, 0.47354418],\n",
              "       [0.04610219, 0.12186202, 0.4773507 , 0.07366963, 0.28101537],\n",
              "       [0.4160033 , 0.40838563, 0.0707214 , 0.08389489, 0.02099485]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminleri sÄ±nÄ±flara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "id": "3rkc6vuO8kHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7c7a34-2ad4-411a-93e0-6c66944977aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([3, 1, 2, ..., 4, 2, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YalnÄ±zca Conv1D karakter modeli sonuÃ§larÄ±nÄ± hesapla\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                        y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "bidY-6e58kCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0589936e-81a9-4f58-c3e4-e70bd8664952",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-2c2eac120973>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# YalnÄ±zca Conv1D karakter modeli sonuÃ§larÄ±nÄ± hesapla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_3_results = calculate_results(y_true=val_labels_encoded,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                         y_pred=model_3_preds)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_3_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \"\"\"\n\u001b[1;32m    280\u001b[0m   \u001b[0;31m# Calculate model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m   \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;31m# Calculate model precision, recall and f1 score using \"weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mmodel_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mget_namespace_and_device\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0marrays_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mdevice_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_array_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdevice_other\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;34mf\"Input arrays use different devices: {str(device_)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;34mf\"{str(device_other)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.10. Ã–nceden EÄŸitilmiÅŸ Token GÃ¶mmeler ve Karakter GÃ¶mmeleri BirleÅŸtirerek Modelleme ve DeÄŸerlendirme**"
      ],
      "metadata": {
        "id": "HJCbXuUXj4-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medical Paper Abstracts'da Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ± Åekil 1'dekine benzer bir model oluÅŸturmaya yaklaÅŸÄ±rken, bahsettikleri hibrit belirteÃ§ gÃ¶mme katmanÄ±nÄ± ele almanÄ±n zamanÄ± geldi. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "Bu karma belirteÃ§ gÃ¶mme katmanÄ±, belirteÃ§ gÃ¶mme ve karakter gÃ¶mmelerinin bir kombinasyonudur. BaÅŸka bir deyiÅŸle, dizileri sÄ±ra etiketi tahmin katmanÄ±na geÃ§irmeden Ã¶nce temsil etmek iÃ§in yÄ±ÄŸÄ±lmÄ±ÅŸ bir gÃ¶mme oluÅŸtururlar.\n",
        "\n",
        "Åimdiye kadar belirteÃ§ ve karakter dÃ¼zeyinde gÃ¶mmeler kullanan iki model geliÅŸtirdik, ancak bu iki model bu gÃ¶mmelerin her birini Ã¶zel olarak kullandÄ±.\n",
        "\n",
        "Åekil 1'deki modeli Ã§oÄŸaltmaya (veya Ã§oÄŸaltmaya yaklaÅŸmaya) baÅŸlamak iÃ§in aÅŸaÄŸÄ±daki adÄ±mlardan geÃ§eceÄŸiz:\n",
        "\n",
        "1. Token dÃ¼zeyinde bir model oluÅŸturun (model_1'e benzer)\n",
        "\n",
        "2. Karakter dÃ¼zeyinde bir model oluÅŸturun (kaÄŸÄ±dÄ± yansÄ±tmak iÃ§in hafif bir deÄŸiÅŸiklikle model_3'e benzer)\n",
        "\n",
        "3. 1 ve 2'nin Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtirin (layers.Concatenate) https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\n",
        "\n",
        "4. TÄ±bbi KaÄŸÄ±t Ã–zetlerinde Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ±'nÄ±n Åekil 1 ve bÃ¶lÃ¼m 4.2'ye benzer 3'Ã¼n Ã¼zerine bir dizi Ã§Ä±ktÄ± katmanÄ± oluÅŸturun\n",
        "\n",
        "5. Token ve karakter dÃ¼zeyinde dizileri girdi olarak alan ve Ã§Ä±ktÄ± olarak sÄ±ra etiketi olasÄ±lÄ±klarÄ± Ã¼reten bir model oluÅŸturun"
      ],
      "metadata": {
        "id": "h_4wovEb87-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. BelirteÃ§ giriÅŸlerini/modelini ayarlayÄ±n\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Karakter giriÅŸlerini/modelini ayarlayÄ±n\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # https://arxiv.org/pdf/1612.05251.pdf adresindeki Åekil 1'de gÃ¶sterilen bi-LSTM\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. BelirteÃ§ ve karakter giriÅŸlerini birleÅŸtirin (hibrit belirteÃ§ yerleÅŸtirme oluÅŸturun)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Ã‡Ä±ktÄ± katmanlarÄ± oluÅŸturun - https://arxiv.org/pdf/1612.05251.pdf 4.2'de aÃ§Ä±klanan bÄ±rakmanÄ±n eklenmesi\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # belirteÃ§/karakter yerleÅŸtirme katmanlarÄ±nÄ±n farklÄ± ÅŸekilleri nedeniyle Åekil 1'den biraz farklÄ±\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Karakter ve jeton giriÅŸleriyle model oluÅŸturun\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")\n",
        "\n",
        "# BelirteÃ§ karakter modelini derle\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # https://arxiv.org/pdf/1612.05251.pdf bÃ¶lÃ¼mÃ¼nÃ¼n 4.2 bÃ¶lÃ¼mÃ¼nde SGD kullanÄ±mÄ±ndan bahsediliyor ancak biz Adam'a sadÄ±k kalacaÄŸÄ±z\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Model Ã¶zeti\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "A5qxQkJd_i7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ee73c468-f913-4d82-9568-3ef8e28759ba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf_hub_embedding_layer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-ed7f7a62d2f3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. BelirteÃ§ giriÅŸlerini/modelini ayarlayÄ±n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtoken_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"token_input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_hub_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtoken_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m token_model = tf.keras.Model(inputs=token_inputs,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf_hub_embedding_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, bir **hibrit model** oluÅŸturarak **belirteÃ§ (token) temelli yerleÅŸtirme** ve **karakter temelli yerleÅŸtirme** yÃ¶ntemlerini birleÅŸtiriyor. Kodun belirli bÃ¶lÃ¼mlerini daha ayrÄ±ntÄ±lÄ± aÃ§Ä±klayayÄ±m:\n",
        "\n",
        "```python\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings)\n",
        "```\n",
        "\n",
        "Bu satÄ±rda, **Bidirectional LSTM (Bi-LSTM)** katmanÄ± kullanÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "**Bi-LSTM Nedir?**\n",
        "\n",
        "- **LSTM (Long Short-Term Memory)**, sekans (zaman serisi veya kelimeler gibi sÄ±ralÄ± veriler) Ã¼zerindeki uzun menzilli baÄŸÄ±mlÄ±lÄ±klarÄ± Ã¶ÄŸrenebilen bir tÃ¼r **Recurrent Neural Network (RNN)** katmanÄ±dÄ±r. LSTM, Ã¶zellikle dil iÅŸleme gÃ¶revlerinde yaygÄ±n olarak kullanÄ±lÄ±r Ã§Ã¼nkÃ¼ geÃ§miÅŸ bilgileri uzun sÃ¼re hatÄ±rlayabilir ve geÃ§ici verileri unutarak Ã¶nemli olanlarÄ± Ã¶ÄŸrenebilir.\n",
        "\n",
        "- **Bidirectional LSTM (Bi-LSTM)**, LSTM katmanÄ±nÄ±n iki yÃ¶nlÃ¼ versiyonudur. Bu, sÄ±ralÄ± veriyi hem **soldan saÄŸa** hem de **saÄŸdan sola** iÅŸleyerek daha fazla baÄŸlam bilgisi elde eder. Bu sayede, metnin baÅŸÄ±ndan ve sonundan gelen baÄŸlamlarÄ± aynÄ± anda Ã¶ÄŸrenebiliriz.\n",
        "\n",
        "- **`LSTM(25)`**: Bu, LSTM katmanÄ±nÄ±n Ã§Ä±ktÄ±sÄ±nÄ±n boyutunu belirtir. Yani, her bir zaman adÄ±mÄ±nda 25 boyutlu bir vektÃ¶r elde edilecek.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "token_model = tf.keras.Model(inputs=token_inputs, outputs=token_output)\n",
        "```\n",
        "\n",
        "```python\n",
        "char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n",
        "```\n",
        "\n",
        "Bu satÄ±rlarda **model parÃ§alarÄ±** tanÄ±mlanÄ±yor:\n",
        "\n",
        "- **`token_model`**: Bu, **belirteÃ§ temelli yerleÅŸtirme** modelidir. `token_inputs` (kelimeler ya da belirteÃ§ler) ile baÅŸlar ve `token_embeddings`'ten geÃ§tikten sonra, bir **`Dense`** katmanÄ±na (`token_output`) baÄŸlanÄ±r. Bu model sadece belirteÃ§ dÃ¼zeyinde Ã¶ÄŸrenme yapar.\n",
        "\n",
        "- **`char_model`**: Bu, **karakter temelli yerleÅŸtirme** modelidir. `char_inputs` (karakterler) ile baÅŸlar, `char_vectorizer` ile metni vektÃ¶rleÅŸtirir, ardÄ±ndan `char_embed` ile karakter gÃ¶mmeleri elde edilir ve sonrasÄ±nda bir **Bi-LSTM katmanÄ±** (`char_bi_lstm`) ile bu karakter dizileri Ã¼zerinde Ã¶ÄŸrenme yapÄ±lÄ±r.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, char_model.output])\n",
        "```\n",
        "\n",
        "Buradaki `token_model.output` ve `char_model.output` kullanÄ±mÄ±, her iki modelin **Ã§Ä±kÄ±ÅŸlarÄ±nÄ±** almak iÃ§in kullanÄ±lÄ±r:\n",
        "\n",
        "- **`token_model.output`**: `token_model`'in Ã§Ä±kÄ±ÅŸÄ±, belirteÃ§ler iÃ§in Ã¶ÄŸrenilen Ã¶zellikleri iÃ§erir (yani, `token_output` katmanÄ±ndan gelen sonuÃ§).\n",
        "  \n",
        "- **`char_model.output`**: `char_model`'in Ã§Ä±kÄ±ÅŸÄ±, karakterler iÃ§in Ã¶ÄŸrenilen Ã¶zellikleri iÃ§erir (yani, `char_bi_lstm` katmanÄ±ndan gelen sonuÃ§).\n",
        "\n",
        "`layers.Concatenate` katmanÄ±, bu iki Ã§Ä±ktÄ±yÄ± **birleÅŸtirir** (concatenate). Burada `name=\"token_char_hybrid\"` ismi verilmiÅŸ. Bu, her iki modelin Ã§Ä±ktÄ±larÄ±nÄ±n **hibrit bir ÅŸekilde** birleÅŸtiÄŸi bir Ã¶zellik vektÃ¶rÃ¼ oluÅŸturur.\n",
        "\n",
        "**.output** ifadesi, her modelin son katmanÄ±ndaki Ã§Ä±kÄ±ÅŸÄ± belirtir. Modelin katmanlarÄ±nÄ± tanÄ±mlarken, `Model()` sÄ±nÄ±fÄ±nÄ±n Ã§Ä±ktÄ±sÄ± genellikle `.output` olarak eriÅŸilir.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "```\n",
        "\n",
        "```python\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "```\n",
        "\n",
        "**Dropout**, **aÅŸÄ±rÄ± uyum** (overfitting) problemini Ã¶nlemeye yardÄ±mcÄ± olan bir **dÃ¼zenleme** (regularization) yÃ¶ntemidir. Dropout, eÄŸitim sÄ±rasÄ±nda belirli katmanlardan rastgele **nÃ¶ronlarÄ± devre dÄ±ÅŸÄ± bÄ±rakÄ±r**. Bu sayede, modelin her bir nÃ¶ronun baÄŸÄ±mlÄ± hale gelmesi engellenir ve genelleme yeteneÄŸi artÄ±rÄ±lÄ±r.\n",
        "\n",
        "- **`0.5`**: Dropout oranÄ±nÄ± belirtir. Burada `0.5` deÄŸeri, her bir eÄŸitim adÄ±mÄ±nda %50 oranÄ±nda nÃ¶ronun rastgele devre dÄ±ÅŸÄ± bÄ±rakÄ±lacaÄŸÄ± anlamÄ±na gelir.\n",
        "\n",
        "- Dropout katmanlarÄ±, aÅŸÄ±rÄ± uyumun Ã¶nlenmesine yardÄ±mcÄ± olur, Ã§Ã¼nkÃ¼ her eÄŸitim adÄ±mÄ±nda farklÄ± nÃ¶ronlar devre dÄ±ÅŸÄ± bÄ±rakÄ±ldÄ±ÄŸÄ± iÃ§in model, daha saÄŸlam bir ÅŸekilde genel kalÄ±plarÄ± Ã¶ÄŸrenir.\n",
        "\n",
        "EÄŸitim sÄ±rasÄ±nda, **dropout** uygulandÄ±ktan sonra model sadece en Ã¶nemli Ã¶zellikleri Ã¶ÄŸrenmeye Ã§alÄ±ÅŸÄ±r ve Ã§ok fazla modelin Ã¶ÄŸrenmesini engelleyen baÄŸÄ±mlÄ±lÄ±klar oluÅŸmaz."
      ],
      "metadata": {
        "id": "rSXBroPAIUM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 ile ilgili olarak; model, stokastik gradyan iniÅŸ kullanÄ±larak eÄŸitilir ve her gradyan adÄ±mÄ±nda tÃ¼m parametreler, yani jeton yerleÅŸtirmeleri, karakter yerleÅŸtirmeleri, Ã§ift yÃ¶nlÃ¼ LSTM parametreleri ve geÃ§iÅŸ olasÄ±lÄ±klarÄ± gÃ¼ncellenir. DÃ¼zenleme iÃ§in, karakter geliÅŸtirilmiÅŸ token yerleÅŸtirmelerine ve etiket tahmin katmanÄ±ndan Ã¶nce 0,5 oranÄ±nda bÄ±rakma uygulanÄ±r.\n",
        "\n",
        "5 --> bu sÄ±ralÄ± API ile deÄŸil fonksiyonel API ile oluÅŸturduk. Bu yÃ¼zden token modeli giriÅŸine ihtiyacÄ±mÄ±z var ve bunu da kullanabilmek iÃ§in char model giriÅŸi kullanÄ±lmalÄ±."
      ],
      "metadata": {
        "id": "5wDbqDXyAU2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AslÄ±nda yapÄ±lan iki model oluÅŸturuldu, Ã§Ä±ktÄ±lar birleÅŸtirildi, bir token ve bir karakter Ã§Ä±ktÄ±sÄ± birleÅŸti ve sonra bunlar Ã¼zerine bazÄ± katmanlar ekledik."
      ],
      "metadata": {
        "id": "cErVyrbaApfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hibrit jeton ve karakter modelini Ã§izin\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_4)"
      ],
      "metadata": {
        "id": "Oidcjf41AqWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”‘ Not: Medical Paper Abstracts'ta Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ± BÃ¶lÃ¼m 4.2, SGD (stokastik gradyan iniÅŸ) optimize ediciyi kullanarak bahseder, ancak diÄŸer modellerimizle tutarlÄ± kalmak iÃ§in Adam optimizer'Ä± kullanacaÄŸÄ±z. Bir alÄ±ÅŸtÄ±rma olarak, tf.keras.optimizers.Adam yerine tf.keras.optimizers.SGD kullanmayÄ± deneyebilir ve sonuÃ§larÄ± karÅŸÄ±laÅŸtÄ±rabilirsiniz.\n",
        "\n",
        "- https://arxiv.org/pdf/1612.05251\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD"
      ],
      "metadata": {
        "id": "urMfBOscBCdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve yine, deneylerimizi hÄ±zlÄ± tutmak iÃ§in, token-character-hybrid modelimizi eÄŸitimin %10'una sÄ±ÄŸdÄ±racaÄŸÄ±z ve doÄŸrulama gruplarÄ±nÄ±n %10'unu doÄŸrulayacaÄŸÄ±z. Bununla birlikte, bu model ile fark, iki girdi, belirteÃ§ dÃ¼zeyinde diziler ve karakter dÃ¼zeyinde diziler gerektirmesidir.\n",
        "\n",
        "Bunu, ilk girdi olduÄŸu gibi bir demet ile bir tf.data.Dataset oluÅŸturarak yapabiliriz, Ã¶rneÄŸin:\n",
        "\n",
        "((Token_data, char_data), (etiket))"
      ],
      "metadata": {
        "id": "qqgDc_7VBbYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Token ve karakter verilerini bir tf.data veri kÃ¼mesinde birleÅŸtirme**\n",
        "\n",
        "- zip kodu ile iki farklÄ± veri kÃ¼mesi birleÅŸtirilir.\n",
        "- HÄ±zlÄ± deney yapma hedefiyle val...kodlarÄ± yazÄ±ldÄ±.\n",
        "- Token model girdisine ve char model girdisine nasÄ±l sahip olduÄŸumuza dikkat. Token seviyesinde veriler vardÄ±, cÃ¼mleleri eÄŸittik ve traine aldÄ±k. Yani bu modelin inÅŸa edildiÄŸi sÄ±rayla aynÄ±. Aksi takdirde, farklÄ± bir sÄ±rayla iletirsek, modelimiz belirteÃ§ seviyesi modelini kullanmaya Ã§alÄ±ÅŸabilir."
      ],
      "metadata": {
        "id": "gxoztyGTByQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakterleri ve belirteÃ§leri bir veri kÃ¼mesinde birleÅŸtirin\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # veri yap\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # etiket yap\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # veri ve etiketleri birleÅŸtir\n",
        "\n",
        "# Verileri Ã¶nceden getirme ve toplu eÄŸitim verileri\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# AynÄ± adÄ±mlarÄ± doÄŸrulama verilerini tekrarlayÄ±n\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# EÄŸitim karakteri ve belirteÃ§ yerleÅŸtirme veri kÃ¼mesine gÃ¶z atÄ±n\n",
        "train_char_token_dataset, val_char_token_dataset\n",
        "\n",
        "# Token ve karakter dÃ¼zeyindeki dizilere bir model uydurmak\n",
        "model_4_history = model_4.fit(train_char_token_dataset, # belirteÃ§ ve karakterlerden oluÅŸan veri kÃ¼mesi Ã¼zerinde eÄŸitim alÄ±n\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
      ],
      "metadata": {
        "id": "8s57gZFECAjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "collapsed": true,
        "outputId": "c6cf8ae2-b3e1-4e3c-e9e9-6ea40a8cbf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_4' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-3ef23ab4bb4d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Token ve karakter dÃ¼zeyindeki dizilere bir model uydurmak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m model_4_history = model_4.fit(train_char_token_dataset, # belirteÃ§ ve karakterlerden oluÅŸan veri kÃ¼mesi Ã¼zerinde eÄŸitim alÄ±n\n\u001b[0m\u001b[1;32m     20\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_char_token_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_4' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Veri KÃ¼mesi OluÅŸturma (Dataset Creation)**\n",
        "\n",
        "```python\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))\n",
        "```\n",
        "  - `train_sentences` (cÃ¼mleler) ve `train_chars` (karakterler) eÄŸitim verisini iÃ§erir. Burada, her bir cÃ¼mle ve ona karÅŸÄ±lÄ±k gelen karakter dizisi eÅŸleÅŸtirilir.\n",
        "  - `train_labels_one_hot` ise her Ã¶rneÄŸe karÅŸÄ±lÄ±k gelen etiketlerin one-hot kodlamasÄ±dÄ±r. (Yani, sÄ±nÄ±f etiketlerinin 0-1 vektÃ¶rleri olarak temsil edilmesi)\n",
        "  - `tf.data.Dataset.from_tensor_slices()` fonksiyonu, bu verileri bir TensorFlow veri kÃ¼mesine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Bu veri kÃ¼mesi modelin eÄŸitiminde kullanÄ±lacak.\n",
        "  - `tf.data.Dataset.zip()` ile hem veriler (`train_char_token_data`) hem de etiketler (`train_char_token_labels`) eÅŸleÅŸtirilir. Bu, modelin eÄŸitim verisi ve etiketleriyle birlikte kullanÄ±labilmesini saÄŸlar.\n",
        "\n",
        "2. **Veri KÃ¼mesi Ãœzerinde Ä°ÅŸlem Yapma (Prefetching and Batching)**\n",
        "\n",
        "```python\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "\n",
        "- **AÃ§Ä±klama**: Bu satÄ±rda iki ÅŸey yapÄ±lÄ±r:\n",
        "  - `batch(32)`: EÄŸitim verisi, 32 Ã¶rnekten oluÅŸan \"batch\" (toplu) olarak gruplandÄ±rÄ±lÄ±r. Bu, modelin daha verimli bir ÅŸekilde eÄŸitilmesini saÄŸlar. Batch'ler sayesinde model her seferinde sadece bir kÄ±smÄ± Ã¼zerinde iÅŸlem yapar, bu da daha hÄ±zlÄ± iÅŸlemeye olanak tanÄ±r.\n",
        "  - `prefetch(tf.data.AUTOTUNE)`: Verilerin \"prefetch\" edilmesi, yani modelin eÄŸitimi sÄ±rasÄ±nda verilerin Ã¶nceden yÃ¼klenmesi anlamÄ±na gelir. Bu, I/O iÅŸlemlerinin eÄŸitim sÄ±rasÄ±nda engel oluÅŸturmadan hÄ±zlÄ± bir ÅŸekilde yapÄ±lmasÄ±nÄ± saÄŸlar. `AUTOTUNE` TensorFlow'un otomatik olarak en iyi Ã¶nceden getirme (prefetch) stratejisini seÃ§mesini saÄŸlar.\n",
        "\n",
        "3. **DoÄŸrulama Verisi iÃ§in AynÄ± Ä°ÅŸlemleri Tekrarlama**\n",
        "\n",
        "```python\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "\n",
        "- **AÃ§Ä±klama**: Bu satÄ±rlar, doÄŸrulama verisi iÃ§in yukarÄ±daki iÅŸlemlerin tekrarlanmasÄ±dÄ±r. EÄŸitim verisinde yapÄ±lan tÃ¼m iÅŸlemler doÄŸrulama verisi iÃ§in de aynÄ± ÅŸekilde yapÄ±lÄ±r. Buradaki temel amaÃ§, eÄŸitim ve doÄŸrulama veri kÃ¼melerinin her ikisinin de aynÄ± formatta ve verimli bir ÅŸekilde yÃ¼klenmesini saÄŸlamaktÄ±r.\n",
        "\n",
        "4. **Veri KÃ¼mesini Ä°nceleme**\n",
        "\n",
        "```python\n",
        "train_char_token_dataset, val_char_token_dataset\n",
        "```\n",
        "\n",
        "- **AÃ§Ä±klama**: Bu satÄ±r, eÄŸitim ve doÄŸrulama veri kÃ¼melerini kontrol etmek iÃ§in yazÄ±lmÄ±ÅŸ. Ã‡alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, bu iki veri kÃ¼mesinin TensorFlow veri kÃ¼mesi olarak nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ gÃ¶sterir. Bu iÅŸlem genellikle kodun doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olmak amacÄ±yla kullanÄ±lÄ±r.\n",
        "\n",
        "5. **Modeli EÄŸitim Ä°Ã§in Uygulama (Model Fitting)**\n",
        "\n",
        "```python\n",
        "model_4_history = model_4.fit(\n",
        "    train_char_token_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=val_char_token_dataset,\n",
        "    validation_steps=int(0.1 * len(val_char_token_dataset))\n",
        ")\n",
        "```\n",
        "\n",
        "- **AÃ§Ä±klama**: Bu satÄ±r modelin eÄŸitimini baÅŸlatÄ±r.\n",
        "  - `model_4.fit()` fonksiyonu, verilen eÄŸitim veri kÃ¼mesi (`train_char_token_dataset`) Ã¼zerinde modeli eÄŸitir.\n",
        "  - `steps_per_epoch=int(0.1 * len(train_char_token_dataset))`: Bu parametre, her epoch baÅŸÄ±na eÄŸitimde kaÃ§ adÄ±m (batch) yapÄ±lacaÄŸÄ±nÄ± belirtir. Burada eÄŸitim setinin %10'u kadar adÄ±m atÄ±lacak.\n",
        "  - `epochs=3`: Modelin 3 epoch boyunca eÄŸitilmesi saÄŸlanÄ±r. Bir epoch, tÃ¼m eÄŸitim verisinin bir kez model tarafÄ±ndan gÃ¶rÃ¼lmesidir.\n",
        "  - `validation_data=val_char_token_dataset`: Modelin her epoch sonunda doÄŸrulama verisi Ã¼zerinde nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶rmek iÃ§in doÄŸrulama verisi saÄŸlanÄ±r.\n",
        "  - `validation_steps=int(0.1 * len(val_char_token_dataset))`: Her epoch sonunda doÄŸrulama verisi iÃ§in kaÃ§ adÄ±m (batch) yapÄ±lacaÄŸÄ±nÄ± belirtir. Burada doÄŸrulama setinin %10'u kadar adÄ±m yapÄ±lÄ±r.\n",
        "\n",
        "Bu kodlar, modeli eÄŸitim verisi ve doÄŸrulama verisi Ã¼zerinde eÄŸitir ve modelin doÄŸruluÄŸunu izler. EÄŸitim sÄ±rasÄ±nda yapÄ±lan her adÄ±mda, modelin belirteÃ§ ve karakter bazlÄ± girdilerle nasÄ±l Ã¶ÄŸrenmeye Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶zlemleyebilirsiniz."
      ],
      "metadata": {
        "id": "u9cp5f63JOfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DoÄŸrulama veri kÃ¼mesinin tamamÄ±nÄ± deÄŸerlendirin\n",
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "metadata": {
        "id": "gzA5TykrCwan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BelirteÃ§-karakter modeli hibritini kullanarak tahminlerde bulunun\n",
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_pred_probs"
      ],
      "metadata": {
        "id": "VbDZsI2QCyxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasÄ±lÄ±klarÄ±nÄ± tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
        "model_4_preds"
      ],
      "metadata": {
        "id": "Lh0gSxRMCys4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token-char-hibrit modelinin sonuÃ§larÄ±nÄ± alÄ±n\n",
        "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "JiliQHWvCynR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.11. Ã–nceden EÄŸitilmiÅŸ Token GÃ¶mmeler, Karakter GÃ¶mmeleri ve Konumsal GÃ¶mmeleri BirleÅŸtirerek Modelleme ve DeÄŸerlendirme**"
      ],
      "metadata": {
        "id": "5MW2eP-xj48T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token gÃ¶mmelerini ve karakter gÃ¶mmelerini birleÅŸtirmek modelimize biraz performans artÄ±ÅŸÄ± saÄŸladÄ± gibi gÃ¶rÃ¼nÃ¼yor.\n",
        "\n",
        "Ama ekleyebileceÄŸimiz bulmacanÄ±n bir parÃ§asÄ± daha var.\n",
        "\n",
        "Ya kendi Ã¶zelliklerimizi modele dÃ¶nÃ¼ÅŸtÃ¼rseydik?\n",
        "\n",
        "Yani, modelimize Ã¶rneklerimiz hakkÄ±nda daha fazla bilgi vermek iÃ§in veriler hakkÄ±nda kendi bilgimizi alÄ±p sayÄ±sal bir ÅŸekilde kodlasaydÄ±k ne olur?\n",
        "\n",
        "Bir modele girdi olarak Ã¶zellikler oluÅŸturmak iÃ§in kendi bilginizi uygulama sÃ¼recine Ã¶zellik mÃ¼hendisliÄŸi denir.\n",
        "\n",
        "SÄ±nÄ±flandÄ±rmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z diziler hakkÄ±nda Ã¶nemli bir ÅŸey dÃ¼ÅŸÃ¼nebiliyor musunuz?\n",
        "\n",
        "Bir Ã¶zete bakacak olsaydÄ±nÄ±z, cÃ¼mlelerin sÄ±rayla gÃ¶rÃ¼nmesini bekler miydiniz? Yoksa sÄ±rayla gÃ¶rÃ¼nmeleri mantÄ±klÄ± mÄ±? Ã–rneÄŸin, begging'de SONUÃ‡LAR olarak etiketlenmiÅŸ diziler ve sonunda HEDEF olarak etiketlenmiÅŸ diziler?\n",
        "\n",
        "Ã–zetler tipik olarak sÄ±ralÄ± bir sÄ±rada gelir, Ã¶rneÄŸin:\n",
        "\n",
        "- OBJECTIVE ...\n",
        "- METHODS ...\n",
        "- METHODS ...\n",
        "- METHODS ...\n",
        "- RESULTS ...\n",
        "- CONCLUSIONS ...\n",
        "\n",
        "ya da;\n",
        "\n",
        "- BACKGROUND ...\n",
        "- OBJECTIVE ...\n",
        "- METHODS ...\n",
        "- METHODS ...\n",
        "- RESULTS ...\n",
        "- RESULTS ...\n",
        "- CONCLUSIONS ...\n",
        "- CONCLUSIONS ...\n",
        "\n",
        "Tabii ki, dizi etiketlerinin kendilerini eÄŸitim verilerine dÃ¶nÃ¼ÅŸtÃ¼remeyiz (test zamanÄ±nda bunlara sahip deÄŸiliz), ancak bir dizi dizinin sÄ±rasÄ±nÄ± soyut olarak kodlayabiliriz.\n",
        "\n",
        "Ã–rneÄŸin,\n",
        "\n",
        "- Sentence 1 of 10 ...\n",
        "- Sentence 2 of 10 ...\n",
        "- Sentence 3 of 10 ...\n",
        "- Sentence 4 of 10 ...\n",
        "\n",
        "Bunu preprocess_text_with_line_numbers() iÅŸlevimizi oluÅŸturduÄŸumuzda fark etmiÅŸ olabilirsiniz. Bir Ã¶zet metin dosyasÄ±nda okuduÄŸumuzda, bir Ã¶zetteki satÄ±r sayÄ±sÄ±nÄ± ve her satÄ±rÄ±n kendisinin sayÄ±sÄ±nÄ± saydÄ±k.\n",
        "\n",
        "Bunu yapmak, DataFrames'lerimizin \"line_number\" ve \"total_lines\" sÃ¼tunlarÄ±na yol aÃ§tÄ±."
      ],
      "metadata": {
        "id": "3EvF95--DkZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n",
        "- Verilerden kesin olmayan Ã¶zellikleri alÄ±p rakamlara dÃ¶nÃ¼ÅŸtÃ¼rme (amaÃ§ modelin Ã¶ÄŸrenmesi).\n",
        "- Modele nasÄ±l fazladan veri kaynaÄŸÄ± ekleyebiliriz?\n"
      ],
      "metadata": {
        "id": "CKcmd9jADr1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim veri Ã§erÃ§evesini inceleyin\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "oxLk9XZHDt5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ae740d25-8fe7-428b-9f0a-029f9644ea58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target                                               text  line_number  \\\n",
              "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
              "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
              "2    METHODS  outcome measures included pain reduction and i...            2   \n",
              "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
              "4    METHODS  secondary outcome measures included the wester...            4   \n",
              "\n",
              "   total_lines  \n",
              "0           11  \n",
              "1           11  \n",
              "2           11  \n",
              "3           11  \n",
              "4           11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e5bba4-b49d-4b77-bd82-698ff314ff67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e5bba4-b49d-4b77-bd82-698ff314ff67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81e5bba4-b49d-4b77-bd82-698ff314ff67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81e5bba4-b49d-4b77-bd82-698ff314ff67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88013b99-3848-4eb5-af80-a75db57a7554\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88013b99-3848-4eb5-af80-a75db57a7554')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88013b99-3848-4eb5-af80-a75db57a7554 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Line_number\" ve \"total_lines\" sÃ¼tunlarÄ±, mutlaka eÄŸitim verileriyle birlikte gelmeyen, ancak konumsal bir gÃ¶mme olarak modelimize aktarÄ±labilen Ã¶zelliklerdir. BaÅŸka bir deyiÅŸle, konumsal gÃ¶mme, cÃ¼mlenin bir soyutta gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ yerdir.\n",
        "\n",
        "Bu Ã¶zellikleri kullanabiliriz Ã§Ã¼nkÃ¼ test zamanÄ±nda mevcut olacaklar.\n",
        "\n",
        "Ã–zetler tipik olarak onlar hakkÄ±nda sÄ±ralÄ± bir sÄ±raya sahip olduÄŸundan (Ã¶rneÄŸin, arka plan, amaÃ§, yÃ¶ntemler, sonuÃ§lar, sonuÃ§), belirli bir cÃ¼mlenin gerÃ§ekleÅŸtiÄŸi yerin satÄ±r numarasÄ±nÄ± modelimize eklemek mantÄ±klÄ±dÄ±r. Ä°ÅŸin gÃ¼zel yanÄ±, bu Ã¶zellikler test zamanÄ±nda mevcut olacak (sadece bir Ã¶zetteki cÃ¼mle sayÄ±sÄ±nÄ± ve her birinin sayÄ±sÄ±nÄ± sayabiliriz).\n",
        "\n",
        "Yani, modelimizin hiÃ§ gÃ¶rmediÄŸi bir soyuttaki dizilerin etiketlerini tahmin edecek olsaydÄ±k, Ã§izgi sayÄ±sÄ±nÄ± ve her bir Ã§izginin konumunu izleyebilir ve modelimize aktarabilirdik.\n",
        "\n",
        "ğŸ›  AlÄ±ÅŸtÄ±rma: Konumsal gÃ¶mme Ã¶zelliÄŸimizi oluÅŸturmanÄ±n baÅŸka bir yolu, \"line_number\" ve \"toplam_lines\" sÃ¼tunlarÄ±nÄ± bir arada birleÅŸtirmek olacaktÄ±r, Ã¶rneÄŸin bir \"line_position\" sÃ¼tunu 1_of_11, 2_of_11, vb. gibi deÄŸerler iÃ§erebilir. 1_of_11, 11 cÃ¼mle uzunluÄŸunda bir Ã¶zetteki ilk satÄ±r olacaktÄ±r. AÅŸaÄŸÄ±daki adÄ±mlardan geÃ§tikten sonra, bu konumsal gÃ¶mme aÅŸamasÄ±nÄ± tekrar gÃ¶zden geÃ§irmek ve birleÅŸik bir \"line_position\" sÃ¼tununun iki ayrÄ± sÃ¼tuna karÅŸÄ± nasÄ±l gittiÄŸini gÃ¶rmek isteyebilirsiniz."
      ],
      "metadata": {
        "id": "y39iRrv9D18c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Konumsal GÃ¶mmeler**\n",
        "\n",
        "\"Line_number\" ve \"total_line\" sÃ¼tunlarÄ±mÄ±z zaten sayÄ±sal olduÄŸundan, onlarÄ± modelimize olduÄŸu gibi geÃ§irebiliriz.\n",
        "\n",
        "Ancak modelimizin \"line_number\"=5 iÃ§eren bir satÄ±rÄ±n \"line_number\"=1 olan bir satÄ±rdan beÅŸ kat daha bÃ¼yÃ¼k olduÄŸunu dÃ¼ÅŸÃ¼nmekten kaÃ§Ä±nmak iÃ§in, \"line_number\" ve \"total_lines\" Ã¶zelliklerimizi kodlamak iÃ§in one-hot-encoding kullanacaÄŸÄ±z.\n",
        "\n",
        "Bunu yapmak iÃ§in tf.one_hot yardÄ±mcÄ± programÄ±nÄ± kullanabiliriz.\n",
        "\n",
        "Tf.one_hot, tek sÄ±cak kodlanmÄ±ÅŸ bir tensÃ¶r dÃ¶ndÃ¼rÃ¼r. Bir diziyi (veya tensÃ¶rÃ¼) girdi olarak kabul eder ve derinlik parametresi dÃ¶ndÃ¼rÃ¼len tensÃ¶rÃ¼n boyutunu belirler.\n",
        "\n",
        "Derinlik parametresini neye ayarlamamÄ±z gerektiÄŸini bulmak iÃ§in, \"line_number\" sÃ¼tununun daÄŸÄ±lÄ±mÄ±nÄ± araÅŸtÄ±ralÄ±m.\n",
        "\n",
        "ğŸ”‘ Not: Ã–zelliklerimizi tek sÄ±cak kodlama sÃ¶z konusu olduÄŸunda, Scikit-Learn'in OneHotEncoder sÄ±nÄ±fÄ± burada baÅŸka bir uygulanabilir seÃ§enektir. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
      ],
      "metadata": {
        "id": "2awP-O6dD-5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ã–zellik mÃ¼hendisliÄŸi uygulanÄ±rken satÄ±r numaralarÄ± (cÃ¼mle nolar, her cÃ¼mle 1 satÄ±r diye geÃ§iyor burada) kullanÄ±lmalÄ± mÄ±?\n",
        "\n",
        " Bir model yalnÄ±zca eÄŸitildiÄŸi formatta veriler Ã¼zerinde gerÃ§ekleÅŸtirebilir veya tahminlerde bulunabilir.\n",
        "\n",
        "Aksi durumda chorme gibi farklÄ± tarayÄ±cÄ±larda sorun Ã§Ä±kabilir?\n",
        "\n",
        " Ã–zellik mÃ¼hendisliÄŸi test zamanÄ±nda eriÅŸilebilir olmalÄ±.\n",
        " - line numbers\n",
        " - toyal lines"
      ],
      "metadata": {
        "id": "rwTJ0JfEEFDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KaÃ§ farklÄ± satÄ±r numarasÄ± var?\n",
        "train_df[\"line_number\"].value_counts()"
      ],
      "metadata": {
        "id": "0nTf_fhPEKMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f2c2912-f9fb-45e2-afaf-5c349eeeecde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "line_number\n",
              "0     15000\n",
              "1     15000\n",
              "2     15000\n",
              "3     15000\n",
              "4     14992\n",
              "5     14949\n",
              "6     14758\n",
              "7     14279\n",
              "8     13346\n",
              "9     11981\n",
              "10    10041\n",
              "11     7892\n",
              "12     5853\n",
              "13     4152\n",
              "14     2835\n",
              "15     1861\n",
              "16     1188\n",
              "17      751\n",
              "18      462\n",
              "19      286\n",
              "20      162\n",
              "21      101\n",
              "22       66\n",
              "23       33\n",
              "24       22\n",
              "25       14\n",
              "26        7\n",
              "27        4\n",
              "28        3\n",
              "29        1\n",
              "30        1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>line_number</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>14758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"line_number\" sÃ¼tununun daÄŸÄ±lÄ±mÄ±nÄ± kontrol edin\n",
        "train_df.line_number.plot.hist()"
      ],
      "metadata": {
        "id": "6eJrMPx2EKFL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "1cae3949-c0d5-4860-db74-1607e369ee17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"line_number\" sÃ¼tunumuzun sÄ±cak kodlanmÄ±ÅŸ tensÃ¶rlerini oluÅŸturmak iÃ§in TensorFlow'u kullanÄ±n\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"
      ],
      "metadata": {
        "id": "7CqFusHPEKBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu satÄ±rlar, **sÄ±ra numaralarÄ± (line numbers)** gibi kategorik bir Ã¶zelliÄŸin **one-hot encoding** (tek sÄ±cak kodlama) yÃ¶ntemini kullanarak sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesini saÄŸlar.\n",
        "\n",
        "1. **`train_df[\"line_number\"].to_numpy()`**:  \n",
        "   Bu kÄ±sÄ±m, eÄŸitim veri setindeki `\"line_number\"` adlÄ± sÃ¼tunu seÃ§er ve bu sÃ¼tundaki deÄŸerleri **NumPy dizisi** (`np.array`) haline getirir.\n",
        "   - Burada `train_df` veri Ã§erÃ§evesindeki her bir satÄ±rÄ±n sÄ±ra numarasÄ±nÄ± almak istiyoruz.\n",
        "   - Ã–rneÄŸin, bu sÃ¼tun her cÃ¼mlenin bulunduÄŸu satÄ±r numarasÄ±nÄ± veya belge sÄ±rasÄ±nÄ± iÃ§erebilir.\n",
        "\n",
        "2. **`tf.one_hot(..., depth=15)`**:  \n",
        "   TensorFlow'un `tf.one_hot()` fonksiyonu, kategorik veriyi **one-hot encoding** formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Yani her sÄ±ra numarasÄ±nÄ± 15 elemanlÄ± bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve sadece ilgili index'e 1 yerleÅŸtirir, geri kalan tÃ¼m elemanlar 0 olur. Bu `depth=15` parametresiyle belirtilen 15, sÄ±nÄ±f sayÄ±sÄ±nÄ± belirtir (yani sÄ±ralama numaralarÄ±nÄ±n 0'dan 14'e kadar olduÄŸunu varsayÄ±yoruz).\n",
        "   \n",
        "   Ã–rneÄŸin:\n",
        "   - EÄŸer bir satÄ±rÄ±n numarasÄ± `2` ise, one-hot encoding sonucu ÅŸÃ¶yle bir vektÃ¶r olacaktÄ±r: `[0, 0, 1, 0, 0, ..., 0]` (sadece 3. pozisyon 1 olacak, diÄŸerleri 0 olacak).\n",
        "   - EÄŸer satÄ±r numarasÄ± `4` ise, one-hot encoding sonucu ÅŸu ÅŸekilde olacaktÄ±r: `[0, 0, 0, 0, 1, 0, ..., 0]`.\n",
        "\n",
        "3. **`depth=15`**:  \n",
        "   Bu parametre, one-hot encoding iÃ§in kullanÄ±lan vektÃ¶rÃ¼n uzunluÄŸunu belirtir. Yani burada 15 sÄ±nÄ±f olduÄŸu belirtilmiÅŸ, bu da her satÄ±rÄ±n 0'dan 14'e kadar olan bir numaraya sahip olduÄŸu anlamÄ±na gelir.\n",
        "\n",
        "### Ã–rnek:\n",
        "EÄŸer `train_df[\"line_number\"]` ÅŸu ÅŸekilde bir dizi iÃ§eriyorsa:\n",
        "```python\n",
        "[2, 4, 0, 1, 3]\n",
        "```\n",
        "\n",
        "`tf.one_hot()` fonksiyonu, bu diziyi ÅŸu ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r:\n",
        "\n",
        "```python\n",
        "[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 2'yi one-hot encode etti\n",
        " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 4'Ã¼ one-hot encode etti\n",
        " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 0'Ä± one-hot encode etti\n",
        " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 1'i one-hot encode etti\n",
        " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]  # 3'Ã¼ one-hot encode etti\n",
        "```\n",
        "\n",
        "KullanÄ±m AmacÄ±:\n",
        "- **Model EÄŸitimi**: Bu tÃ¼r one-hot encoding, modelin sÄ±ralama bilgisiyle (satÄ±r numaralarÄ±yla) anlamlÄ± iliÅŸkiler Ã¶ÄŸrenmesine olanak tanÄ±r. Kategorik verileri sayÄ±sal verilere dÃ¶nÃ¼ÅŸtÃ¼rmek, modelin bu veriyi anlayabilmesi iÃ§in gereklidir.\n",
        "- **Kategorik Veriyi SayÄ±sal Hale Getirme**: Ã–zellikle sinir aÄŸlarÄ±nda kategorik verilerin (satÄ±r numaralarÄ±, sÄ±nÄ±flar, vb.) iÅŸlemeye uygun hale gelmesi iÃ§in one-hot encoding yaygÄ±n olarak kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "Fpj-avFdKDcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf.one_hot'un derinlik parametresini 15'e ayarlamak, \"line_number\" deÄŸeri 15'in Ã¼zerinde olan herhangi bir numunenin tÃ¼m 0'larÄ±n tensÃ¶rÃ¼ne ayarlandÄ±ÄŸÄ± anlamÄ±na gelir; burada 15'in altÄ±ndaki \"satÄ±r_number\" olan herhangi bir Ã¶rnek, tÃ¼m 0'larÄ±n tensÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸÃ¼r, ancak dizinde \"line_number\" deÄŸerine eÅŸit bir 1 ile.\n",
        "\n",
        "ğŸ”‘ Not: \"line_number\" (derinlik=30) tÃ¼m potansiyel deÄŸerleri iÃ§in yer olan tek sÄ±cak bir tensÃ¶r oluÅŸturabiliriz, ancak bu, deÄŸerlerin bÃ¼yÃ¼k Ã§oÄŸunluÄŸunun 0 olduÄŸu mevcut olanÄ±n (derinlik=15) iki katÄ± bÃ¼yÃ¼klÃ¼ÄŸÃ¼nde bir tensÃ¶rle sonuÃ§lanÄ±r. AyrÄ±ca, yalnÄ±zca ~2.000/180.000 Ã¶rnek 15'in Ã¼zerinde bir \"satÄ±r_numarasÄ±\" deÄŸerine sahiptir. Bu nedenle, Ã¶zellik alanÄ±mÄ±zÄ± ikiye katlamak iÃ§in verilerimiz hakkÄ±nda fazla bilgi edinmezdik. Bu tÃ¼r bir soruna boyutsallÄ±ÄŸÄ±n laneti denir. Ancak, bu derin modellerle Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in, modele mÃ¼mkÃ¼n olduÄŸunca fazla bilgi atmaya ve ne olduÄŸunu gÃ¶rmeye deÄŸer olabilir. Derinlik parametresinin deÄŸerlerini bir uzantÄ± olarak keÅŸfetmeyi bÄ±rakacaÄŸÄ±m."
      ],
      "metadata": {
        "id": "C-dIrngIEa1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tek-etkin kodlanmÄ±ÅŸ \"satÄ±r_numarasÄ±\" Ã¶zellik Ã¶rneklerini kontrol edin\n",
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"
      ],
      "metadata": {
        "id": "NLKFWXMMEdSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6501669-374a-4436-90dd-fc81c9221114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 15]),\n",
              " <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Toplam_satÄ±r\" sÃ¼tunuyla \"satÄ±r_numarasÄ±\" sÃ¼tunumuz iÃ§in yaptÄ±ÄŸÄ±mÄ±zÄ±n aynÄ±sÄ±nÄ± yapabiliriz. Ä°lk olarak, tf.one_hot'un derinlik parametresi iÃ§in uygun bir deÄŸer bulalÄ±m."
      ],
      "metadata": {
        "id": "aMNXtsKsEjST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KaÃ§ farklÄ± sayÄ±da satÄ±r var?\n",
        "train_df[\"total_lines\"].value_counts()"
      ],
      "metadata": {
        "id": "CHsRJrcgEjyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "outputId": "961c4e95-e2dc-4851-8125-cc19009875a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_lines\n",
              "11    24468\n",
              "10    23639\n",
              "12    22113\n",
              "9     19400\n",
              "13    18438\n",
              "14    14610\n",
              "8     12285\n",
              "15    10768\n",
              "7      7464\n",
              "16     7429\n",
              "17     5202\n",
              "6      3353\n",
              "18     3344\n",
              "19     2480\n",
              "20     1281\n",
              "5      1146\n",
              "21      770\n",
              "22      759\n",
              "23      264\n",
              "4       215\n",
              "24      200\n",
              "25      182\n",
              "26       81\n",
              "28       58\n",
              "3        32\n",
              "30       31\n",
              "27       28\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_lines</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>22113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>19400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>18438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toplam satÄ±rlarÄ±n daÄŸÄ±lÄ±mÄ±nÄ± kontrol edin\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "id": "W602daECEoko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "93a5a488-0c5a-4f83-fdd3-6125b97ee063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Total_lines\" sÃ¼tunumuzun daÄŸÄ±lÄ±mÄ±na bakÄ±ldÄ±ÄŸÄ±nda, 20 deÄŸeri Ã¶rneklerin Ã§oÄŸunu kapsÄ±yor gibi gÃ¶rÃ¼nÃ¼yor.\n",
        "\n",
        "Bunu np.percentile() ile doÄŸrulayabiliriz. https://numpy.org/doc/stable/reference/generated/numpy.percentile.html"
      ],
      "metadata": {
        "id": "Xk-Tl-3pEs35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 deÄŸerindeki \"total_lines\" deÄŸerinin kapsamÄ±nÄ± kontrol edin\n",
        "np.percentile(train_df.total_lines, 98) # 20 deÄŸeri Ã¶rneklerin %98'ini kapsar"
      ],
      "metadata": {
        "id": "LM0_IfxSEwWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a886f5a-57a3-4279-b4cd-9a139df23f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"total_lines\" sÃ¼tunumuzun sÄ±cak kodlanmÄ±ÅŸ tensÃ¶rlerini oluÅŸturmak iÃ§in TensorFlow'u kullanÄ±n\n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "\n",
        "# Tek-sÄ±cak tensÃ¶rÃ¼n toplam Ã§izgilerinin ÅŸeklini ve Ã¶rneklerini kontrol edin\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
      ],
      "metadata": {
        "id": "YaahGOUCEwTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ac586c-a2a0-46a6-c54f-ec6f70c76b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 20]),\n",
              " <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tribrid gÃ¶mme modeli oluÅŸturma**\n",
        "\n",
        "Konumsal gÃ¶mme tensÃ¶rleri hazÄ±r.\n",
        "\n",
        "Åimdiye kadar inÅŸa ettiÄŸimiz en bÃ¼yÃ¼k modeli inÅŸa etme zamanÄ±. Token gÃ¶mmeleri, karakter gÃ¶mmeleri ve yeni hazÄ±rlanmÄ±ÅŸ konumsal gÃ¶mmelerimizi iÃ§eren bir tane.\n",
        "\n",
        "KeÅŸfedilmiÅŸ bÃ¶lgeye gireceÄŸiz ama burada daha Ã¶nce uygulamadÄ±ÄŸÄ±nÄ±z hiÃ§bir ÅŸey olmayacak.\n",
        "\n",
        "Daha spesifik olarak aÅŸaÄŸÄ±daki adÄ±mlardan geÃ§eceÄŸiz:\n",
        "\n",
        "1. Token dÃ¼zeyinde bir model oluÅŸturun (model_1'e benzer)\n",
        "\n",
        "2. Karakter dÃ¼zeyinde bir model oluÅŸturun (kaÄŸÄ±dÄ± yansÄ±tmak iÃ§in hafif bir deÄŸiÅŸiklikle model_3'e benzer)\n",
        "\n",
        "3. Bir \"line_number\" modeli oluÅŸturun (tek-sÄ±cak kodlanmÄ±ÅŸ \"line_number\" tensÃ¶rÃ¼nÃ¼ alÄ±r ve doÄŸrusal olmayan bir katmandan geÃ§irir)\n",
        "\n",
        "4. Bir \"total_lines\" modeli oluÅŸturun (tek-sÄ±cak kodlu \"total_lines\" tensÃ¶rÃ¼ alÄ±r ve doÄŸrusal olmayan bir katmandan geÃ§irir)\n",
        "\n",
        "5. 1 ve 2'nin Ã§Ä±ktÄ±larÄ±nÄ± bir token-karakter-hibrit gÃ¶mme iÃ§inde birleÅŸtirin (katmanlar kullanarak. BirleÅŸtirin) ve TÄ±bbi KaÄŸÄ±t Ã–zetlerinde Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ±'nÄ±n Åekil 1 ve bÃ¶lÃ¼m 4.2'sine Ã§Ä±ktÄ± serisini iletin https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\n",
        "\n",
        "6. 3, 4 ve 5'in Ã§Ä±ktÄ±larÄ±nÄ± bir token-karakter-konumsal tribrid gÃ¶mmede birleÅŸtirin (katmanlar kullanarak. BirleÅŸtirin)\n",
        "\n",
        "7. Tribrid gÃ¶mme ve Ã§Ä±kÄ±ÅŸ tahmin edilen etiket olasÄ±lÄ±klarÄ±nÄ± kabul etmek iÃ§in bir Ã§Ä±ktÄ± katmanÄ± oluÅŸturun\n",
        "\n",
        "8. 1, 2, 3, 4 giriÅŸlerini ve 7'nin Ã§Ä±kÄ±ÅŸlarÄ±nÄ± bir tf.keras.Model'de birleÅŸtirin https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
        "\n",
        "https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "LSTM(32) dokÃ¼mandan gelir, videoda 24 yapmÄ±ÅŸ gerekÃ§esi de karakter gÃ¶mme token 50 ike 25 alÄ±yor, ama 8'in katlarÄ±nÄ± tercih etmek iÃ§in bunu uyguluyor.\n",
        "\n",
        "train_line_numbers_one_hot[0].shape --> 15\n",
        "\n",
        "train_total_lines_one_hot.shape --> (180040,20)\n",
        "\n",
        "4'te model ismi y diye adlandÄ±rÄ±ldÄ±, x ile karÄ±ÅŸtÄ±rmamamk iÃ§in. AyrÄ±ca 32'lik Ã¶zellik vektÃ¶rÃ¼ne gÃ¶mÃ¼lme olur."
      ],
      "metadata": {
        "id": "Li_eIdYWE9Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Token giriÅŸleri\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Karakter giriÅŸleri\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. SatÄ±r numarasÄ± giriÅŸleri\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Toplam satÄ±r giriÅŸleri\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Token ve karakter yerleÅŸtirmelerini hibrit bir yerleÅŸtirmede birleÅŸtirin\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Konumsal yerleÅŸtirmeleri birleÅŸtirilmiÅŸ belirteÃ§ ve karakter yerleÅŸtirmeleriyle bir tribrid yerleÅŸtirmede birleÅŸtirin\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Ã‡Ä±ktÄ± katmanÄ± oluÅŸtur\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Modeli bir araya getir\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)\n",
        "\n",
        "# Model Ã¶zeti\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "BUhOreQAHmC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "e7f2f8cc-89e8-482e-c6d9-2537e956e8da",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Exception encountered when calling layer 'keras_layer_6' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_6' (type KerasLayer):\n  â€¢ inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>\n  â€¢ training=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-a872e6e0cd48>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Token giriÅŸleri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtoken_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"token_inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_hub_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtoken_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m token_model = tf.keras.Model(inputs=token_inputs,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer_6' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_6' (type KerasLayer):\n  â€¢ inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>\n  â€¢ training=None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* char_inputs --> karakter gÃ¶mme\n",
        "* token_inputs --> token dÃ¶mme\n",
        "* line_number_input ve total_line_input --> Ã¶zellik gÃ¶mme"
      ],
      "metadata": {
        "id": "-C3leZpGH0rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirteci, karakteri ve konumsal gÃ¶mme modelini Ã§izin\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_5)"
      ],
      "metadata": {
        "id": "KYOnB4LWH2Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli gÃ¶rselleÅŸtirmek, anlaÅŸÄ±lmayÄ± Ã§ok daha kolay hale getirir.\n",
        "\n",
        "Esasen yaptÄ±ÄŸÄ±mÄ±z ÅŸey, dizilerimiz hakkÄ±nda mÃ¼mkÃ¼n olduÄŸunca fazla bilgiyi Ã§eÅŸitli gÃ¶mmelere (modelimize girdiler) kodlamaya Ã§alÄ±ÅŸmaktÄ±r, bÃ¶ylece modelimiz hangi etiketin bir diziye (modelimizin Ã§Ä±ktÄ±larÄ±) ait olduÄŸunu bulmak iÃ§in en iyi ÅŸansa sahiptir.\n",
        "\n",
        "Modelimizin, TÄ±bbi KaÄŸÄ±t Ã–zetlerinde Ortak CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Sinir AÄŸlarÄ± Åekil 1'de gÃ¶sterilen modele Ã§ok benzediÄŸini fark edeceksiniz. Ancak, hala birkaÃ§ fark devam ediyor: https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "- GloVe emebdding'ler yerine Ã¶nceden eÄŸitilmiÅŸ TensorFlow Hub belirteÃ§ gÃ¶mmeleri kullanÄ±yoruz.\n",
        "\n",
        "- Bi-LSTM katmanÄ± yerine token-karakter hibrit gÃ¶mmelerimizin Ã¼zerinde yoÄŸun bir katman kullanÄ±yoruz.\n",
        "\n",
        "- Makalenin BÃ¶lÃ¼m 3.1.3'Ã¼, bir etiket dizisi optimizasyon katmanÄ±ndan bahseder (bu, dizi etiketlerinin saygÄ±n bir sÄ±rayla Ã§Ä±kmasÄ±nÄ± saÄŸlamaya yardÄ±mcÄ± olur) ancak Åekil 1'de gÃ¶sterilmez. Modelimizde bu katmanÄ±n eksikliÄŸi iÃ§in makyaj yapmak iÃ§in konumsal gÃ¶mme katmanlarÄ±nÄ± oluÅŸturduk.\n",
        "\n",
        "- Makalenin 4.2. BÃ¶lÃ¼mÃ¼, belirteÃ§ ve karakter gÃ¶mmelerinin eÄŸitim sÄ±rasÄ±nda gÃ¼ncellendiÄŸinden bahseder, Ã¶nceden eÄŸitilmiÅŸ TensorFlow Hub gÃ¶mmelerimiz donmuÅŸ kalÄ±r.\n",
        "\n",
        "- KaÄŸÄ±t SGD optimize ediciyi kullanÄ±yor, Adam'a baÄŸlÄ± kalacaÄŸÄ±z.\n",
        "\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "\n",
        "YukarÄ±daki tÃ¼m farklÄ±lÄ±klar bu projenin potansiyel uzantÄ±larÄ±dÄ±r."
      ],
      "metadata": {
        "id": "jtIvT9P0IfnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelimizin hangi katmanlarÄ±nÄ±n eÄŸitilebilir olup olmadÄ±ÄŸÄ±nÄ± kontrol edin\n",
        "for layer in model_5.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "8sh9zvfUIhQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi modelimiz inÅŸa edildi, derleyelim.\n",
        "\n",
        "Bu sefer, kayÄ±p fonksiyonumuza label_smoothing adlÄ± yeni bir parametre tanÄ±tacaÄŸÄ±z. Etiket yumuÅŸatma, bir Ã¶rneÄŸe belirli bir etiket uygulamaya Ã§ok fazla odaklanmadÄ±ÄŸÄ±ndan emin olarak modelimizi dÃ¼zenlemeye (aÅŸÄ±rÄ± takmayÄ± Ã¶nlemeye) yardÄ±mcÄ± olur.\n",
        "\n",
        "Ã–rneÄŸin, bir Ã§Ä±ktÄ± tahminine sahip olmak yerine:\n",
        "\n",
        "- Bir numune iÃ§in [0.0, 0.0, 1.0, 0.0, 0.0] (model, doÄŸru etiketin indeks 2 olduÄŸundan Ã§ok emindir).\n",
        "\n",
        "Tahminler ÅŸÃ¶yle bir ÅŸey olacak ÅŸekilde yumuÅŸatÄ±lacak:\n",
        "\n",
        "- [0.01, 0.01, 0.096, 0.01, 0.01] diÄŸer etiketlerin her birine kÃ¼Ã§Ã¼k bir aktivasyon vererek, umarÄ±m genellemeyi iyileÅŸtirir.\n",
        "\n",
        "ğŸ“– Kaynak: Etiket yumuÅŸatma hakkÄ±nda daha fazla bilgi iÃ§in, PyImageSearch'Ã¼n harika blog gÃ¶nderisine bakÄ±n, Keras, TensorFlow ve Deep Learning ile etiket yumuÅŸatma. https://pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/\n",
        "\n",
        "label smooting --> 0-1 arasÄ± float tÃ¼rÃ¼nde sayÄ±dÄ±r. Etiket deÄŸerleri yumuÅŸatÄ±lmÄ±ÅŸtÄ±r. Etiket deÄŸerine olan gÃ¼venirlilik esnektir. Ã–rneÄŸin bu deÄŸer 0.2 ise bir 0 etiketi iÃ§in 0.1 ve 1 etiketi iÃ§in 0.9 kullanÄ±lÄ±r.\n",
        "\n",
        "SÄ±fÄ±rda, bir sÄ±fÄ±r noktasÄ±nda takÄ±lÄ±rsa, Ã¶ÄŸrenmeyi tamamen durdurabilir Ã§Ã¼nkÃ¼ model der ki ben sadece 1.0 olanÄ± Ã¶ÄŸreneceÄŸim, diÄŸerleri unutulabilir.\n",
        "\n",
        "Ama yumuÅŸatÄ±lmÄ±ÅŸta model 0.01'de sÄ±kÄ±ÅŸÄ±p kalmaz, daha saÄŸlÄ±klÄ± tahminler...\n",
        "\n",
        "Etiket yumuÅŸatmasÄ± olan bu iÅŸlevi kullanabilmek iÃ§in etiketlerimize tek bir sÄ±cak kodlama biÃ§iminde ihtiyacÄ±mÄ±z vardÄ±."
      ],
      "metadata": {
        "id": "HMjBdGvrInhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BelirteÃ§, karakter ve konumsal gÃ¶mme modelini derleyin\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # etiket yumuÅŸatma ekleyin (gerÃ§ekten kendine gÃ¼venen Ã¶rnekler biraz yumuÅŸatÄ±lÄ±r)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "raX_NfJVIshF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tribrid gÃ¶mme veri kÃ¼meleri oluÅŸturun ve tribrid modelini sÄ±ÄŸdÄ±rÄ±n**\n",
        "\n",
        "Bu sefer modelimiz dÃ¶rt Ã¶zellik giriÅŸi gerektiriyor:\n",
        "\n",
        "1. EÄŸitim hattÄ± numaralarÄ± tek sÄ±cak tensÃ¶r (train_line_numbers_one_hot)\n",
        "\n",
        "2. EÄŸitim toplam hatlarÄ± bir-sÄ±cak tensÃ¶r (train_total_lines_one_hot)\n",
        "\n",
        "3. Token-seviye dizileri tensÃ¶rÃ¼ (train_sentences)\n",
        "\n",
        "4. Char-level dizileri tensÃ¶rÃ¼ (train_chars)\n",
        "\n",
        "Uygun ÅŸekilde ÅŸekillendirilmiÅŸ ve toplu PrefetchedDataset'ler oluÅŸturmak iÃ§in bunlarÄ± tf.data.Dataset.from_tensor_slices() yÃ¶ntemimize demet olarak aktarabiliriz."
      ],
      "metadata": {
        "id": "XhfjFl1WI1MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitim ve doÄŸrulama veri kÃ¼meleri oluÅŸturun (dÃ¶rt tÃ¼r girdinin tÃ¼mÃ¼)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # satÄ±r numarasÄ±\n",
        "                                                                train_total_lines_one_hot, # toplam satÄ±rlar\n",
        "                                                                train_sentences, # eÄŸitim tokenleri\n",
        "                                                                train_chars)) # eÄŸitim karakterleri\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # eÄŸitim etiketleri\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # veri ve etiketleri birleÅŸtir\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # gruplara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n ve uygun ÅŸekilde Ã¶nceden getirin\n",
        "\n",
        "# DoÄŸrulama veri kÃ¼mesi\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # gruplara dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n ve uygun ÅŸekilde Ã¶nceden getirin\n",
        "\n",
        "# GiriÅŸ ÅŸekillerini kontrol edin\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset\n",
        "\n",
        "# Belirteci, karakteri ve konumsal gÃ¶mme modelini takÄ±n\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
      ],
      "metadata": {
        "id": "H5CasYHFI_zE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "collapsed": true,
        "outputId": "55278ded-da1b-4f83-a2fc-7582e9eea99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_5' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-fce7297ceb32>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Belirteci, karakteri ve konumsal gÃ¶mme modelini takÄ±n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history_model_5 = model_5.fit(train_pos_char_token_dataset,\n\u001b[0m\u001b[1;32m     24\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pos_char_token_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_5' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BelirteÃ§-karakter-konumsal hibrit modelle tahminler yapÄ±n\n",
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ],
      "metadata": {
        "id": "-ksTPa__I_vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasÄ±lÄ±klarÄ±nÄ± tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "id": "4GiTVX7UJHHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BelirteÃ§-karakter-konumsal hibrit modelin sonuÃ§larÄ±nÄ± hesaplayÄ±n\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "K0JyqPRgJHDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model SonuÃ§larÄ±nÄ± KarÅŸÄ±laÅŸtÄ±r**"
      ],
      "metadata": {
        "id": "X0Wpqr5pj453"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model sonuÃ§larÄ±nÄ± bir DataFrame'de birleÅŸtirin\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
        "                                  \"pretrained_token_embed\": model_2_results,\n",
        "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
        "                                  \"hybrid_char_token_embed\": model_4_results,\n",
        "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "gKjUX9iWKItN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3b824fcd-f81c-4f70-8039-3a749708c3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_1_results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-1dd819eba5ab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model sonuÃ§larÄ±nÄ± bir DataFrame'de birleÅŸtirin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n\u001b[0;32m----> 3\u001b[0;31m                                   \u001b[0;34m\"custom_token_embed_conv1d\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_1_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                   \u001b[0;34m\"pretrained_token_embed\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_2_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0;34m\"custom_char_embed_conv1d\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_3_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_1_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DoÄŸruluÄŸu diÄŸer Ã¶lÃ§Ã¼mlerle aynÄ± Ã¶lÃ§eÄŸe dÃ¼ÅŸÃ¼rÃ¼n\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "jqgTmVXQKilu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TÃ¼m model sonuÃ§larÄ±nÄ± Ã§izin ve karÅŸÄ±laÅŸtÄ±rÄ±n\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "id": "3hPNgcX_KiiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model sonuÃ§larÄ±nÄ± f1 puanÄ±na gÃ¶re sÄ±ralayÄ±n\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "id": "t_JExj_JKp_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-scores'a dayanarak, tribrid gÃ¶mme modelimiz adil bir farkla en iyi performansÄ± sergiliyor gibi gÃ¶rÃ¼nÃ¼yor.\n",
        "\n",
        "Bununla birlikte, PubMed 200k RCT'nin Tablo 3'Ã¼nde bildirilen sonuÃ§larla karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda: TÄ±bbi Ã–zetler makalesinde SÄ±ralÄ± CÃ¼mle SÄ±nÄ±flandÄ±rmasÄ± iÃ§in Bir Veri KÃ¼mesi, modelimizin F1-skoru hala dÃ¼ÅŸÃ¼k performans gÃ¶steriyor (yazar modeli, ~82.6'lÄ±k F1 skorumuza karÅŸÄ± 20k RCT veri kÃ¼mesinde 90.0'lÄ±k bir F1 puanÄ± elde ediyor). https://arxiv.org/pdf/1710.06071\n",
        "\n",
        "Bu fark hakkÄ±nda dikkat edilmesi gereken bazÄ± ÅŸeyler var:\n",
        "\n",
        "- Modellerimiz (taban Ã§izgisi hariÃ§), 20k RCT veri kÃ¼mesindeki tam ~180.000 yerine ~18.000 (partilerin %10'u) dizi ve etiket Ã¶rneÄŸi Ã¼zerinde eÄŸitilmiÅŸtir.\n",
        "\n",
        "  - Bununla birlikte, makine Ã¶ÄŸrenimi deneylerinde genellikle durum bÃ¶yledir, eÄŸitimin daha az sayÄ±da Ã¶rnek Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olun, ardÄ±ndan gerektiÄŸinde yÃ¼kseltin (bu projenin bir uzantÄ±sÄ±, tam veri kÃ¼mesinde bir model eÄŸitecektir).\n",
        "\n",
        "- Modelimizin tahmin performans seviyeleri, test veri kÃ¼mesinde deÄŸil, doÄŸrulama veri kÃ¼mesinde deÄŸerlendirilmiÅŸtir (en iyi modelimizi kÄ±sa sÃ¼re iÃ§inde test veri kÃ¼mesinde deÄŸerlendireceÄŸiz)."
      ],
      "metadata": {
        "id": "ClYQ_b-4K3Sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Model Kaydetme ve YÃ¼kleme**"
      ],
      "metadata": {
        "id": "UO4VfrMFj43n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ã‡ok az deney yaptÄ±ÄŸÄ±mÄ±z iÃ§in, en iyi performans gÃ¶steren modelimizi kaydetmek iyi bir fikirdir, bÃ¶ylece onu yeniden eÄŸitmek zorunda kalmadan yeniden kullanabiliriz.\n",
        "\n",
        "Ãœzerinde save() yÃ¶ntemini Ã§aÄŸÄ±rarak en iyi performans gÃ¶steren modelimizi kaydedebiliriz. https://www.tensorflow.org/guide/keras/serialization_and_saving#the_short_answer_to_saving_loading\n",
        "\n",
        "Modeli kaydettiÄŸinde model kaydedilir ve veri kÃ¼mesini deÄŸerlendirdiÄŸinde onu tekrar yÃ¼klemiÅŸ olursun.\n",
        "\n",
        "Bu modeli kaydedip colab dÄ±ÅŸÄ±nda baÅŸka bir yerde kullanabilmeliyiz."
      ],
      "metadata": {
        "id": "44p9qpHhLEtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En iyi performans gÃ¶steren modeli SavedModel formatÄ±na kaydedin (varsayÄ±lan)\n",
        "model_5.save(\"skimlit_tribrid_model\") # model dizeyle belirtilen yola kaydedilecek"
      ],
      "metadata": {
        "id": "Y1_I9C-FLN8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ä°steÄŸe baÄŸlÄ±: Google Colab kullanÄ±yorsanÄ±z, daha kalÄ±cÄ± depolama iÃ§in kayÄ±tlÄ± modelinizi Google Drive'a kopyalamak (veya indirmek) isteyebilirsiniz (baÄŸlantÄ±nÄ±zÄ± kestikten sonra Google Colab dosyalarÄ± kaybolur). https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh"
      ],
      "metadata": {
        "id": "lnUPeJLBLPH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaydedilen modelin Google Colab'dan Drive'a kopyalanmasÄ±na Ã¶rnek (Google Drive'Ä±n takÄ±lÄ± olmasÄ±nÄ± gerektirir)\n",
        "# !cp skimlit_best_model -r /content/drive/MyDrive/tensorflow_course/skim_lit"
      ],
      "metadata": {
        "id": "p_7hEtnMLSx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TÃ¼m iyi yemek piÅŸirme ÅŸovlarÄ± gibi, Ã¶nceden eÄŸitilmiÅŸ bir modelimiz var (tam olarak Google Drive ve Google Storage'da kaydedilen ve saklanan model_5 iÃ§in oluÅŸturduÄŸumuz aynÄ± tÃ¼r model). https://drive.google.com/file/d/1quaeTYEzwolI0dXv98S9GEXOTVu9Akfk/view\n",
        "\n",
        "Bu nedenle, deÄŸerlendirme iÃ§in hepimizin aynÄ± modeli kullandÄ±ÄŸÄ±mÄ±zdan emin olmak iÃ§in onu indirip yÃ¼kleyeceÄŸiz.\n",
        "\n",
        "Ve modelimize yÃ¼klerken, birkaÃ§ Ã¶zel nesne (TensorFlow Hub katmanÄ±mÄ±z ve TextVectorization katmanÄ±mÄ±z) kullandÄ±ÄŸÄ±ndan, bunlarÄ± tf.keras.models.load_model()'Ä±n custom_objects parametresinde belirterek yÃ¼klememiz gerekecek.\n",
        "\n",
        "- https://www.tensorflow.org/guide/keras/serialization_and_saving#custom_objects\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model"
      ],
      "metadata": {
        "id": "Yg13s_RPLV5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Depolama AlanÄ±ndan Ã¶nceden eÄŸitilmiÅŸ modeli indirin\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
        "!mkdir skimlit_gs_model\n",
        "!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"
      ],
      "metadata": {
        "id": "5WWuzIxgLY0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow modeli baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± iÃ§e aktarÄ±n (gerekirse) - https://github.com/tensorflow/tensorflow/issues/38250\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "model_path = \"skimlit_gs_model/skimlit_tribrid_model/\"\n",
        "\n",
        "# Ä°ndirilen modeli Google Depolama AlanÄ±ndan yÃ¼kle\n",
        "loaded_model = tf.keras.models.load_model(model_path)\n",
        "                                          # Not: TensorFlow 2.5+ ile SavedModel'inizde keras_metadata.pb dosyasÄ± varsa\n",
        "                                          # (model.save() kullanÄ±lÄ±rken oluÅŸturulur), Ã¶zel_nesnelere ihtiyacÄ±nÄ±z olmamalÄ±dÄ±r\n",
        "                                          # parametre. YapmanÄ±z durumunda kodu aÅŸaÄŸÄ±ya bÄ±rakÄ±yorum.\n",
        "                                          #custom_objects={\"TextVectorization\": TextVectorization, # karakter vektÃ¶rleÅŸtirmesi iÃ§in gereklidir\n",
        "                                          # \"KerasLayer\": hub.KerasLayer}) # belirteÃ§ yerleÅŸtirme iÃ§in gerekli"
      ],
      "metadata": {
        "id": "FSsq-qLbLewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dosyada oluÅŸan modele saÄŸ tÄ±k yaparsan istediÄŸin yÃ¼kleme seÃ§enekleri Ã§Ä±kmaz.\n",
        "\n",
        "YÃ¼klÃ¼ modeli test etmenin yollarÄ±ndan birisi de tahmin yapÄ±p karÅŸÄ±laÅŸtÄ±rmaktÄ±r. Bu tahminler result kodundaki sonuÃ§lar ile Ã§ok yakÄ±n olmalÄ±."
      ],
      "metadata": {
        "id": "Clt3zOhwLhet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. DeÄŸerlendirme**"
      ],
      "metadata": {
        "id": "3cawrazvj41R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin doÄŸru bir ÅŸekilde kaydedildiÄŸinden ve yÃ¼klendiÄŸinden emin olmak iÃ§in, onunla tahminlerde bulunalÄ±m, deÄŸerlendirelim ve ardÄ±ndan daha Ã¶nce hesapladÄ±ÄŸÄ±mÄ±z tahmin sonuÃ§larÄ±yla karÅŸÄ±laÅŸtÄ±ralÄ±m.\n",
        "\n",
        "Bir model ile sadece eÄŸitim aldÄ±ÄŸÄ± veri formatÄ±yla aynÄ± formatta tahminler yapÄ±labilir.\n",
        "\n",
        "Kaynak ÅŸablonundaki veri tablolarÄ± google depolama alanÄ±nda kayÄ±tlÄ±dÄ±r. Buradan veri almak iÃ§in saÄŸ tÄ±k link kopyala yap. (learntensorflow.io) Bu link !wget...unzip komutlarÄ± ile yÃ¼klenebilir. -d dizin demek."
      ],
      "metadata": {
        "id": "mroVT5nYMDi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1. DoÄŸrulama Veri Setini DeÄŸerlendir**"
      ],
      "metadata": {
        "id": "DpDJaWtUj4y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DoÄŸrulama setindeki yÃ¼klÃ¼ modelle tahminler yapÄ±n\n",
        "loaded_pred_probs = loaded_model.predict(val_pos_char_token_dataset, verbose=1)\n",
        "loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n",
        "loaded_preds[:10]"
      ],
      "metadata": {
        "id": "cwzeRgKsMJWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YÃ¼klenen modelin tahminlerini deÄŸerlendirin\n",
        "loaded_model_results = calculate_results(val_labels_encoded,\n",
        "                                         loaded_preds)\n",
        "loaded_model_results"
      ],
      "metadata": {
        "id": "B9N_rvuwMJRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YÃ¼klenen model sonuÃ§larÄ±nÄ± orijinal eÄŸitilmiÅŸ model sonuÃ§larÄ±yla karÅŸÄ±laÅŸtÄ±rÄ±n (oldukÃ§a yakÄ±n olmalÄ±dÄ±r)\n",
        "np.isclose(list(model_5_results.values()), list(loaded_model_results.values()), rtol=1e-02)"
      ],
      "metadata": {
        "id": "DMRnKJfgMLn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YÃ¼klenen model Ã¶zetini kontrol edin (eÄŸitilebilir parametrelerin sayÄ±sÄ±nÄ± not edin)\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "VNQhtubUMLj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KaydedilmiÅŸ bir Model'e yÃ¼klemenin tÃ¼m katmanlarÄ± Ã§Ã¶zdÃ¼ÄŸÃ¼nÃ¼ (hepsini eÄŸitilebilir hale getirdiÄŸini) belirtmekte fayda var. Bu nedenle, herhangi bir katmanÄ± dondurmak istiyorsanÄ±z, eÄŸitilebilir Ã¶zelliklerini False olarak ayarlamanÄ±z gerekir."
      ],
      "metadata": {
        "id": "CFojRoCCMQsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2. Test Veri Setinde Modeli DeÄŸerlendir**"
      ],
      "metadata": {
        "id": "163xCEfGj4wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin performansÄ±nÄ± PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts makalesinin Tablo 3'Ã¼nde bildirilen sonuÃ§larla daha karÅŸÄ±laÅŸtÄ±rÄ±labilir hale getirmek iÃ§in, test veri kÃ¼mesi hakkÄ±nda tahminlerde bulunalÄ±m ve bunlarÄ± deÄŸerlendirelim. https://arxiv.org/pdf/1710.06071"
      ],
      "metadata": {
        "id": "nqV35BVoMc06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test veri kÃ¼mesi kÃ¼mesi oluÅŸturun ve Ã¶nceden getirildi\n",
        "test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
        "                                                               test_total_lines_one_hot,\n",
        "                                                               test_sentences,\n",
        "                                                               test_chars))\n",
        "test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n",
        "test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Åekilleri kontrol edin\n",
        "test_pos_char_token_dataset"
      ],
      "metadata": {
        "id": "RTjmfluCMfLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test veri kÃ¼mesi Ã¼zerinde tahminler yapÄ±n\n",
        "test_pred_probs = loaded_model.predict(test_pos_char_token_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
        "test_preds[:10]"
      ],
      "metadata": {
        "id": "biV13K1vMfIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YÃ¼klÃ¼ model test tahminlerini deÄŸerlendirin\n",
        "loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                              y_pred=test_preds)\n",
        "loaded_model_test_results"
      ],
      "metadata": {
        "id": "--HxtalYMfFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re (ÅŸimdiye kadarki en iyi modelimiz) kaÄŸÄ±ttaki sonuÃ§larÄ±n performansÄ±nÄ± eÅŸleÅŸtirmek iÃ§in hala bazÄ± yollara sahip (onlarÄ±n modeli test veri kÃ¼mesinde 90.0 F1 puanÄ± alÄ±r, bizimki de ~82.1 F1 puanÄ± alÄ±r).\n",
        "\n",
        "Bununla birlikte, daha Ã¶nce tartÄ±ÅŸtÄ±ÄŸÄ±mÄ±z gibi, modelimiz RCT 20k veri kÃ¼mesindeki toplam ~180.000 dizinin yalnÄ±zca 20.000'inde eÄŸitilmiÅŸtir. AyrÄ±ca Ã¶nceden eÄŸitilmiÅŸ gÃ¶mmelerimizi (kaÄŸÄ±t ince ayarlÄ± GloVe gÃ¶mmeleri) ince ayar yapmadÄ±k. SonuÃ§larÄ±mÄ±zÄ± iyileÅŸtirmek iÃ§in deneyebileceÄŸimiz birkaÃ§ uzantÄ± var."
      ],
      "metadata": {
        "id": "1Evv65cwMm1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3. En Ã‡ok YanlÄ±ÅŸÄ± Bul**"
      ],
      "metadata": {
        "id": "XTrjtxcRj4uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelinizin nerede yanlÄ±ÅŸ gittiÄŸini (veya potansiyel olarak verilerinizin nerede yanlÄ±ÅŸ olduÄŸunu) araÅŸtÄ±rmanÄ±n en iyi yollarÄ±ndan biri, \"en yanlÄ±ÅŸ\" tahminleri gÃ¶rselleÅŸtirmektir.\n",
        "\n",
        "En yanlÄ±ÅŸ tahminler, modelin yÃ¼ksek olasÄ±lÄ±klÄ± bir tahminde bulunduÄŸu ancak yanlÄ±ÅŸ anladÄ±ÄŸÄ± Ã¶rneklerdir (modelin tahmini, temel doÄŸruluk etiketiyle aynÄ± fikirde deÄŸildir).\n",
        "\n",
        "En yanlÄ±ÅŸ tahminlere bakmak, daha fazla modeli nasÄ±l geliÅŸtireceÄŸimiz veya verilerimizdeki etiketleri nasÄ±l dÃ¼zelteceÄŸimiz konusunda bize deÄŸerli bilgiler verebilir.\n",
        "\n",
        "Test veri kÃ¼mesinden en yanlÄ±ÅŸ tahminleri gÃ¶rselleÅŸtirmemize yardÄ±mcÄ± olacak bazÄ± kodlar yazalÄ±m.\n",
        "\n",
        "Ã–nce tÃ¼m tamsayÄ± tabanlÄ± test tahminlerimizi dize tabanlÄ± sÄ±nÄ±f adlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz."
      ],
      "metadata": {
        "id": "PUPyCbzHMyQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Test tahminlerinin sÄ±nÄ±f adlarÄ±nÄ±n listesini alÄ±n\n",
        "test_pred_classes = [label_encoder.classes_[pred] for pred in test_preds]\n",
        "test_pred_classes"
      ],
      "metadata": {
        "id": "8vu2RfkbM1R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi test DataFame'imizi birkaÃ§ deÄŸerle zenginleÅŸtireceÄŸiz:\n",
        "\n",
        "1. Belirli bir Ã¶rnek iÃ§in modelimizin tahminini iÃ§eren bir \"tahmin\" (dize) sÃ¼tunu.\n",
        "\n",
        "2. Belirli bir Ã¶rnek iÃ§in modelin maksimum tahmin olasÄ±lÄ±ÄŸÄ±nÄ± iÃ§eren bir \"pred_prob\" (float) sÃ¼tunu.\n",
        "\n",
        "3. Modelin tahmininin numunenin hedef etiketiyle eÅŸleÅŸip eÅŸleÅŸmediÄŸini gÃ¶steren bir \"doÄŸru\" (bool) sÃ¼tunu."
      ],
      "metadata": {
        "id": "4FhTMPm1M6gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminle zenginleÅŸtirilmiÅŸ test veri Ã§erÃ§evesi oluÅŸturun\n",
        "test_df[\"prediction\"] = test_pred_classes # test tahmin sÄ±nÄ±fÄ± adlarÄ±nÄ± iÃ§eren sÃ¼tun oluÅŸturun\n",
        "test_df[\"pred_prob\"] = tf.reduce_max(test_pred_probs, axis=1).numpy() # Maksimum tahmin olasÄ±lÄ±ÄŸÄ±nÄ± elde edin\n",
        "test_df[\"correct\"] = test_df[\"prediction\"] == test_df[\"target\"] # tahminin doÄŸru olup olmadÄ±ÄŸÄ±na iliÅŸkin ikili sÃ¼tun oluÅŸturun\n",
        "test_df.head(20)"
      ],
      "metadata": {
        "id": "mwSihef_M83u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En yanlÄ±ÅŸ 100 Ã¶rneÄŸi bulun (not: 100 ikili bir sayÄ±dÄ±r, isterseniz hepsini inceleyebilirsiniz)\n",
        "top_100_wrong = test_df[test_df[\"correct\"] == False].sort_values(\"pred_prob\", ascending=False)[:100]\n",
        "top_100_wrong"
      ],
      "metadata": {
        "id": "nF-VSwrjM_-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En Ã§ok yanlÄ±ÅŸ tercihleri â€‹â€‹araÅŸtÄ±rÄ±n\n",
        "for row in top_100_wrong[0:10].itertuples(): # farklÄ± Ã¶rnekleri gÃ¶rÃ¼ntÃ¼lemek iÃ§in dizinleri ayarlayÄ±n\n",
        "  _, target, text, line_number, total_lines, prediction, pred_prob, _ = row\n",
        "  print(f\"Hedef: {target}, Pred: {prediction}, Tahmin: {pred_prob}, SatÄ±r numarasÄ±: {line_number}, Toplam satÄ±r sayÄ±sÄ±: {total_lines}\\n\")\n",
        "  print(f\"CÃ¼mle:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "metadata": {
        "id": "rrgQJWhvM_6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En yanlÄ±ÅŸ tahminler hakkÄ±nda ne fark ediyorsunuz? Model aptalca hatalar yapÄ±yor mu? Veya bazÄ± etiketler yanlÄ±ÅŸ/belirsiz mi (Ã¶rneÄŸin, soyuttaki bir satÄ±r potansiyel olarak HEDEF veya ARKA PLAN olarak etiketlenebilir ve mantÄ±klÄ± olabilir).\n",
        "\n",
        "Buradaki bir sonraki adÄ±m, tutarsÄ±z etiketlere sahip birkaÃ§ Ã¶rnek varsa, eÄŸitim veri kÃ¼menizi gÃ¶zden geÃ§irebilir, etiketleri gÃ¼ncelleyebilir ve ardÄ±ndan bir modeli yeniden eÄŸitebilirsiniz. Veri kÃ¼menizin etiketlerini iyileÅŸtirmeye/araÅŸtÄ±rmaya yardÄ±mcÄ± olacak bir model kullanma sÃ¼reci genellikle aktif Ã¶ÄŸrenme olarak adlandÄ±rÄ±lÄ±r."
      ],
      "metadata": {
        "id": "Hn21riYDNE_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.4. Ã–rnek Tahminler Yap**"
      ],
      "metadata": {
        "id": "MdOKNl6_j4r7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tamam, test veri kÃ¼mesi hakkÄ±nda bazÄ± tahminlerde bulunduk, ÅŸimdi modelimizi gerÃ§ekten test etme zamanÄ±.\n",
        "\n",
        "Bunu yapmak iÃ§in, vahÅŸi doÄŸadan bazÄ± veriler alacaÄŸÄ±z ve modelimizin nasÄ±l performans gÃ¶sterdiÄŸini gÃ¶receÄŸiz.\n",
        "\n",
        "BaÅŸka bir deyiÅŸle, PubMed'den bir RCT Ã¶zeti bulacak, metni modelimizle Ã§alÄ±ÅŸmasÄ± iÃ§in Ã¶nceden iÅŸleyecek, ardÄ±ndan hangi etiketi tahmin ettiÄŸini gÃ¶rmek iÃ§in vahÅŸi soyuttaki her diziyi modelimizden geÃ§irecektik.\n",
        "\n",
        "Uygun bir Ã¶rnek iÃ§in, bÃ¶lÃ¼nmÃ¼ÅŸ Ã¶zetler olmadan RCT'ler (randomize kontrollÃ¼ Ã§alÄ±ÅŸmalar) iÃ§in PubMed'i aramamÄ±z gerekecek (PubMed'i keÅŸfederken, Ã¶zetlerin Ã§oÄŸunun zaten ayrÄ± bÃ¶lÃ¼mlere Ã¶nceden biÃ§imlendirilmiÅŸ olduÄŸunu fark edeceksiniz, bu okunabilirliÄŸe Ã¶nemli Ã¶lÃ§Ã¼de yardÄ±mcÄ± olur).\n",
        "\n",
        "Ã‡eÅŸitli PubMed Ã§alÄ±ÅŸmalarÄ±ndan geÃ§erken, yÃ¼ksek iÅŸlevli otizm spektrum bozukluklarÄ± iÃ§in manuelleÅŸtirilmiÅŸ bir sosyal tedavinin RCT'den aÅŸaÄŸÄ±daki yapÄ±landÄ±rÄ±lmamÄ±ÅŸ Ã¶zetini bulmayÄ± baÅŸardÄ±m: https://pubmed.ncbi.nlm.nih.gov/20232240/\n",
        "\n",
        "Orjinali:\n",
        "\n",
        "This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n",
        "\n",
        "Ã‡evirisi:\n",
        "\n",
        "Bu RCT, HFASD'li Ã§ocuklar iÃ§in manuelleÅŸtirilmiÅŸ bir sosyal mÃ¼dahalenin etkinliÄŸini incelemiÅŸtir. KatÄ±lÄ±mcÄ±lar rastgele tedavi veya bekleme listesi koÅŸullarÄ±na atandÄ±. Tedavi, sosyal becerileri, yÃ¼z-duygu tanÄ±mayÄ±, ilgi alanÄ±nÄ± geniÅŸletmeyi ve edebi olmayan dilin yorumlanmasÄ±nÄ± hedefleyen Ã¶ÄŸretim ve terapÃ¶tik faaliyetleri iÃ§eriyordu. Sorunlu davranÄ±ÅŸlarÄ± azaltmak ve beceri edinimini teÅŸvik etmek iÃ§in bir response-cost programÄ± uygulandÄ±. Yedi birincil sonuÃ§ Ã¶lÃ§Ã¼tÃ¼nÃ¼n beÅŸi (ebeveyn derecelendirmeleri ve doÄŸrudan Ã§ocuk Ã¶lÃ§Ã¼mleri) iÃ§in Ã¶nemli tedavi etkileri bulundu. Personel derecelendirmelerine (yalnÄ±zca tedavi grubu) dayalÄ± ikincil Ã¶nlemler, ebeveynler tarafÄ±ndan bildirilen kazanÄ±mlarÄ± doÄŸruladÄ±. YÃ¼ksek dÃ¼zeyde tedavi sadakati ile birlikte yÃ¼ksek dÃ¼zeyde ebeveyn, Ã§ocuk ve personel memnuniyeti bildirilmiÅŸtir. StandartlaÅŸtÄ±rÄ±lmÄ±ÅŸ etki boyutu tahminleri Ã¶ncelikle orta ve bÃ¼yÃ¼k aralÄ±klardaydÄ± ve tedavi grubunu tercih etti.\n",
        "\n",
        "BÃ¼yÃ¼k metin yÄ±ÄŸÄ±nÄ±na bakmak oldukÃ§a korkutucu gÃ¶rÃ¼nebilir. Åimdi, Ã§alÄ±ÅŸmanÄ±zla ilgili bir Ã§alÄ±ÅŸma bulmak iÃ§in literatÃ¼rÃ¼ gÃ¶zden geÃ§irmeye Ã§alÄ±ÅŸan bir tÄ±p araÅŸtÄ±rmacÄ±sÄ± olduÄŸunuzu hayal edin.\n",
        "\n",
        "OldukÃ§a zor gÃ¶rÃ¼nÃ¼yor deÄŸil mi?\n",
        "\n",
        "SkimLit'e girin ğŸ¤“ğŸ”¥!\n",
        "\n",
        "Åimdiye kadarki en iyi modelimizin (model_5) yukarÄ±daki soyuttan ne yaptÄ±ÄŸÄ±nÄ± gÃ¶relim.\n",
        "\n",
        "Ama bekle...\n",
        "\n",
        "Tahmin edebileceÄŸiniz gibi, yukarÄ±daki Ã¶zet, modelimizin eÄŸitildiÄŸi verilerle aynÄ± yapÄ±da biÃ§imlendirilmemiÅŸtir. Bu nedenle, Ã¼zerinde bir tahminde bulunmadan Ã¶nce, tÄ±pkÄ± diÄŸer dizilerimiz olduÄŸu gibi onu Ã¶nceden iÅŸlememiz gerekir.\n",
        "\n",
        "Daha spesifik olarak, her Ã¶zet iÃ§in ÅŸunlarÄ± yapmamÄ±z gerekecek:\n",
        "\n",
        "- CÃ¼mlelere (satÄ±rlara) bÃ¶lÃ¼n.\n",
        "\n",
        "- Karakterlere bÃ¶lÃ¼n.\n",
        "\n",
        "- Her satÄ±rÄ±n numarasÄ±nÄ± bulun.\n",
        "\n",
        "- Toplam satÄ±r sayÄ±sÄ±nÄ± bulun.\n",
        "\n",
        "1 numaradan baÅŸlayarak, Ã¶zetlerimizi gerÃ§ek cÃ¼mlelere bÃ¶lmenin birkaÃ§ yolu vardÄ±r. Basit bir tanesi, Python'un in-built split() string yÃ¶ntemini kullanmak ve bir fullstop'un gÃ¶rÃ¼ndÃ¼ÄŸÃ¼ her yerde Ã¶zeti bÃ¶lmek olacaktÄ±r. Ancak, bunun nerede yanlÄ±ÅŸ gidebileceÄŸini hayal edebiliyor musunuz?\n",
        "\n",
        "BaÅŸka bir daha geliÅŸmiÅŸ seÃ§enek, spaCy'nin (Ã§ok gÃ¼Ã§lÃ¼ bir NLP kitaplÄ±ÄŸÄ±) sentencizer sÄ±nÄ±fÄ±ndan yararlanmak olacaktÄ±r. SpaCy'nin Ä°ngilizce dil modeline dayanan kullanÄ±mÄ± kolay bir cÃ¼mle ayÄ±rÄ±cÄ±dÄ±r.\n",
        "\n",
        "- https://spacy.io/\n",
        "- https://spacy.io/usage/linguistic-features#sbd\n",
        "- https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "Modelimizi denemek iÃ§in PubMed RCT makalelerinden bazÄ± Ã¶zetler hazÄ±rladÄ±m, GitHub'dan indirebiliriz."
      ],
      "metadata": {
        "id": "6cJwYEvANpPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Ã–rnek Ã¶zetleri indirin ve aÃ§Ä±n (PubMed'den kopyalayÄ±p yapÄ±ÅŸtÄ±rÄ±n)\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
        "  example_abstracts = json.load(f)\n",
        "\n",
        "example_abstracts"
      ],
      "metadata": {
        "id": "nKQ_N5jONsyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek Ã¶zetlerimizin neye benzediÄŸini gÃ¶rÃ¼n\n",
        "abstracts = pd.DataFrame(example_abstracts)\n",
        "abstracts"
      ],
      "metadata": {
        "id": "Zm2u_l8HN21o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ¼mle oluÅŸturucu oluÅŸturun - Kaynak: https://spacy.io/usage/linguistic-features#sbd\n",
        "from spacy.lang.en import English\n",
        "nlp = English() # setup English sentence parser\n",
        "\n",
        "# spaCy'nin yeni versiyonu\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\") # cÃ¼mle bÃ¶lme boru hattÄ± nesnesi oluÅŸtur\n",
        "\n",
        "# AyrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ dizilerin \"belgesini\" oluÅŸturun, farklÄ± bir Ã¶zet iÃ§in dizini deÄŸiÅŸtirin\n",
        "doc = nlp(example_abstracts[0][\"abstract\"])\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)] # dize tÃ¼rÃ¼nde belgeden tespit edilen cÃ¼mleleri dÃ¶ndÃ¼r (spaCy belirteÃ§ tÃ¼rÃ¼ deÄŸil)\n",
        "abstract_lines"
      ],
      "metadata": {
        "id": "afnc2_kdN4vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GÃ¼zel! SpaCy, Ã¶zetteki cÃ¼mleleri doÄŸru bir ÅŸekilde bÃ¶lmÃ¼ÅŸ gibi gÃ¶rÃ¼nÃ¼yor. Bununla birlikte, ayrÄ± cÃ¼mlelere mÃ¼kemmel bir ÅŸekilde bÃ¶lÃ¼nmeyen daha karmaÅŸÄ±k Ã¶zetler olabileceÄŸi unutulmamalÄ±dÄ±r (Baclofen'deki Ã¶rnek gibi, hepatit C virÃ¼sÃ¼ (HCV) enfeksiyonu olan alkol baÄŸÄ±mlÄ± sirotik hastalarda alkol yoksunluÄŸunu teÅŸvik eder), bu durumda, daha Ã¶zel bÃ¶lme tekniklerinin araÅŸtÄ±rÄ±lmasÄ± gerekir. https://pubmed.ncbi.nlm.nih.gov/22244707/\n",
        "\n",
        "Åimdi Ã¶zetimiz cÃ¼mlelere bÃ¶lÃ¼ndÃ¼, toplam satÄ±rlarÄ±n yanÄ± sÄ±ra satÄ±r sayÄ±larÄ±nÄ± da saymak iÃ§in biraz kod yazmaya ne dersiniz?\n",
        "\n",
        "Bunu yapmak iÃ§in, preprocess_text_with_line_numbers() iÅŸlevimizin bazÄ± iÅŸlevlerinden yararlanabiliriz."
      ],
      "metadata": {
        "id": "5EfzFjniN7wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Toplam satÄ±r sayÄ±sÄ±nÄ± al\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Ã–zet olarak her satÄ±rÄ± gÃ¶zden geÃ§irin ve her satÄ±r iÃ§in Ã¶zellikler iÃ§eren sÃ¶zlÃ¼klerin bir listesini oluÅŸturun\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "id": "y6sCauQ-N-Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Åimdi \"line_number\" ve \"total_lines\" deÄŸerlerimiz var, onlarÄ± tf.one_hot ile tek sÄ±cak kodlayabiliriz, tÄ±pkÄ± eÄŸitim veri kÃ¼memizde yaptÄ±ÄŸÄ±mÄ±z gibi (derinlik parametresi iÃ§in aynÄ± deÄŸerleri kullanarak)."
      ],
      "metadata": {
        "id": "1tNyjLVYOARq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek Ã¶zetteki tÃ¼m satÄ±r_numarasÄ± deÄŸerlerini alÄ±n\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "# EÄŸitim verileriyle aynÄ± derinliÄŸe kadar tek seferde kodlama, bÃ¶ylece model doÄŸru giriÅŸ ÅŸeklini kabul eder\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
        "test_abstract_line_numbers_one_hot"
      ],
      "metadata": {
        "id": "hMCoiyvOOBvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek Ã¶zetten tÃ¼m total_lines deÄŸerlerini alÄ±n\n",
        "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
        "\n",
        "# EÄŸitim verileriyle aynÄ± derinliÄŸe kadar tek sÄ±cak kodlama, bÃ¶ylece model doÄŸru giriÅŸ ÅŸeklini kabul eder\n",
        "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
        "test_abstract_total_lines_one_hot"
      ],
      "metadata": {
        "id": "fNKkHKlRODSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zet satÄ±rlarÄ±nÄ± karakterlere ayÄ±rÄ±n\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "metadata": {
        "id": "z8FYBK3mOFH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek soyut Ã¶zelliklere iliÅŸkin tahminlerde bulunun\n",
        "%%time\n",
        "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "id": "qnaA1TO6OGhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasÄ±lÄ±klarÄ±nÄ± tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "id": "eRcoMUpKOGe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin sÄ±nÄ±fÄ± tamsayÄ±larÄ±nÄ± dize sÄ±nÄ±fÄ± adlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "id": "ss5foczTOGdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zet satÄ±rlarÄ±nÄ± ve tahmin edilen sÄ±ra etiketlerini gÃ¶rselleÅŸtirin\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "id": "_N8aPl1nOGbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okumak Ã§ok daha kolay deÄŸil mi? Demek istediÄŸim, modelimizin tahminleri geliÅŸtirilebilir gibi gÃ¶rÃ¼nÃ¼yor, ama bu ne kadar havalÄ±?\n",
        "\n",
        "Sitedeki yapÄ±landÄ±rÄ±lmamÄ±ÅŸ herhangi bir RCT Ã¶zetini biÃ§imlendirmek iÃ§in modelimizi PubMed web sitesinin arka ucuna uyguladÄ±ÄŸÄ±mÄ±zÄ± hayal edin.\n",
        "\n",
        "Ya da herhangi bir yapÄ±landÄ±rÄ±lmamÄ±ÅŸ RCT Ã¶zetine (modelimiz tarafÄ±ndan desteklenen) yapÄ± ekleyecek \"SkimLit\" adlÄ± bir tarayÄ±cÄ± uzantÄ±sÄ± bile olabilir.\n",
        "\n",
        "Ve eÄŸer tÄ±bbi araÅŸtÄ±rmacÄ± arkadaÅŸÄ±nÄ±zÄ± gÃ¶sterdiyse ve tahminlerin standartlara uygun olmadÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼lerse, \"bu etiket doÄŸru mu?... deÄŸilse, ne olmalÄ±?\" diyen bir dÃ¼ÄŸme olabilir. Bu ÅŸekilde, modelimizin gelecekteki tahminleriyle birlikte veri kÃ¼mesi zaman iÃ§inde geliÅŸtirilebilir.\n",
        "\n",
        "Tabii ki, modeli, kullanÄ±labilirliÄŸi, Ã¶n iÅŸleme iÅŸlevselliÄŸini (Ã¶rneÄŸin, Ã¶rnek soyut Ã¶n iÅŸleme boru hattÄ±mÄ±zÄ± iÅŸlevsel hale getirmek) geliÅŸtirmek iÃ§in kullanabileceÄŸimiz daha birÃ§ok yol var, ancak bunlarÄ± alÄ±ÅŸtÄ±rmalar/uzantÄ±lar iÃ§in bÄ±rakacaÄŸÄ±m.\n",
        "\n",
        "ğŸ¤” Soru: VahÅŸi doÄŸadan test Ã¶rneÄŸimizin sonuÃ§larÄ±nÄ±n gerÃ§ekten vahÅŸi olduÄŸundan nasÄ±l emin olabiliriz? Test ettiÄŸimiz numune hakkÄ±nda kontrol etmemiz gereken bir ÅŸey var mÄ±?"
      ],
      "metadata": {
        "id": "OMyLT03sOK7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.5. Kendi Denemelerim :)**"
      ],
      "metadata": {
        "id": "4xj7Hp2kj4p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MuhammedBarut/dosyalar_nlp/main/kronik_gastrit.json\"\n",
        "\n",
        "response = requests.get(url)\n",
        "kronik_gastrit = response.json()\n",
        "\n",
        "print(kronik_gastrit)"
      ],
      "metadata": {
        "id": "E7y6XPhrOXa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek Ã¶zetlerimizin neye benzediÄŸini gÃ¶rÃ¼n\n",
        "ozet = pd.DataFrame(kronik_gastrit)\n",
        "ozet"
      ],
      "metadata": {
        "id": "5a5A0WKaOXXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CÃ¼mle oluÅŸturucu oluÅŸtur\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "# spaCy'nin yeni versiyonu\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "# AyrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ dizilerin \"belgesini\" oluÅŸturun, farklÄ± bir Ã¶zet iÃ§in dizini deÄŸiÅŸtirin\n",
        "doc = nlp(kronik_gastrit[0][\"abstract\"])\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)]\n",
        "abstract_lines"
      ],
      "metadata": {
        "id": "SoGBCuDOOXU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Toplam satÄ±r sayÄ±sÄ±nÄ± al\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Ã–zet olarak her satÄ±rÄ± gÃ¶zden geÃ§irin ve her satÄ±r iÃ§in Ã¶zellikler iÃ§eren sÃ¶zlÃ¼klerin bir listesini oluÅŸturun\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "id": "im3nNHGWOXSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek Ã¶zetteki tÃ¼m satÄ±r_numarasÄ± deÄŸerlerini alÄ±n\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "\n",
        "# EÄŸitim verileriyle aynÄ± derinliÄŸe kadar tek sÄ±cak kodlama, bÃ¶ylece model doÄŸru giriÅŸ ÅŸeklini kabul eder\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
        "test_abstract_line_numbers_one_hot"
      ],
      "metadata": {
        "id": "K8Qo2uH6OXQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zet satÄ±rlarÄ±nÄ± karakterlere ayÄ±rÄ±n\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "metadata": {
        "id": "akIHCZPxOePU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–rnek soyut Ã¶zelliklere iliÅŸkin tahminlerde bulunun\n",
        "%%time\n",
        "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "id": "gDrqAXl5OeNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasÄ±lÄ±klarÄ±nÄ± tahmin sÄ±nÄ±flarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "id": "VQfIRKL3OeIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin sÄ±nÄ±fÄ± tamsayÄ±larÄ±nÄ± dize sÄ±nÄ±fÄ± adlarÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "id": "4w6bcPqFOeFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zet satÄ±rlarÄ±nÄ± ve tahmin edilen sÄ±ra etiketlerini gÃ¶rselleÅŸtirin\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "id": "mglcLDf-OjxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. KaynakÃ§a**"
      ],
      "metadata": {
        "id": "qViT0ESjj4nV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bir metin veri kÃ¼mesi indirme (GitHub'dan PubMed RCT200k) https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "* Model mimarisini https://arxiv.org/abs/1612.05251 adresinden Ã§oÄŸaltma\n",
        "* Dosyalar & Kaynaklar: https://github.com/mrdbourke/tensorflow-deep-learning\n",
        "* Bu dosyanÄ±n orjinali: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
      ],
      "metadata": {
        "id": "cd164cAkxZ7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. EÄŸitim veri kÃ¼mesindeki tÃ¼m veriler Ã¼zerinde model_5'i iyileÅŸtirmeyi durdurana kadar birÃ§ok dÃ¶nem boyunca eÄŸitin. Bu biraz zaman alabileceÄŸinden, kullanmak isteyebilirsiniz:\n",
        "\n",
        "  - Sadece modelin en iyi aÄŸÄ±rlÄ±klarÄ±nÄ± kaydetmek iÃ§in tf.keras.callbacks.ModelCheckpoint. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
        "\n",
        "  - tf.keras.callbacks.DoÄŸrulama kaybÄ± ~3 dÃ¶nem iÃ§in geliÅŸmeyi durdurduktan sonra modeli eÄŸitimden durdurmak iÃ§in EarlyStopping. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
        "\n",
        "2. Ã–nceden eÄŸitilmiÅŸ GloVe gÃ¶mmelerini kullanma konusunda Keras kÄ±lavuzuna gÃ¶z atÄ±n. Bunu modellerimizden biriyle Ã§alÄ±ÅŸtÄ±rabilir misin? https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "\n",
        "  - Ä°pucu: Bunu Ã¶zel bir belirteÃ§ GÃ¶mme katmanÄ±yla birleÅŸtirmek isteyeceksiniz. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "  - GloVe gÃ¶mÃ¼lerini ince ayar yapÄ±p yapmamanÄ±z veya donmuÅŸ bÄ±rakmanÄ±z size kalmÄ±ÅŸ.\n",
        "\n",
        "3. TensorFlow Hub BERT PubMed uzmanÄ± (PubMed metinleri Ã¼zerinde Ã¶nceden eÄŸitilmiÅŸ bir dil modeli) iÃ§in TensorFlow Hub Evrensel CÃ¼mle KodlayÄ±cÄ±sÄ± Ã¶nceden eÄŸitilmiÅŸ gÃ¶mmeyi deÄŸiÅŸtirmeyi deneyin. Bu etki ortaya Ã§Ä±kar mÄ±? https://www.kaggle.com/models/google/experts-bert/tensorFlow2/pubmed/2?tfhub-redirect=true\n",
        "\n",
        "  - Not: BERT PubMed uzmanÄ± Ã¶nceden eÄŸitilmiÅŸ gÃ¶mmeyi kullanmak, diziler iÃ§in ekstra bir Ã¶n iÅŸlem adÄ±mÄ± gerektirir (TensorFlow Hub kÄ±lavuzunda ayrÄ±ntÄ±lÄ± olarak aÃ§Ä±klandÄ±ÄŸÄ± gibi). https://www.kaggle.com/models/google/experts-bert/tensorFlow2/pubmed/2?tfhub-redirect=true\n",
        "\n",
        "  - BERT modeli bu makalede bahsedilen sonuÃ§larÄ± yendi mi? Https://arxiv.org/pdf/1710.06071.pdf\n",
        "\n",
        "4. Her dizi iÃ§in line_number ve total_lines Ã¶zelliklerimizi birleÅŸtirirseniz ne olur? Ã–rneÄŸin, bunun yerine bir X_of_Y Ã¶zelliÄŸi oluÅŸturuldu mu? Bu, model performansÄ±nÄ± etkiler mi?\n",
        "\n",
        "  - BaÅŸka bir Ã¶rnek: line_number=1 ve total_lines=11, line_of_X=1_of_11'e dÃ¶nÃ¼ÅŸÃ¼r.\n",
        "\n",
        "5. Ã–rnek bir soyut dize almak iÃ§in bir iÅŸlev (veya bir dizi iÅŸlev) yazÄ±n, Ã¶nceden iÅŸleyin (modelimizin eÄŸitildiÄŸi ÅŸekilde), Ã¶zetteki her dizi iÃ§in bir tahminde bulunun ve Ã¶zeti biÃ§imde dÃ¶ndÃ¼rÃ¼n:\n",
        "\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "\n",
        "...\n",
        "\n",
        "PubMed'den kendi dÃ¼zenlenmemiÅŸ RCT Ã¶zetinizi bulabilir veya bunu ÅŸu adresten deneyebilirsiniz: Baclofen, hepatit C virÃ¼sÃ¼ (HCV) enfeksiyonu olan alkol baÄŸÄ±mlÄ± siroz hastalarÄ±nda alkolden uzak durmayÄ± teÅŸvik eder. https://pubmed.ncbi.nlm.nih.gov/22244707/"
      ],
      "metadata": {
        "id": "rlMysx6CORZ0"
      }
    }
  ]
}