{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Medikal Metinlerin Sınıflandırılması**"
      ],
      "metadata": {
        "id": "76ILSckHUDRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "print(f\"Bu çalışma kitabının son çalışma tarihi: {datetime.datetime.now()}\")"
      ],
      "metadata": {
        "id": "bjYpVtvDXEZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "783e2765-51ae-4a79-f3b1-b3534a522cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bu çalışma kitabının son çalışma tarihi: 2025-01-02 19:29:58.423089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU var mı?\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "jrV2Rn7OXYgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1583b019-4b29-4612-8f79-a09e100e5811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-5a3cb6f8-b03a-a8b4-bddd-74a236c92ff7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **İçindekiler**\n",
        "```\n",
        "1. Tanıtım & Genel Bilgiler\n",
        "2. Veri\n",
        "  2.1. Verilerin Yüklenmesi ve Kontrolü\n",
        "  2.2. Satır Okuma Fonksiyonu\n",
        "  2.3. Veriyi Ön İşleyecek Fonksiyon Yazımı\n",
        "  2.4. Verilerin İncelenmesi\n",
        "  2.5. Tek Sıcak Kodlayıcı İle Sayısal Etiketler\n",
        "3. Modelleme\n",
        "  3.1. Model 0 Temel Model Yazımı ve Değerlendirilmesi\n",
        "  3.2. Yardımcı Fonksiyonlar Dosyası\n",
        "  3.3. Derin Modelleme İçin Veri Hazırlığı\n",
        "  3.4. Metin Vektörleştirme\n",
        "  3.5. Gömme Hazırlama\n",
        "  3.6. Veri Kümelerini hazırlama\n",
        "  3.7. Kelime Düzeyinde Conv1D İle Modelleme ve Değerlendirme\n",
        "  3.8. Tensorflow Hub İle Modelleme ve Değerlendirme\n",
        "  3.9. Karakter Düzeyinde Conv1D İle Modelleme ve Değerlendirme\n",
        "  3.10. Önceden Eğitilmiş Token Gömmeler ve Karakter Gömmeleri Birleştirerek Modelleme ve Değerlendirme\n",
        "  3.11. Önceden Eğitilmiş Token Gömmeler, Karakter Gömmeleri ve Konumsal Gömmeleri Birleştirerek Modelleme ve Değerlendirme\n",
        "4. Model Sonuçlarını Karşılaştır\n",
        "5. Model Kaydetme ve Yükleme\n",
        "6. Değerlendirme\n",
        "  6.1. Doğrulama Veri Setini Değerlendir\n",
        "  6.2. Test Veri Setinde Modeli Değerlendir\n",
        "  6.3. En Çok Yanlışı Bul\n",
        "  6.4. Örnek Tahminler Yap\n",
        "  6.5. Kendi Denemelerim :)\n",
        "7. Kaynakça\n",
        "```"
      ],
      "metadata": {
        "id": "WI5e_GQqUDEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Tanıtım & Genel Bilgiler**"
      ],
      "metadata": {
        "id": "AlgHgm_9j5sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PubMed sağlıkla ilgili makalelerin yer aldığı bir websitesidir. Bu çalışmada 2017 tarihli PubMed 200k RCT makalesinin arkasındaki derin öğrenme modelini çoğaltacağız: Tıbbi Özetlerde Sıralı Cümle Sınıflandırması için Bir Veri Kümesi. https://arxiv.org/abs/1710.06071\n",
        "\n",
        "Yayınlandığında, makale ~200.000 etiketli Randomize Kontrollü Deneme (RCT) özetinden oluşan PubMed 200k RCT adlı yeni bir veri kümesi sundu.\n",
        "\n",
        "Veri kümesinin amacı, NLP modellerinin sıralı olarak görünen cümleleri sınıflandırma yeteneğini araştırmaktı.\n",
        "\n",
        "Başka bir deyişle, bir RCT'nin özeti göz önüne alındığında, her cümle soyutta nasıl bir role hizmet eder?\n",
        "\n",
        "Uzun bir paragrafı bölümlere ayırıp özetini çıkarmak isteseydik? Buradaki model many to one sorunu. Örnek bir paragrafta on cümle varsa hepsi ayrı ayrı değerlendirilir, bu input, ama hedef paragrafın etiketi ise tek kelime, bu da output. Yani kolaylaştırmak için her bir diziye hangi bölüme ait olmaları gerektiğine dair etiket veririz."
      ],
      "metadata": {
        "id": "jhvGdVthvDY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelleme Adımları\n",
        "\n",
        "1. Verileri hazırlayın (tensörlere dönüştürün)\n",
        "2. Tensorflow hub'ı, önceden eğitilmiş bir model oluşturun veya seçin (sorunuza uyacak şekilde)\n",
        "3. Modeli verilere uydurun ve tahmin yapın\n",
        "4. Modeli değerlendirin\n",
        "5. Deneyerek geliştirin\n",
        "6. Eğitilen modelinizi kaydedin ve yeniden yükleyin\n",
        "\n",
        "* Tüm veri sayılara dönüştürülmeli. Nöral ağlar metin veya doğal dil işleyemez.\n",
        "* Tüm tensörler doğru ölçüde (şekil) olmalıdır."
      ],
      "metadata": {
        "id": "JR5IyqAduq4o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Örneğin;\n",
        "\n",
        "**Okuması zor:**\n",
        "\n",
        "Nutritional psychiatry: the present state of the\n",
        "evidence\n",
        "\n",
        "Wolfgang Marx 1, Genevieve Moseley 2, Michael Berk 2, Felice Jacka 2\n",
        "\n",
        "Affiliations + expand\n",
        "PMID: 28942748 DOI: 10.1017/S0029665117002026\n",
        "Abstract Mental illness, including depression, anxiety and bipolar disorder, accounts for a significant\n",
        "proportion of global disability and poses a substantial social, economic and heath burden. Treatment is presently dominated by pharmacotherapy, such as antidepressants, and psychotherapy, such as cognitive behavioural therapy; however, such treatments avert less than half of the disease burden, suggesting that additional strategies are needed to prevent and treat mental disorders. There are now consistent mechanistic, observational and interventional data to suggest diet quality may be a modifiable risk factor for mental illness. This review provides an overview of the nutritional psychiatry field. It includes a discussion of the neurobiological mechanisms likely modulated by diet, the use of dietary and nutraceutical interventions in mental disorders, and recommendations for further research. Potential biological pathways related to mental disorders include inflammation, oxidative stress, the gut microbiome, epigenetic modifications and neuroplasticity. Consistent epidemiological evidence, particularly for depression, suggests an association between measures of diet quality and mental health, across multiple populations and age groups; these do not appear to be explained by other demographic, lifestyle factors or reverse causality. Our recently published intervention trial provides preliminary clinical evidence that dietary interventions in clinically diagnosed populations are feasible and can provide significant clinical benefit. Furthermore, nutraceuticals including n-3 fatty acids, folate, S- adenosylmethionine, N-acetyl cysteine and probiotics, among others, are promising avenues for future research. Continued research is now required to investigate the efficacy of intervention studies in large cohorts and within clinically relevant populations, particularly in patients with\n",
        "schizophrenia, bipolar and anxiety disorders.\n",
        "Source: https://pubmed.ncbi.n/m.nih.gov/28942748/\n",
        "\n",
        "**Okuması kolay:**\n",
        "\n",
        "Considerations for a surgical RCT for diffuse low-\n",
        "grade glioma: a survey\n",
        "\n",
        "Alireza Mansouri 1, Karanbir Brar 2, Michael D Cusimano 3\n",
        "Affiliations + expand\n",
        "\n",
        "PMID: 32537182 PMCID: PMC7274180 (available on 2021-06-01) DOI: 10.1093/nop/npz058\n",
        "\n",
        "Abstract\n",
        "Background: Diffuse low-grade gliomas (DLGGs) are heterogeneous tumors that inevitably\n",
        "-maximal safe resection of DLGGs has been favored. However, this transition is not supported by\n",
        "-ai realise it main an intes leadin a disa. Hi enver, ai. ansi, is sort upor up front :\n",
        "randomized controlled trial (RCT) data. Here, we sought to survey the neuro-oncology community\n",
        "\n",
        "Methods: A 21-question survey focusing on a surgical RCT for DLGGs was developed and validated by 2 neurosurgeons. A sample case of a patient for whom management might be debatable was presented to gather additional insight. The survey was disseminated to members of the Society for Neuro-Oncology (SNO) and responses were collected from March 16 to July 10,2018.\n",
        "\n",
        "Results: A total of 131 responses were collected. Sixty-three of 117 (54%) respondents thought an RCT would not be ethical, 39 of 117 (33%) would consider participating, and 56 of 117 (48%) believed an RCT would be valuable for determining the differing roles of biopsy, surgery, and observation. This was exemplified by an evenly distributed selection of the latter management options for our sample case. Eighty-three of 120 (69.2%) respondents did not believe in equipoise for DLGG patients. Quality of life and overall survival were deemed equally important end points for\n",
        "a putative RCT.\n",
        "\n",
        "Conclusions: Based on our survey, it is evident that management of certain DLGG patients is not well defined and an RCT may be justified. As with any surgical RCT, logistic challenges are anticipated. Robust patient-relevant end points and standardization of perioperative adjuncts are\n",
        "necessary if a surgical RCT is undertaken.\n",
        "Source: https://pubmed.ncbi.nlm.nih.gov/32537182/"
      ],
      "metadata": {
        "id": "0f2TXS9awbDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Veriler bazı etiketler alır;**\n",
        "\n",
        "- background\n",
        "- objective\n",
        "- methods\n",
        "- result\n",
        "- conclusion\n",
        "\n",
        "Örnek tahmin edilmiş output olarak [0.03, 0.82, 0.13, 0.02, 0.001] olabilir.\n",
        "\n",
        "Burada çok sınıflı sınıflandırma var.\n",
        "\n",
        "input örneği olarak shape = [batch_size, embedding_size]\n",
        "\n",
        "[None, 512] ya da [32, 512] gibi.\n",
        "\n",
        "Output shape [5] (Yukarıdaki beş etikete dikkat. Aslında modelde makalede senin hangi parametreleri verdiğinle ilgili bir konu).\n",
        "\n",
        "Giriş ve çıktı şekli üzerinde çalıştığımız problemdeki gömme stiline bağlıdır."
      ],
      "metadata": {
        "id": "1f55Khrvwr6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Örneğin modele giren veri**\n",
        "\n",
        "Örneğin, aşağıdaki girdiyi alan bir NLP modelini eğitebilir miyiz (not: aşağıdaki örnekte tüm sayısal semboller \"@\" ile değiştirilmiştir):\n",
        "\n",
        "To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ). A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks. Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers. Pain was assessed using the visual analog pain scale ( @-@ mm ). Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD )., Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured. There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks. The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively. Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group. These differences remained significant at @ weeks. The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ). Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ).\n",
        "\n",
        "**Modelden çıkmış olması gereken durumu**\n",
        "\n",
        "Ve aşağıdaki çıktıyı döndürür:\n",
        "\n",
        "['###24293578\\n',\n",
        " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
        " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
        " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
        " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
        " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
        " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
        " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
        " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
        " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
        " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
        " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
        " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
        " '\\n']"
      ],
      "metadata": {
        "id": "37lwZ9uUw_aq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Araştırmacıların literatürü gözden geçirmelerini gözden geçirmelerini ve gerektiğinde daha derine dalmalarını sağlamak için soyut cümleleri oynadıkları role (örneğin amaç, yöntemler, sonuçlar, vb.) sınıflandırmak için bir NLP modeli oluşturun.\n",
        "\n",
        "1. Verilerimizin nereden geldiği: PubMed 200k RCT: Tıbbi Özetlerde Sıralı Cümle Sınıflandırması için bir Veri Kümesi https://arxiv.org/abs/1710.06071\n",
        "\n",
        "2. Modelimiz nereden geliyor: Tıbbi kağıt özetlerinde ortak cümle sınıflandırması için sinir ağları. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "📖 Kaynaklar: Bu not defterindeki kodu gözden geçirmeden önce, ne yapacağımıza dair bir arka plan almak isteyebilirsiniz. Bunu yapmak için, aşağıdaki kağıtları gözden geçirmek için bir (veya iki saat) harcayın ve ardından bu deftere dönün:"
      ],
      "metadata": {
        "id": "Qc-w9ycjxO4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Veri**"
      ],
      "metadata": {
        "id": "lZM8tNw0j5qB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1. Verilerin Yüklenmesi ve Kontrolü**"
      ],
      "metadata": {
        "id": "cS20h4pKj5ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PubMed 200k RCT veri kümesini indirme işlemi\n",
        "# Makele yazarı .txt formatında dosyaları kaydetti https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "\n",
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "id": "BXqEQQkj2ofc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09a0613c-86e7-4d68-95c7-8bd6adf44cfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\n",
            "PubMed_200k_RCT\t\t\t\t       PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign  README.md\n",
            "PubMed_20k_RCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub sayfasındaki README dosyasına baktığımızda aşağıdaki bilgileri elde ediyoruz: https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "\n",
        "- PubMed 20k, PubMed 200k'nin bir alt kümesidir. Yani, PubMed 20k'deki herhangi bir özet mevcut, PubMed 200k'de de mevcuttur.\n",
        "\n",
        "- PubMed_200k_RCT, PubMed_200k_RCT_numbers_replaced_with_at_sign ile aynıdır, ancak ikincisinde tüm sayılar @ ile değiştirilmiştir. (PubMed_20k_RCT vs. PubMed_20k_RCT_numbers_replaced_with_at_sign).\n",
        "\n",
        "- Github dosya boyutu sınırı 100 MiB olduğundan, PubMed_200k_RCT\\train.7z ve PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip dosyalarını sıkıştırmak zorunda kaldık. Train.7z'yi açmak için Windows'ta 7-Zip, Mac OS X'te Keka veya Linux'ta p7zip kullanabilirsiniz.\n",
        "\n",
        "Başlangıç olarak, odaklanacağımız veri kümesi PubMed_20k_RCT_numbers_replaced_with_at_sign'dır.\n",
        "\n",
        "Tüm 200 bin veri kümesiyle çalışmak yerine, daha küçük bir alt kümeyle başlayarak deneylerimizi hızlı tutacağız. @ ile değiştirmek yerine sayılarla veri kümesini seçebilirdik ama seçmedik."
      ],
      "metadata": {
        "id": "FY2CYtR82sFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PubMed_20K veri setinde neler var?\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
        "\n",
        "# train.txt - eğitim örnekleri.\n",
        "# dev.txt - dev, doğrulama kümesinin başka bir adı olan geliştirme kümesinin kısaltmasıdır (doğrulama olarak kullanıyoruz)\n",
        "# test.txt - test örnekleri."
      ],
      "metadata": {
        "id": "Rgq5cjTX22mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc6c302-cadf-4e10-981b-161eacc1136e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 20k veri kümesini kullanarak başlayın\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "id": "95dvaBT14D7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hedef dizindeki tüm dosya adlarını kontrol edin\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "id": "sIP-gLEU4D4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad704f48-b2c9-413b-b1f2-660c5f92a2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2. Satır Okuma Fonksiyonu**"
      ],
      "metadata": {
        "id": "vRT64-fuj5l_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google'a yaz --> \"python read text file\"\n",
        "# realpython.com/read-write-files-pyhton\n",
        "# r --> read; f--> file...dosyayı oku sonra file'ye dönüştür\n",
        "# readlines -->  Dosya nesnesinden kalan satırları okur ve bunları bir liste olarak döndürür\n",
        "\n",
        "# Bir belgenin satırlarını okumak için işlev oluşturun\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Dosya adını (bir metin dosyası) okur ve metnin satırlarını liste olarak döndürür.\n",
        "\n",
        "  Argümanlar:\n",
        "      dosya adı: okunacak hedef dosya yolunu içeren bir dize.\n",
        "\n",
        "  Return:\n",
        "      Hedef dosya adından satır başına bir dize içeren dizelerin listesi.\n",
        "      Örneğin:\n",
        "      [\"bu dosya adının ilk satırıdır\",\n",
        "       \"bu dosya adının ikinci satırıdır\",\n",
        "       \"...\"]\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "id": "CBE60FwV4w80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bir metin dosyasının dosya yolunu alan, açan, satırların her birini okuyan ve döndüren get_lines() metodu\n",
        "\n",
        "# eğitim dosyalarının bulunduğu satırları okuyun\n",
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:20]"
      ],
      "metadata": {
        "id": "HU1nbwFB6X0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c888a7-d213-4a6d-b947-65ae327c4f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Örnek başlarında ###4343 gibi sayısal kimlik biçimleri var. Başlangıcı ayırt etmede kullanabilirsin.\n",
        "\n",
        "Eğitim metin dosyasındaki satırları okumak, farklı örnekler içeren dizelerin bir listesiyle sonuçlanır, bir örnekteki cümleler ve cümlenin özette oynadığı roldür.\n",
        "\n",
        "Her cümlenin rolü, bir sekme (\\t) ile ayrılmış her satırın başında ön eklenir ve her cümle yeni bir satırla (\\n) biter.\n",
        "\n",
        "Farklı özetler kimlikleri (### ile başlayan satırlar) ve yeni satırlar (\\n) ile ayrılır.\n",
        "\n",
        "Bunu bilerek, örneklerimizi gelecekteki makine öğrenimi modelimize eğitim verileri olarak aktarmaya hazır hale getirmek için yapmamız gereken birkaç adım var gibi görünüyor.\n",
        "\n",
        "Aşağıdaki adımları gerçekleştirmek için bir işlev yazalım:\n",
        "\n",
        "- Örneklerden oluşan bir hedef dosya alın.\n",
        "- Hedef dosyadaki satırları okuyun.\n",
        "- Hedef dosyadaki her satır için:\n",
        "  - Satır ### ile başlıyorsa, bunu soyut kimlik ve yeni bir özetin başlangıcı olarak işaretleyin.\n",
        "    - Bir örnekteki satır sayısının sayısını koruyun.\n",
        "  - Satır \\n ile başlıyorsa, bunu soyut bir örneğin sonu olarak işaretleyin.\n",
        "    - Bir örnekteki toplam satırların sayısını koruyun.\n",
        "  - \\t'den önceki metni satırın etiketi olarak kaydedin.\n",
        "  - \\t'den sonraki metni satırın metni olarak kaydedin.\n",
        "- Hedef metin dosyasındaki tüm satırları anahtar/değer çiftlerini içeren sözlüklerin bir listesi olarak döndürün:\n",
        "  - \"Line_number\" - özetteki satırın konumu (örn. 3).\n",
        "  - \"Hedef\" - çizginin soyuttaki rolü (örn. AMAÇ).\n",
        "  - \"Metin\" - soyuttaki satırın metni.\n",
        "  - \"Total_lines\" - soyut bir örnekteki toplam satır (örn. 14).\n",
        "- Özet kimlikleri ve yeni satırlar, döndürülen önceden işlenmiş verilerden atlanmalıdır.\n",
        "\n",
        "Örnek, önceden işlenmiş numune döndürdü (özetten tek bir satır):\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis.',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "  ```"
      ],
      "metadata": {
        "id": "rYAu1wbC64_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.3. Veriyi Ön İşleyecek Fonksiyon Yazımı**"
      ],
      "metadata": {
        "id": "aHulSXzmj5j3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Özet satır verilerinin sözlüklerinin listesini döndürür.\n",
        "\n",
        "  Dosya adını alır, içeriğini okur ve her satıra göre sıralar,\n",
        "  hedef etiketi, cümlenin metni gibi şeyleri çıkarmak,\n",
        "  güncel özette kaç cümle var ve cümle numarası kaç\n",
        "  hedef hattıdır.\n",
        "\n",
        "  Argümanlar:\n",
        "      dosya adı: satır verilerini okumak ve çıkarmak için hedef metin dosyasının bir dizesi\n",
        "      itibaren.\n",
        "\n",
        "  Return:\n",
        "      Her biri özetten bir satır içeren sözlüklerin listesi,\n",
        "      satır etiketi, özetteki satır konumu ve toplam sayı\n",
        "      Özetteki satırların nereden geldiği. Örneğin:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # dosya adından tüm satırları al\n",
        "  abstract_lines = \"\" # boş bir özet oluştur\n",
        "  abstract_samples = [] # boş bir özet listesi oluştur\n",
        "\n",
        "  # Hedef dosyadaki her satırda döngü yapın\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # satırın kimlik satırı olup olmadığını kontrol edin\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # özet dizeyi sıfırla\n",
        "    elif line.isspace(): # satırın yeni bir satır olup olmadığını kontrol edin\n",
        "      abstract_line_split = abstract_lines.splitlines() # Özeti ayrı satırlara bölme\n",
        "\n",
        "      # Her satırı özet olarak yineleyin ve aynı anda sayın\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # satırdaki verileri depolamak için boş dict oluştur\n",
        "        target_text_split = abstract_line.split(\"\\t\") # hedef etiketi metinden ayır\n",
        "        line_data[\"target\"] = target_text_split[0] # hedef etiketi al\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # hedef metni alın ve indirin\n",
        "        line_data[\"line_number\"] = abstract_line_number # özette çizgi hangi sayı doğrusunda görünüyor?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # özette toplam kaç satır var? (0'dan başlayın)\n",
        "        abstract_samples.append(line_data) # özet örnekler listesine satır verileri ekleme\n",
        "\n",
        "    else: # Yukarıdaki koşullar yerine getirilmezse satır etiketli bir cümle içerir\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "lA__qdJuRg8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "def preprocess_text_with_line_numbers(filename):\n",
        "```\n",
        "Bu satırda, fonksiyonun adı ve parametresi belirleniyor. `filename` parametresi, işlenecek dosyanın adını alır.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "input_lines = get_lines(filename)\n",
        "abstract_lines = \"\"\n",
        "abstract_samples = []\n",
        "```\n",
        "- `get_lines(filename)`: Bu fonksiyon, belirtilen dosyanın içeriğini satır satır okur ve her satırı bir liste halinde döndürür.\n",
        "- `abstract_lines`: Bu değişken, her bir özetin metnini geçici olarak tutacak bir string değişkendir. Başlangıçta boş olarak tanımlanır.\n",
        "- `abstract_samples`: Bu değişken, özetin her bir satırını ve ilgili bilgileri içeren sözlüklerin listesi olacak şekilde tanımlanır.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "for line in input_lines:\n",
        "```\n",
        "Bu döngü, dosyanın her bir satırı üzerinde işlem yapacak şekilde başlar.\n",
        "\n",
        "```python\n",
        "if line.startswith(\"###\"):\n",
        "    abstract_id = line\n",
        "    abstract_lines = \"\"\n",
        "```\n",
        "- Eğer satır, \"###\" ile başlıyorsa (yani bir kimlik satırı ise), bu satırda genellikle bir özetin kimliği yer alır.\n",
        "- `abstract_id = line`: Bu satırdaki kimlik bilgisini alır (ancak bu örnekte `abstract_id` sadece bir kere atanıyor, ilerleyen kodda kullanılmıyor).\n",
        "- `abstract_lines = \"\"`: Yeni bir özet başladığında, geçici özet metni sıfırlanır.\n",
        "\n",
        "```python\n",
        "elif line.isspace():\n",
        "    abstract_line_split = abstract_lines.splitlines()\n",
        "```\n",
        "- `line.isspace()`: Eğer satır boşsa (yani sadece boşluk karakteri içeriyorsa), bir özetin bittiğini ve bir sonraki özetin başladığını gösterir.\n",
        "- `abstract_lines.splitlines()`: Boş satır bulunduğunda, birikmiş özet metni satırlara ayrılır.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "    line_data = {}\n",
        "    target_text_split = abstract_line.split(\"\\t\")\n",
        "    line_data[\"target\"] = target_text_split[0]\n",
        "    line_data[\"text\"] = target_text_split[1].lower()\n",
        "    line_data[\"line_number\"] = abstract_line_number\n",
        "    line_data[\"total_lines\"] = len(abstract_line_split) - 1\n",
        "    abstract_samples.append(line_data)\n",
        "```\n",
        "Bu kısım, her bir özet satırını işler:\n",
        "- `enumerate(abstract_line_split)`: Özetteki her bir satırı numaralandırarak işler.\n",
        "- `line_data = {}`: Bu satırdaki verileri tutacak bir sözlük oluşturur.\n",
        "- `target_text_split = abstract_line.split(\"\\t\")`: Satır, tab karakteri ile iki kısımdan oluştuğu için, bu karakterle metni ikiye böler. Birinci kısım hedef etiketi (örneğin `OBJECTIVE`), ikinci kısım ise metin kısmıdır (örneğin, özet metni).\n",
        "- `line_data[\"target\"]`: Etiket kısmını alır.\n",
        "- `line_data[\"text\"]`: Metin kısmını alır ve küçük harflere dönüştürür (`lower()` metodu ile), böylece metin büyük-küçük harf duyarlı olmadan işlenir.\n",
        "- `line_data[\"line_number\"]`: Bu satırın özetin içinde hangi sırada olduğunu belirler.\n",
        "- `line_data[\"total_lines\"]`: Özetteki toplam satır sayısını (0'dan başladığı için 1 eksik) hesaplar.\n",
        "- `abstract_samples.append(line_data)`: Her bir satırdaki bilgileri `abstract_samples` listesine ekler.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "else:\n",
        "    abstract_lines += line\n",
        "```\n",
        "- Eğer satır boş değilse ve \"###\" ile başlamıyorsa, bu satır bir özet satırıdır. Bu durumda satır, geçici `abstract_lines` değişkenine eklenir.\n",
        "\n",
        "```python\n",
        "return abstract_samples\n",
        "```\n",
        "Fonksiyon, özetin her satırını içeren `abstract_samples` listesini döndürür. Bu liste, her satır için etiket, metin, satır numarası ve toplam satır sayısı gibi bilgileri içeren sözlüklerden oluşur.\n",
        "\n"
      ],
      "metadata": {
        "id": "MFYsAYZ-WICP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dosyadan veri alın ve ön işleme tabi tutun\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev, doğrulama kümesinin başka bir adıdır\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "id": "Rx5waGT0XgBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a227b29-ee86-439d-e412-04e05449ab74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 656 ms, sys: 109 ms, total: 764 ms\n",
            "Wall time: 819 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim verilerimizin ilk özetini kontrol edin\n",
        "train_samples[:14]"
      ],
      "metadata": {
        "id": "KNsylqUJXf62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d41a5b7-0b5f-412f-b5c1-e4d6b5ff77f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.4. Verilerin İncelenmesi**"
      ],
      "metadata": {
        "id": "kpZRFc5Kj5h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "id": "cIoJuFaFXxVH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "5005c187-0884-4afa-e2d5-c19b95bbc703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb611bb6-e25a-4ac2-9738-650ca1e9c5ef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ca45f98-d1d2-4424-b7d5-4582b2f07da4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ca45f98-d1d2-4424-b7d5-4582b2f07da4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ca45f98-d1d2-4424-b7d5-4582b2f07da4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim verilerindeki etiketlerin dağılımı\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "id": "wheVa1cuXxE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "76624ea3-0799-4b3e-a94c-2dba41068994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>METHODS</th>\n",
              "      <td>59353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RESULTS</th>\n",
              "      <td>57953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CONCLUSIONS</th>\n",
              "      <td>27168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BACKGROUND</th>\n",
              "      <td>21727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>OBJECTIVE</th>\n",
              "      <td>13839</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cümle uzunluklarının dağılımı\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "id": "t5mfBu5WXxBV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "60da2035-b246-481b-8d7c-074cc665078d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Özet metin satırlarını listelere dönüştürün\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)\n",
        "\n",
        "# tolist() bir veri penceresi içeriğini Python list formatına dönüştürür\n",
        "# Örn. her bir satırdaki cümleler ['This is a test.', 'Another sentence.', 'Final sentence.'] olur"
      ],
      "metadata": {
        "id": "axcIJ2K-YHQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "904c54bd-e7f4-4b47-de20-84f4814b1df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim cümlelerinin ilk 10 satırını görüntüleyin\n",
        "train_sentences[:10]"
      ],
      "metadata": {
        "id": "RgVzk9iNYHNp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4127d8f8-7a77-49a6-fde4-44c1f01a4c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.5. Tek Sıcak Kodlayıcı İle Sayısal Etiketler**"
      ],
      "metadata": {
        "id": "q_t8PsIaj5fw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow'un CategoricalCrossentropy kayıp işlevi, one hpt encoding etikete sahip olmalı.\n",
        "\n",
        "Etiketleri sayısal olarak kodlamak için Scikit-Learn'in OneHotEncoder ve LabelEncoder sınıflarını kullanacağız.\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
        "\n",
        "Aşağıdaki kod öbekleri için;\n",
        "\n",
        "***Sparse*** yeni versiyonda gelen bir özellik, varsayılan true'dir. False yaptığımızda hata vermedi, True olduğunda matris uzunluğu belirsiz uyarısı alındı.\n",
        "\n",
        "Onehotencoder iki boyutludur, doğru şekilde veri olmazsa şeklini (-1,1) yap uyarısı alırsın. Bu yüzden kod satırına eklendi.\n",
        "\n",
        "val_labels_one_hot  --> Doğrulama hedef etiketlerimizi aynı şekilde dönüştürmek için yalnızca dönüştürülmüş yöntemi kullanmamız gerekiyor. Yani bulunan eğitim veri çerçevesinden etiketlerin yapısını alınır ve doğrulama veri çerçevesini aynı şekilde kodlar."
      ],
      "metadata": {
        "id": "v9f-ILAwZMXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One hot encode etiketleri\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Eğitim etiketlerinin nasıl göründüğünü kontrol edin\n",
        "train_labels_one_hot"
      ],
      "metadata": {
        "id": "23iwEA9jZ8VA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea1db84-00ef-4813-c014-4696b681d7ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`One-hot encoding` (ya da bir diğer adıyla tek-sıcak kodlama), kategorik değişkenlerin sayısal verilere dönüştürülmesi için yaygın olarak kullanılan bir tekniktir. Bu teknik, modelin kategorik verileri sayısal formatta anlamasını sağlamak için kullanılır.\n",
        "\n",
        "`One-hot encoding`, kategorik verileri ikili (binary) bir vektöre dönüştürme işlemidir. Bu işlem, her bir kategori için ayrı bir sütun oluşturur ve sadece o kategoriye ait olan satırda 1 değeri, diğer tüm kategorilerde ise 0 değeri bulunur. Yani, her kategori için \"1\" bir yerleştirilir, geri kalan yerler \"0\" olur.\n",
        "\n",
        "Örneğin, bir etiket sütununda aşağıdaki kategoriler varsa:\n",
        "```\n",
        "[\"cat\", \"dog\", \"fish\", \"dog\", \"cat\"]\n",
        "```\n",
        "\n",
        "Bu, `One-hot encoding` uygulandıktan sonra şöyle bir yapıya dönüşür:\n",
        "```\n",
        "cat   -> [1, 0, 0]\n",
        "dog   -> [0, 1, 0]\n",
        "fish  -> [0, 0, 1]\n",
        "dog   -> [0, 1, 0]\n",
        "cat   -> [1, 0, 0]\n",
        "```\n",
        "\n",
        "Her kategori için bir sütun eklenir (örneğin, \"cat\", \"dog\", \"fish\") ve her satırda bu kategorilerden birine 1 değeri atanır, diğerleri 0 olur.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "```\n",
        "\n",
        "1. **`OneHotEncoder`**: `sklearn.preprocessing` modülünden `OneHotEncoder` sınıfını içeri aktarıyoruz. Bu sınıf, kategorik verileri one-hot encoding formatına dönüştürmek için kullanılır.\n",
        "\n",
        "   - **`sparse=False`**: Bu parametre, dönüşümün **sparse matrix** (seyrek matris) yerine normal bir numpy dizisi (dense array) formatında yapılmasını sağlar. Sparse matrisler bellek tasarrufu sağlasa da, burada genellikle dense (yoğun) diziler tercih edilir.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "```\n",
        "\n",
        "2. **`fit_transform` ve `transform`**:\n",
        "   - **`fit_transform`**: Bu metod, eğitim verisinde (train) `OneHotEncoder`'ı uygular ve aynı zamanda bu verilerle yeni kodlamayı öğrenir. `train_df[\"target\"]` etiketlerini one-hot encoding formatına dönüştürür.\n",
        "   - **`transform`**: Bu metod, eğitim verisiyle öğrenilen kodlamayı kullanarak, doğrulama (val) ve test (test) etiketlerine one-hot encoding uygular.\n",
        "\n",
        "3. **`to_numpy().reshape(-1, 1)`**:\n",
        "   - `train_df[\"target\"]`: Bu, `train_df` DataFrame'inin \"target\" adlı etiket sütununu alır.\n",
        "   - `.to_numpy()`: Pandas Series'i numpy dizisine dönüştürür.\n",
        "   - `.reshape(-1, 1)`: Bu işlem, veriyi iki boyutlu bir vektöre dönüştürür (örneğin, 2D şekli `(n, 1)` yapar, burada `n` satır sayısını temsil eder). `OneHotEncoder` sadece 2D verilerle çalışır, bu yüzden bu dönüşüm gereklidir.\n",
        "\n",
        "---\n",
        "\n",
        "**Eğitim Etiketlerinin Görünümü**\n",
        "\n",
        "```python\n",
        "train_labels_one_hot\n",
        "```\n",
        "Bu satır, eğitim etiketlerinin one-hot encoding uygulanmış halini gösterir. Örneğin, eğer `train_df[\"target\"]` 3 farklı kategori içeriyorsa (örneğin, `[\"cat\", \"dog\", \"fish\"]`), `train_labels_one_hot` şu şekilde bir numpy array olabilir:\n",
        "\n",
        "```python\n",
        "array([[1., 0., 0.],  # cat\n",
        "       [0., 1., 0.],  # dog\n",
        "       [0., 0., 1.]]) # fish\n",
        "```\n",
        "\n",
        "Her satır, orijinal etiketin one-hot encoding karşılığıdır.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BQoKCcgQa5s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Etiketleri (\"hedef\" sütunlar) çıkarın ve bunları tam sayılara kodlayın\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Eğitim etiketlerinin nasıl göründüğünü kontrol edin\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "id": "IrtErYtnZ8R0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d094a930-faa6-4422-8273-e59e1444e293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Label Encoding` (Etiket Kodlama), kategorik verilerin sayısal verilere dönüştürülmesinin bir başka yaygın yoludur. Bu, kategorik etiketlerin her birini tek bir sayıya dönüştürmek için kullanılır. Bu işlem, **sınıflandırma problemlerinde** modelin sayısal verileri anlaması için gereklidir.\n",
        "\n",
        "`Label Encoding`, her kategoriyi bir sayıya dönüştürür. Örneğin, \"cat\", \"dog\", \"fish\" gibi etiketler sırasıyla 0, 1, 2 gibi sayılarla değiştirilir.\n",
        "\n",
        "Bu işlem genellikle **etiketlerin sıralı olduğu** durumlarda kullanılır. Yani, etiketler arasında bir sıralama veya hiyerarşi varsa, `Label Encoding` mantıklı olabilir. Ancak, sırasız etiketlerde de kullanılabilir, ancak bu durumda sıralamanın modelin performansını etkilememesi için dikkatli olunması gerekir.\n",
        "\n",
        "Örnek:\n",
        "- \"cat\" -> 0\n",
        "- \"dog\" -> 1\n",
        "- \"fish\" -> 2\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "```\n",
        "\n",
        "1. **`LabelEncoder`**: Bu sınıf, **kategorik etiketleri** sayısal verilere dönüştürmek için kullanılır. `LabelEncoder`, her farklı kategoriyi (etiketi) bir sayı ile eşler.\n",
        "\n",
        "```python\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "```\n",
        "\n",
        "2. **`fit_transform`**:\n",
        "   - **`fit_transform`**: Bu metot, `train_df[\"target\"]` sütunundaki tüm etiketleri (kategorik veriler) öğrenir (fit) ve her etiketi bir sayıya dönüştürür (transform).\n",
        "   - `train_df[\"target\"].to_numpy()`: Bu, `train_df` DataFrame'inin `target` adlı sütununu bir numpy dizisine dönüştürür. `LabelEncoder`, numpy dizileri ile çalışır, bu yüzden verinin bu formata dönüştürülmesi gereklidir.\n",
        "   - Sonuçta, her etiketin sayısal karşılığı olan bir numpy dizisi elde edilir.\n",
        "\n",
        "```python\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "```\n",
        "\n",
        "3. **`transform`**:\n",
        "   - **`transform`**: Bu metod, eğitim verisiyle (`fit`) öğrenilen kodlamayı kullanarak **doğrulama (val)** ve **test (test)** setlerindeki etiketleri sayılara dönüştürür.\n",
        "   - Burada önemli olan, `fit_transform` sadece eğitim verisinde yapılırken, doğrulama ve test verisinde sadece `transform` kullanılır. Bu, modelin **gerçek test verisi**yle karşılaşmadan önce öğrenme işleminin bitmesini sağlar.\n",
        "\n",
        "---\n",
        "\n",
        " `train_labels_encoded` Nasıl Görünür?\n",
        "\n",
        "`train_labels_encoded` dizisi, `train_df[\"target\"]` etiketlerinin sayısal karşılıklarını içerir. Örneğin, eğer `train_df[\"target\"]` şu etiketleri içeriyorsa:\n",
        "\n",
        "```\n",
        "[\"cat\", \"dog\", \"fish\", \"dog\", \"cat\"]\n",
        "```\n",
        "\n",
        "Ve `LabelEncoder` bunları şu şekilde sayılara dönüştürürse:\n",
        "```\n",
        "cat -> 0\n",
        "dog -> 1\n",
        "fish -> 2\n",
        "```\n",
        "\n",
        "O zaman `train_labels_encoded` şu şekilde olur:\n",
        "\n",
        "```python\n",
        "array([0, 1, 2, 1, 0])\n",
        "```\n",
        "\n",
        "Burada her etiketin sayısal karşılığı gösterilmektedir.\n",
        "\n",
        "---\n",
        "\n",
        "`Label Encoding` çeşitli sebeplerle kullanılır:\n",
        "\n",
        "1. **Makine Öğrenmesi Modellerinin Sayısal Veri İhtiyacı**: Çoğu makine öğrenmesi algoritması (özellikle doğrusal modeller ve karar ağaçları) kategorik verileri doğrudan işleyemez. Bu nedenle, kategorik etiketlerin sayısal verilere dönüştürülmesi gerekir.\n",
        "\n",
        "2. **Kategorik Değişkenlerin Kodlanması**: Eğer verinizde kategorik etiketler varsa, bunların sayısal bir forma dönüştürülmesi gereklidir. `LabelEncoder`, her farklı kategoriyi benzersiz bir sayıya dönüştürür.\n",
        "\n",
        "3. **Sıralı Veriler İçin**: Eğer etiketler sıralı ise (örneğin, düşük, orta, yüksek gibi), `Label Encoding` kullanmak anlamlıdır çünkü her kategoriye bir sıra numarası atar. Örneğin, bir müşteri memnuniyetini 1, 2, 3 olarak kodlamak uygun olabilir.\n",
        "\n",
        "4. **Bellek ve Hesaplama Verimliliği**: `One-hot encoding`'de her kategori için ayrı bir sütun oluşturulurken, `Label Encoding` sadece tek bir sütun kullanır. Bu, veri setinin boyutunu küçültür ve bellek kullanımı açısından daha verimli olabilir. Ancak, `Label Encoding` bazen etiketler arasındaki ilişkiyi yanlış anlamaya yol açabilir.\n",
        "\n",
        "---\n",
        "\n",
        " `Label Encoding` ve `One-hot Encoding` Farkı:\n",
        "\n",
        "- **`Label Encoding`**: Her kategoriyi bir sayıya dönüştürür. Genellikle sıralı verilerde kullanılır ve kategoriler arasında gizli sıralama ilişkileri oluşturabilir.\n",
        "  \n",
        "  Örnek:\n",
        "  ```\n",
        "  [\"cat\", \"dog\", \"fish\"]\n",
        "  --> [0, 1, 2]\n",
        "  ```\n",
        "\n",
        "- **`One-hot Encoding`**: Her kategoriyi ikili vektörler ile temsil eder. Kategoriler arasındaki ilişkiyi temsil etmez ve her kategori bağımsız olarak işlenir.\n",
        "  \n",
        "  Örnek:\n",
        "  ```\n",
        "  [\"cat\", \"dog\", \"fish\"]\n",
        "  --> [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
        "  ```"
      ],
      "metadata": {
        "id": "R4kbyMxmblct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelEncoder örneğinden sınıf adlarını ve sınıf sayısını alın\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "id": "VBxAPLplZ90E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "572e3d70-b8df-403f-e117-086f6e6b0ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, **LabelEncoder** tarafından kodlanan sınıf etiketlerini ve toplam sınıf sayısını almak için kullanılır. Şimdi kodu daha ayrıntılı şekilde açıklayalım:\n",
        "\n",
        "```python\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names\n",
        "```\n",
        "\n",
        "1. **`label_encoder.classes_`**:\n",
        "   - **`LabelEncoder`** sınıfının `.classes_` özelliği, etiketlerin **sayısal formda** kodlanmış hallerini, **orijinal kategorik etiketler** olarak içerir.\n",
        "   - Bu özellik, eğitim verisi üzerinde `fit()` metodu çalıştırıldıktan sonra doldurulur ve her bir sınıfın (etiketin) sırasıyla **sıfırdan başlayarak numaralandığı** sınıf adlarını içerir.\n",
        "   - Örneğin, `LabelEncoder` ile \"cat\", \"dog\", \"fish\" etiketlerini kodladığınızda, `label_encoder.classes_` şu şekilde olur:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "\n",
        "2. **`len(label_encoder.classes_)`**:\n",
        "   - Bu ifade, **`label_encoder.classes_`**'deki öğelerin sayısını döndürür. Yani, **kaç farklı sınıf** olduğunu verir.\n",
        "   - Örneğin, eğer `classes_` şöyleyse:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "     Burada 3 sınıf olduğu için, `num_classes` değeri `3` olacaktır.\n",
        "\n",
        "3. **`class_names = label_encoder.classes_`**:\n",
        "   - Bu satır, **sınıf adlarını** (`classes_`) bir değişkene atar. Yani, etiketlerin orijinal hallerini `class_names` değişkenine kaydeder.\n",
        "   - Eğer `classes_` array'ı şu şekildeyse:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "     O zaman `class_names` şu değeri alır:\n",
        "     ```python\n",
        "     array(['cat', 'dog', 'fish'])\n",
        "     ```\n",
        "\n",
        "4. **`num_classes, class_names`**:\n",
        "   - Son olarak, bu iki değeri döndürür:\n",
        "     - `num_classes`: Toplam sınıf sayısını verir.\n",
        "     - `class_names`: Etiketlerin orijinal, kategorik isimlerini verir.\n",
        "\n",
        "   Bu kodun çıktısı şu şekilde olur:\n",
        "\n",
        "   ```python\n",
        "   num_classes = 3\n",
        "   class_names = ['cat', 'dog', 'fish']\n",
        "   ```\n",
        "\n",
        "---\n",
        "\n",
        "### Örnek:\n",
        "\n",
        "Varsayalım ki etiketleriniz şu şekilde:\n",
        "```\n",
        "[\"cat\", \"dog\", \"fish\"]\n",
        "```\n",
        "\n",
        "`LabelEncoder` bunları sırasıyla şu şekilde kodlar:\n",
        "```\n",
        "0 -> cat\n",
        "1 -> dog\n",
        "2 -> fish\n",
        "```\n",
        "\n",
        "Kod çalıştığında:\n",
        "- `num_classes` değeri `3` olur (çünkü üç farklı sınıf var).\n",
        "- `class_names` değeri şu şekilde olur:\n",
        "  ```python\n",
        "  array(['cat', 'dog', 'fish'])\n",
        "  ```\n",
        "\n",
        "Bu sayede, modelin tahminlerinin geri dönüştürülmesi ve anlaşılabilir hale getirilmesi kolaylaşır."
      ],
      "metadata": {
        "id": "GjGhG3EzcL1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Modelleme**"
      ],
      "metadata": {
        "id": "fLg5Opx7j5di"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medikal çalışmasının kaynağı --> https://arxiv.org/pdf/1612.05251"
      ],
      "metadata": {
        "id": "FSsiIcfHajv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1. Model 0 Temel Model Yazımı ve Değerlendirilmesi**"
      ],
      "metadata": {
        "id": "do7rBdEbj5ZV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "İlk modelimiz, Scikit-Learn'in makine öğrenimi haritası tarafından önerildiği gibi bir TF-IDF Multinomial Naive Bayes modelidir. https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
        "\n",
        "Bunu oluşturmak için, TF-IDF (terim frekansı-ters belge frekansı) algoritmasını kullanarak soyut cümlelerimizi sayılara dönüştürmek için TfidfVectorizer sınıfını kullanan bir Scikit-Learn Pipeline oluşturacağız ve ardından MultinomialNB agloritm'i kullanarak cümlelerimizi sınıflandırmayı öğreneceğiz.\n",
        "\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
      ],
      "metadata": {
        "id": "909wi9kJcY_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Boru hattı oluştur\n",
        "model_0 = Pipeline([\n",
        "  (\"tf-idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Eğitim verilerini boru hattına uydur\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded);"
      ],
      "metadata": {
        "id": "jkUJxnNf6qS6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "81c8d0a0-4949-46f6-df3a-3101829fd348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.05 s, sys: 39.5 ms, total: 3.09 s\n",
            "Wall time: 3.1 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tf-idf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Değerlerinde verileri üzerindeki bu modeli değerlendir\n",
        "model_0.score(\n",
        "    X = val_sentences,\n",
        "    y = val_labels_encoded\n",
        ")"
      ],
      "metadata": {
        "id": "mXAk9C2l8Dbl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c28102-1de0-4f6a-bc77-3ee31ed83ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminler yap\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "id": "Lhf43dqp8HYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92706482-b3f4-4e0a-c621-80dd25f314e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, 2, 2, 2, 2, 2, 4, 4, 0, 4, 1, 1, 2, 2, 4, 1, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`from sklearn.feature_extraction.text import TfidfVectorizer`\n",
        "- **TfidfVectorizer**: Bu, metin verilerini sayısal verilere dönüştüren bir vektörleştirici (vectorizer) sınıfıdır. \"TF-IDF\" (Term Frequency-Inverse Document Frequency) yöntemi, her terimin önemini hesaplarken, terimin bir belgedeki sıklığını (TF) ve tüm koleksiyon içindeki nadirliğini (IDF) göz önünde bulundurur. Bu sayede önemli ve nadir kelimelere yüksek ağırlık verilir.\n",
        "- **Amaç**: Doğal dildeki metni makine öğrenimi modelinin anlayacağı sayısal verilere dönüştürmek.\n",
        "\n",
        "`from sklearn.naive_bayes import MultinomialNB`\n",
        "- **MultinomialNB**: Bu, Naive Bayes sınıflandırıcılarının bir çeşididir. Özellikle metin verileri gibi çok terimli (multinomial) verilerle çalışmak için uygundur. Her bir belgeyi, o belgenin hangi sınıfa ait olduğunu tahmin etmek için kullanır.\n",
        "- **Amaç**: Metin verilerini belirli bir kategoriye (sınıfa) sınıflandırmak. Örneğin, bir e-postanın spam olup olmadığını tahmin etmek.\n",
        "\n",
        "`from sklearn.pipeline import Pipeline`\n",
        "- **Pipeline**: Bu, bir dizi adımı sırasıyla birleştiren bir sınıftır. Bir boru hattı (pipeline), veriyi işlemek için gereken tüm adımları (veya işlemleri) sıralı şekilde organize eder. Yani, bu yapıyı kullanarak, veri hazırlık aşamasından modelin eğitilmesine kadar her şeyi bir arada tutabilirsiniz.\n",
        "- **Amaç**: Veriyi ve modeli düzenli bir şekilde işlemeyi sağlayan bir \"boru hattı\" oluşturmak.\n",
        "\n",
        "`model_0 = Pipeline([(\"tf-idf\", TfidfVectorizer()), (\"clf\", MultinomialNB())])`\n",
        "- **Bu satırda**:\n",
        "  - Bir **pipeline** oluşturuluyor. Bu boru hattı, iki adım içeriyor:\n",
        "    1. **\"tf-idf\"**: İlk adımda metin verilerini, `TfidfVectorizer` kullanarak sayısal verilere dönüştürmek.\n",
        "    2. **\"clf\"**: İkinci adımda, dönüştürülmüş veriyi `MultinomialNB` sınıflandırıcısına vererek sınıflandırmak.\n",
        "- **Amaç**: Veriyi sayısal hale getirdikten sonra, bu sayısal veriyi kullanarak bir sınıflandırma yapmak.\n",
        "\n",
        "`model_0.fit(X=train_sentences, y=train_labels_encoded)`\n",
        "- **fit**: Modeli eğitim verileriyle (X) ve etiketleriyle (y) eğitir. Bu adımda:\n",
        "  - `X` (train_sentences): Eğitim verisi, yani metinleri içeren bir liste veya dizi.\n",
        "  - `y` (train_labels_encoded): Eğitim verilerine karşılık gelen etiketler. Bu, her bir metne hangi sınıfın (etiketin) ait olduğunu gösterir. Örneğin, bir metnin \"spam\" veya \"ham\" (spam değil) olduğunu belirten etiketler olabilir.\n",
        "  \n",
        "- **Amaç**: Model, eğitim verilerini kullanarak metinlerin hangi sınıfa ait olduğunu öğrenir. İlk adımda metinleri sayısal verilere dönüştürür, sonra ikinci adımda bu sayısal veriyi sınıflandırıcıya verir ve öğrenme işlemi başlar."
      ],
      "metadata": {
        "id": "6ivSrWnk-fpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2. Yardımcı Fonksiyonlar Dosyası**"
      ],
      "metadata": {
        "id": "CYo03qcGj5XY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temel modelin tahminlerini değerlendirmek için önceden hazırlanmış helper_functions.py komut dosyasını içeri aktaracağız. Bu dosya içerisinde calculate_results() işlevi ile değerlendirme yaparız.\n",
        "\n",
        "Daha spesifik olarak calculate_results() işlevi aşağıdakileri elde etmemize yardımcı olacaktır:\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1 Score"
      ],
      "metadata": {
        "id": "cwtnvfmJ8dy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yardımcı işlevler komut dosyasını indirin\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "id": "iFnqZ32S9H7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77501a1a-6698-4203-a31e-e439ca36e638"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-02 19:30:13--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2025-01-02 19:30:13 (14.7 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### İçe aktarılmış olan yardımcı fonksiyonların detayları\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "\n",
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's\n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False):\n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "\n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"\n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "\n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes),\n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "\n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n",
        "\n",
        "# Make a function to predict on images and plot them (works with multi-class)\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "\n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here)\n",
        "    \"\"\"\n",
        "\n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "\n",
        "# Create function to unzip a zipfile into current working directory\n",
        "# (since we're going to be downloading and unzipping a few files)\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "7_-HlRGI9H4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate_results'u yardımcı fonksiyonlardan içeri aktarma\n",
        "from helper_functions import calculate_results\n",
        "\n",
        "# Temel modelin sonuçları nedir?\n",
        "baseline_results = calculate_results(\n",
        "    y_true = val_labels_encoded,\n",
        "    y_pred = baseline_preds\n",
        ")\n",
        "\n",
        "baseline_results"
      ],
      "metadata": {
        "id": "zoFV1fOY9fcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f133b1f2-8ebc-4da8-c7da-1be3342702dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869,\n",
              " 'f1': 0.6989250353450294}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3. Derin Modelleme İçin Veri Hazırlığı**"
      ],
      "metadata": {
        "id": "5u6NpAHBj5U8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etiketleri sayısal formatta hazırlamıştık, şimdi metinleri sayısal biçime dönüştürmek için çalışma yapmalıyız, metin vektörleştirme. Her bir token bir sayıya dönüştürülür ve bu birleştirilmiş kelimelere dayalı bir embeddings oluşturulur. Denemek ve geliştirmek için çalışma temelimiz var.\n",
        "\n",
        "Ancak daha derin modeller oluşturmaya başlamadan önce, vektörleştirme ve katmanları gömme oluşturmalıyız.\n",
        "\n",
        "Vektörleştirme katmanı metnimizi sayılara dönüştürecek ve gömme katmanı bu sayılar arasındaki ilişkileri yakalayacaktır.\n",
        "\n",
        "Vektörleştirme ve gömme katmanlarımızı oluşturmaya başlamak için uygun kitaplıkları (yani TensorFlow ve NumPy) içe aktarmamız gerekecek.\n",
        "\n",
        "Cümlelerimizi sayılara dönüştüreceğimiz için, her cümlede kaç kelime olduğunu bulmak gerekir.\n",
        "\n",
        "Modelimiz cümlelerimizden geçtiğinde, hepsi aynı uzunlukta olduğunda en iyi şekilde çalışır (bu, aynı boyutta tensörlerde gruplar oluşturmak için önemlidir).\n",
        "\n",
        "Örneğin, bir cümle sekiz kelime uzunluğunda ve diğeri 29 kelime uzunluğundaysa, sekiz kelimelik cümleyi sıfırla doldurmak istiyoruz, böylece 29 kelimelik cümle ile aynı uzunlukta olur."
      ],
      "metadata": {
        "id": "X2jmqEBPi8Q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Q8Ow2KOvjvxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Her cümle ortalama ne kadar uzunlukta? Dağılım hakkında bilgimiz olmalı\n",
        "# Bir cümle 4 kelime iken diğeri 90 kelime de olabilir\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "\n",
        "avg_sent_len # ortalama cümle uzunluğunu döndür (belirteç cinsinden)"
      ],
      "metadata": {
        "id": "nUhtDwkyjzDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50fa5220-09a0-4a34-c089-f40ffa8c8c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`sent_lens = [len(sentence.split()) for sentence in train_sentences]`\n",
        "- Bu satırda, eğitim verisindeki her cümle için kelime sayısı hesaplanıyor.\n",
        "- `train_sentences`: Bu, eğitim verisindeki cümlelerin bir listesidir. Her bir öğe bir cümledir.\n",
        "- `sentence.split()`: Bu, her cümleyi boşluk karakterine göre böler ve cümledeki kelimeleri bir liste olarak döndürür. Örneğin, `\"Bu bir test cümlesidir.\"` cümlesi `[\"Bu\", \"bir\", \"test\", \"cümlesidir.\"]` olarak bölünür.\n",
        "- `len(sentence.split())`: Bu, her cümlenin kelime sayısını hesaplar. Örneğin, `\"Bu bir test cümlesidir.\"` cümlesi 4 kelime içerdiği için `len(sentence.split())` değeri 4 olacaktır.\n",
        "- **Amaç**: Her cümlenin kelime sayısını içeren bir liste (`sent_lens`) oluşturmak.\n",
        "\n",
        "`avg_sent_len = np.mean(sent_lens)`\n",
        "- **`np.mean(sent_lens)`**: NumPy kütüphanesinin `mean` fonksiyonu, `sent_lens` listesindeki tüm cümlelerin kelime sayılarının ortalamasını hesaplar.\n",
        "- **Amaç**: Cümlelerin ortalama kelime sayısını bulmak.\n",
        "\n",
        "Örnek:\n",
        "- Diyelim ki `train_sentences` şöyle:\n",
        "  ```python\n",
        "  train_sentences = [\n",
        "      \"Merhaba.\",\n",
        "      \"Bugün çok güzel bir gün.\",\n",
        "      \"Yapay zeka, veri biliminde önemli bir yer tutmaktadır. Çeşitli alanlarda kullanılmaktadır.\"\n",
        "  ]\n",
        "  ```\n",
        "- İlk cümlede 1 kelime var, ikinci cümlede 5 kelime var, üçüncü cümlede ise 10 kelime var.\n",
        "- `sent_lens` listesi: `[1, 5, 10]`\n",
        "- Ortalama cümle uzunluğu (`avg_sent_len`) hesaplanır: `(1 + 5 + 10) / 3 = 5.33` (yaklaşık)\n",
        "\n",
        "Sonuç olarak, ortalama cümle uzunluğu yaklaşık 5.33 kelime olacaktır."
      ],
      "metadata": {
        "id": "W6Chrg2d_Y0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dağılım nasıl?\n",
        "plt.hist(sent_lens, bins = 7);"
      ],
      "metadata": {
        "id": "WLQnBg9Gkf5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "b528005f-e07f-4b4a-db16-0556940e01eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cümlelerin büyük çoğunluğunun uzunluğu 0 ile 50 token arasında gibi görünüyor.\n",
        "\n",
        "Cümle uzunluklarının %95'ini kapsayan değeri bulmak için NumPy'nin yüzdelik dilimini kullanabiliriz.\n",
        "\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.percentile.html\n",
        "\n",
        "🤔 Soru: Neden %95?\n",
        "\n",
        "Eğitim setindeki cümlelerin maksimum cümle uzunluğunu kullanabiliriz.\n",
        "\n",
        "Sonuç 55 çıkar (aşağıda). Belirteç katmanımızı oluşturduğumuzda, tüm cümlelerimizi aynı uzunlukta dönüştürmek için bu değeri kullanacağız. Uzunluğu 55'in altında olan cümleler sıfırlarla doldurulur ve uzunluğu 55'in üzerinde olan cümleler kesilir (55'ten sonraki kelimeler kesilir)."
      ],
      "metadata": {
        "id": "VJtKueVokt7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bir cümlenin uzunluğu, uzunlukların %95'ini kapsıyor?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "\n",
        "output_seq_len # çıktımızın uzunluğunu döndür"
      ],
      "metadata": {
        "id": "bucDAYY4kurv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdfccad-6cc5-4ab3-cc7c-ed04695f6b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim veri setindeki maksimum cümle uzunluğu\n",
        "max(sent_lens)"
      ],
      "metadata": {
        "id": "e1fWyaeclVLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69063ee-2f0a-407a-9250-6e938fc2d7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔑 Not: Bir NLP sorunu için bir metin külliyatı ile çalışırken attığımız adımlar iyi bir uygulamadır. Numunelerinizin ne kadar uzun olduğunu ve bunların dağılımının ne olduğunu bilmek istiyorsunuz. Daha fazla örnek için bkz. bölüm 4 PubMed 200k RCT makalesinin Veri Analizi. https://arxiv.org/pdf/1710.06071"
      ],
      "metadata": {
        "id": "odqGm6Klm0vc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4. Metin Vektörleştirme**"
      ],
      "metadata": {
        "id": "mMFoavzfj5Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metinleri sayıya dönüştürmeliyiz, TensorFlow'dan TextVectorization katmanını kullanmalıyız.\n",
        "\n",
        "Max_tokens (veri kümemizdeki benzersiz kelimelerin sayısı) ve output_sequence_length (her vektörleştirilmiş cümle için istediğimiz çıktı uzunluğu) hariç tüm parametreleri varsayılan tutacağız.\n",
        "\n",
        "PubMed 200k RCT makalesinin 3.2. Bölümü, PubMed 20k veri kümesinin kelime boyutunu 68.000 olarak belirtir. Yani bunu max_tokens parametremiz olarak kullanacağız. https://arxiv.org/pdf/1710.06071\n",
        "\n",
        "***Tokenization ile embedding arasındaki fark, embedding daha zengin bir temsildir. Örneğin embedding, eğitim verilerinden geçerken her kelime için üç boyutlu bir vektör oluşturulabilir. Tüm bu değerler, metnimizdeki kelimelerin modelimiz olarak birbirleriyle nasıl ilişkili olduğunu öğrenebilir.***\n",
        "\n",
        "***Tokenization, her kelime bir int rakam olabilir, one hot encoding ile 010, 100, 001 gibi matris olabilir. Embedingste 0-1 arası rakamlardan oluşan 3x3 matris oluşabilir.***"
      ],
      "metadata": {
        "id": "1CPRVK8em7f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kelime dağarcığımızda kaç kelime var? (doküman 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "metadata": {
        "id": "mYkMj8Yrofcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektörleştirici oluştur\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(\n",
        "    max_tokens = max_tokens,       # kelime hazinesindeki kelime sayısı\n",
        "    output_sequence_length = 55    # vektörleştirilmiş dizilerin istenen çıktı uzunluğu\n",
        ")"
      ],
      "metadata": {
        "id": "GWdGp91Sos5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Modelin eğitilmesi sırasında daha küçük max_tokens değerleri kullanmak, işlem gücünü azaltabilir ve eğitim süresini hızlandırabilir. Ancak, çok düşük bir max_tokens değeri, önemli kelimelerin kaybolmasına neden olabilir.\n",
        "* Yaygın olarak, max_tokens değeri 10,000 ile 50,000 arasında bir aralıkta seçilir, ancak bu sayılar veri setinizin büyüklüğüne bağlı olarak değişebilir.\n",
        "\n",
        "`max_tokens` Değerini Belirlemek için Yöntemler\n",
        "\n",
        "1. **Kelime Frekansına Dayalı Seçim**\n",
        "Bir yöntem, eğitim verinizdeki kelimelerin frekansını hesaplamak ve en sık kullanılan belirli sayıda kelimeyi seçmektir. Örneğin, `max_tokens`'ı eğitim setinizdeki en sık 10,000 kelimeye sınırlayabilirsiniz.\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "import numpy as np\n",
        "\n",
        "# Verinizin kelimelerini tokenize edin\n",
        "all_words = ' '.join(train_sentences)  # Tüm cümleleri birleştir\n",
        "word_list = all_words.split()  # Tüm kelimelere ayır\n",
        "\n",
        "# Kelime sıklığını hesapla\n",
        "word_counts = {word: word_list.count(word) for word in set(word_list)}\n",
        "\n",
        "# Kelime sıklığına göre en sık geçen 10,000 kelimeyi seç\n",
        "sorted_words = sorted(word_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "most_common_words = sorted_words[:10000]\n",
        "\n",
        "# max_tokens olarak en sık geçen kelimeler sayısını belirleyebilirsiniz\n",
        "max_tokens = len(most_common_words)\n",
        "```\n",
        "\n",
        "2. **Veri Setindeki Kelimeleri Sayarak**\n",
        "Veri setindeki kelimeleri sayarak doğrudan `max_tokens` değerini hesaplayabilirsiniz. Örneğin, toplamda kaç farklı kelime olduğunu bulabilir ve bunun bir yüzdesi olarak `max_tokens` belirleyebilirsiniz.\n",
        "\n",
        "```python\n",
        "from collections import Counter\n",
        "\n",
        "# Tüm metni birleştir\n",
        "all_words = ' '.join(train_sentences)\n",
        "words = all_words.split()\n",
        "\n",
        "# Kelime sayısını ve farklı kelimelerin sayısını hesapla\n",
        "word_counts = Counter(words)\n",
        "unique_words = len(word_counts)\n",
        "\n",
        "# `max_tokens`'ı veri setindeki benzersiz kelimelerin sayısına göre belirleyebilirsiniz\n",
        "max_tokens = unique_words  # Örneğin tüm benzersiz kelimeler kullanılabilir\n",
        "```\n",
        "\n",
        "3. **Pratik Bir Yaklaşım**\n",
        "Eğer elinizde büyük bir veri seti varsa ve fazla işlem gücü harcamak istemiyorsanız, genel bir yaklaşım olarak `max_tokens`'ı 10,000 ile 50,000 arasında seçebilirsiniz. Bu, çoğu metin sınıflandırma modelinde yeterince iyi bir başlangıç noktasıdır.\n",
        "\n",
        "```python\n",
        "# Örnek olarak max_tokens değeri\n",
        "max_tokens = 10000  # veya 5000, 20000 gibi\n",
        "```"
      ],
      "metadata": {
        "id": "4vrysMFvAM1u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi metin vektörleştiriciyi eğitim verilerine uyarlayalım (eğitim verilerini okusun ve hangi sayının hangi kelimeyi temsil etmesi gerektiğini bulsun) ve ardından test edelim.\n",
        "\n",
        "Bunu test verilerindeki doğrulamaya uyarlarsak, bu veri kümelerinin görünmemesi amaçlanmıştır. Böylece eğitim verilerine uyum sağladık ve daha sonra doğrulama ve test verilerimize sığdırabiliriz."
      ],
      "metadata": {
        "id": "0G4PpWq1pb5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektörleştiricisini eğitim cümlelerine uyarlayın\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "GAQ1JD5Tp-BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektörleştiricisini test edin\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Metin:\\n{target_sentence}\")\n",
        "print(f\"\\nMetin Uzunluğu: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVektörleşmiş Metin:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "metadata": {
        "id": "WJ6zlnhAp97F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15161be2-b3c6-478b-abab-8ba1ec8650c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metin:\n",
            "among accord lipid trial participants , the occurrence of extremely low hdl-c ever during study follow-up was @ % higher among those randomized to fenofibrate ( @ % fenofibrate vs. @ % placebo , p < @ ) .\n",
            "\n",
            "Metin Uzunluğu: 39\n",
            "\n",
            "Vektörleşmiş Metin:\n",
            "[[ 116 9495  864   32   60    2 1066    4 3945  220 2784 6099   52   17\n",
            "    94   10   82  116  125   29    6 7078 7078   44   48   14    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim sözlüğümüzde kaç kelime var?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Sözlükteki kelime sayısı: {len(rct_20k_text_vocab)}\"),\n",
        "print(f\"Sözlükteki en çok tekrar eden kelime: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Sözlükte en az tekrar eden kelime: {rct_20k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "Lz_ELzw4p92Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e154565c-ae04-4f5b-cf5c-4767ce675312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sözlükteki kelime sayısı: 64841\n",
            "Sözlükteki en çok tekrar eden kelime: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Sözlükte en az tekrar eden kelime: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metin vektörleştiricimizin yapılandırmasını edinin\n",
        "text_vectorizer.get_config()"
      ],
      "metadata": {
        "id": "i0GdDHHVp9xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d691713d-cd29-44ad-c910-fdc80a6c6af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization_1',\n",
              " 'trainable': True,\n",
              " 'dtype': {'module': 'keras',\n",
              "  'class_name': 'DTypePolicy',\n",
              "  'config': {'name': 'float32'},\n",
              "  'registered_name': None},\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.5. Gömme Hazırlama**"
      ],
      "metadata": {
        "id": "UYpH9jrvj5Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Belirteç_vektörleştirme katmanımız, metnimizdeki kelimeleri doğrudan sayılarla eşler. Ancak, bu mutlaka bu sayılar arasındaki ilişkileri yakalamaz.\n",
        "\n",
        "Metnimizin daha zengin bir sayısal temsilini oluşturmak için bir gömme kullanabiliriz. https://www.tensorflow.org/text/guide/word_embeddings?hl=tr\n",
        "\n",
        "Modelimiz öğrendikçe (birçok farklı soyut cümle örneğini ve etiketlerini gözden geçirerek), külliyatımızdaki belirteçler arasındaki ilişkileri daha iyi temsil etmek için gömmesini güncelleyecektir.\n",
        "\n",
        "TensorFlow'un Gömme katmanını kullanarak eğitilebilir bir gömme katmanı oluşturabiliriz.\n",
        "\n",
        "Bir kez daha, burada ilgilendiğimiz ana parametreler, Gömme katmanımızın giriş ve çıkışlarıdır.\n",
        "\n",
        "Input_dim parametresi kelime dağarcığımızın boyutunu tanımlar. Ve output_dim parametresi, gömme çıktısının boyutunu tanımlar.\n",
        "\n",
        "Bir kez oluşturulduktan sonra, gömme katmanımız text_vectorization katmanımızın tamsayı çıktılarını girdi olarak alacak ve bunları output_dim boyutu vektörlerine dönüştürecektir."
      ],
      "metadata": {
        "id": "lG8pzvdLrVNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Genel Notlar**\n",
        "- output dim --> 32,64, 128'in gibi 8'in katları olmalı.\n",
        "- Her ne kadar büyük gömülürse modelin eğitmesi gereken parametre sayısı o kadar fazla olur.\n",
        "- mask_zero: Boolean değerdir. input_value=0. Özel bir padding. RNN kullanımı çeşitli uzunlukta giriş verileri kullanılırken elverişlidir. Eğer true ise modeldeki tüm subsequent katmanlar maskelenmeli. Daha verimli hesaplama için TRUE olmalı.\n",
        "- Çıktıyı incele, çok sıfır var o zaman verimli bir model (one_hot benzeri).\n",
        "- token_embeding --> Token yerleştirme katmanına herhangi bir şey aktarmadan önce bunun sayısal biçimde olması gerekli.\n",
        "- Gömülü cümle şeklinde her bir dizi uzunluğunda rakamlardan 55 adet var her biri 128 vektör uzunluğunda."
      ],
      "metadata": {
        "id": "4ERZ1fBqtMPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gömme katmanı oluştur (aslında input_dim ve output_dim yeterli, listeyi uzatadabilirsin)\n",
        "token_embed = layers.Embedding(\n",
        "    input_dim = len(rct_20k_text_vocab), # kelime uzunluğu\n",
        "    output_dim = 128,                    # farklı yerleştirme boyutları, eğitilecek parametrelerin büyük ölçüde farklı olmasına neden olur\n",
        "    mask_zero = True,                    # Değişken dizi uzunluklarını işlemek için maskelemeyi kullanın (yerden tasarruf edin)\n",
        "    name = \"token_embedding\"\n",
        ")\n",
        "\n",
        "# Örnek gömmelerin gösterimi\n",
        "print(f\"Vektörleşme öncesi cümleler:\\n{target_sentence}\\n\")\n",
        "\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Vektörleşme sonrası cümle (gömme öncesi):\\n{vectorized_sentence}\\n\")\n",
        "\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Gömme sonrası cümle:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Gömülmüş cümle şekli: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "id": "SogevH0etatn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6390db14-d741-4157-a6f3-32cf1c261911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vektörleşme öncesi cümleler:\n",
            "among accord lipid trial participants , the occurrence of extremely low hdl-c ever during study follow-up was @ % higher among those randomized to fenofibrate ( @ % fenofibrate vs. @ % placebo , p < @ ) .\n",
            "\n",
            "Vektörleşme sonrası cümle (gömme öncesi):\n",
            "[[ 116 9495  864   32   60    2 1066    4 3945  220 2784 6099   52   17\n",
            "    94   10   82  116  125   29    6 7078 7078   44   48   14    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Gömme sonrası cümle:\n",
            "[[[ 0.0450269   0.03514195 -0.0080569  ...  0.00595022 -0.03892398\n",
            "    0.04339631]\n",
            "  [ 0.0489152   0.03578948  0.03945035 ... -0.03081435 -0.00316496\n",
            "    0.04754409]\n",
            "  [-0.00370265  0.04541652  0.04479161 ...  0.01556161  0.02524466\n",
            "    0.00633305]\n",
            "  ...\n",
            "  [-0.02776702 -0.03965263  0.04264294 ... -0.03421847  0.01198611\n",
            "   -0.02226293]\n",
            "  [-0.02776702 -0.03965263  0.04264294 ... -0.03421847  0.01198611\n",
            "   -0.02226293]\n",
            "  [-0.02776702 -0.03965263  0.04264294 ... -0.03421847  0.01198611\n",
            "   -0.02226293]]]\n",
            "\n",
            "Gömülmüş cümle şekli: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **`input_dim`**:\n",
        "   - **Tanım**: Gömme katmanına giren veri boyutunu belirtir. Bu, kelime veya token sayısına eşittir.\n",
        "   - **Özellik**: Burada `len(rct_20k_text_vocab)` değeri, kelime dağarcığındaki toplam kelime sayısını temsil eder.\n",
        "\n",
        "2. **`output_dim`**:\n",
        "   - **Tanım**: Gömme vektörlerinin boyutu. Yani, her token için kaç boyutlu bir vektör elde edileceğini belirtir.\n",
        "   - **Özellik**: Bu örnekte, her token için 64 boyutlu bir vektör kullanılacaktır.\n",
        "\n",
        "3. **`name`**:\n",
        "   - **Tanım**: Katmana bir isim verir. Bu genellikle modelin özelliklerini daha okunabilir hale getirmek için kullanılır.\n",
        "   - **Özellik**: Burada katmanın adı `token_embedding` olarak belirlenmiş.\n",
        "\n",
        "4. **`mask_zero`**:\n",
        "   - **Tanım**: Bu parametre, girişteki sıfırların (yani genellikle padding token'larının) göz ardı edilip edilmeyeceğini belirtir. Eğer `True` ise sıfır olan input değerleri maskelenir.\n",
        "   - **Özellik**: Bu durumda, sıfır olan değerler (padding) gömme katmanına dahil edilmez.\n",
        "\n",
        "5. **`input_length`**:\n",
        "   - **Tanım**: Gömme katmanına giren dizilerin uzunluğunu belirtir. Bu, giriş verisinin sabit bir uzunluğa sahip olduğunu varsayar.\n",
        "   - **Özellik**: Burada, her giriş dizisinin uzunluğu 55 olarak belirlenmiş.\n",
        "\n",
        "6. **`embeddings_initializer`**:\n",
        "   - **Tanım**: Gömme katmanındaki vektörlerin başlangıç değerlerini belirler. `uniform`, değerlerin küçük rastgele sayılarla başlatılacağı anlamına gelir.\n",
        "   - **Özellik**: Bu, genellikle ağırlıkların rastgele bir şekilde başlangıçta dağıtılması için kullanılır.\n",
        "\n",
        "7. **`trainable`**:\n",
        "   - **Tanım**: Gömme katmanının eğitilebilir olup olmadığını belirtir. Eğer `True` ise, gömme katmanındaki ağırlıklar (embedding vektörleri) eğitilebilir (yani öğrenilebilir).\n",
        "   - **Özellik**: Burada, gömme katmanı eğitilebilir olarak ayarlanmış.\n",
        "\n",
        "8. **`activity_regularizer`**:\n",
        "   - **Tanım**: Aktivite düzenleyici, katmanın çıktılarına uygulanan bir L2 ceza terimidir. Modelin daha az kompleks olmasını sağlamak için kullanılır.\n",
        "   - **Özellik**: Bu, gömme katmanının çıktısına L2 ceza uygulanacağını belirtir.\n",
        "\n",
        "9. **`embeddings_regularizer`**:\n",
        "   - **Tanım**: Gömme katmanının ağırlıklarına uygulanan düzenleyicidir. Bu da L2 ceza terimi kullanarak ağırlıkların büyüklüğünü sınırlamaya yardımcı olur.\n",
        "   - **Özellik**: Bu, gömme vektörlerinin regularizasyonu için L2 ceza uygulanır.\n",
        "\n",
        "10. **`update_embedding`**:\n",
        "    - **Tanım**: Bu parametre TensorFlow'un eski sürümlerinde kullanılabilir. Günümüzde bu parametre yerine `trainable=True` tercih edilmektedir.\n",
        "    - **Özellik**: Bu, gömme katmanının ağırlıklarının güncellenip güncellenmeyeceğini kontrol eder. Ancak bu parametre artık yaygın olarak kullanılmaz.\n",
        "\n",
        "11. **`input_shape`**:\n",
        "    - **Tanım**: Katman için giriş verisinin şekli. Burada `(None, 55)` kullanılmış; `None` giriş batch boyutunun dinamik olduğunu belirtir, `55` ise her dizinin uzunluğunu belirtir.\n",
        "\n",
        "12. **`dtype`**:\n",
        "    - **Tanım**: Katmandaki verinin veri türünü belirtir. Genellikle `float32` kullanılır.\n",
        "    - **Özellik**: Burada, veri türü olarak `float32` belirtilmiş.\n",
        "\n",
        "---\n",
        "\n",
        "- **`mask_zero=True`**: Eğer padding yapıyorsanız, sıfırların maskelenmesi önemli olabilir.\n",
        "- **`embeddings_initializer`** ve **`trainable=True`**: Gömme katmanlarının başlangıçta rastgele başlatılmasını ve eğitilebilir olmasını istiyorsanız bunları kullanabilirsiniz.\n",
        "- **`activity_regularizer`** ve **`embeddings_regularizer`**: Eğer overfitting'i engellemek için düzenleme (regularization) yapmak istiyorsanız bu parametreleri kullanabilirsiniz."
      ],
      "metadata": {
        "id": "75OSI68AvunB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.6. Veri Kümelerini hazırlama**"
      ],
      "metadata": {
        "id": "i1OzQJ3Nj5HZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bir makine öğrenimi modeliyle kullanılmak üzere veri kümelerimizi önceden işleme zahmetini yaşadık, ancak modellerimizle daha hızlı çalışmasını sağlamak için kullanabileceğimiz birkaç adım var.\n",
        "\n",
        "Yani, tf.data API, daha hızlı veri yüklemesini sağlayan yöntemler sağlar.\n",
        "\n",
        "📖 Kaynak: TensorFlow'da veri yüklemeyle ilgili en iyi uygulamalar için aşağıdakilere göz atın:\n",
        "\n",
        "- tf.data: TensorFlow giriş boru hatları oluşturun https://www.tensorflow.org/guide/data?hl=tr\n",
        "\n",
        "- tf.data API ile daha iyi performans https://www.tensorflow.org/guide/data_performance?hl=tr\n",
        "\n",
        "Verilerimizle kullanmak isteyeceğimiz ana adımlar, onu bir PrefetchDataset gruplarına dönüştürmektir.\n",
        "\n",
        "Bunu yaparak TensorFlow'un verilerimizi GPU'ya mümkün olduğunca hızlı bir şekilde yüklemesini ve daha hızlı eğitim süresine yol açmasını sağlayacağız.\n",
        "\n",
        "Toplu bir PrefetchDataset oluşturmak için batch() ve prefetch() yöntemlerini kullanabiliriz, tf.data.AUTOTUNE parametresi ayrıca TensorFlow'un veri kümelerini hazırlamak için kullanılacak en uygun işlem miktarını belirlemesine izin verecektir.\n",
        "\n",
        "* https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch\n",
        "* https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch\n",
        "* https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE"
      ],
      "metadata": {
        "id": "KKq_Uw1-waSD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Verilerimizi TensorFlow Veri Kümelerine dönüştürün\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset\n",
        "\n",
        "# Hepsi etiket dizesidir.\n",
        "# Eğitim veri seti, veri setini dilimleme eğilimindedir. Yani artık test veri kümelerindeki eğitim doğrulamalarındaki örneklerin her biri artık veri kümelerini dilimleme eğiliminde\n",
        "# Çıktıdaki şekil (None, (5)) tuple tarzındadır. One hot eğitim verisi bir üst şekli etiketler"
      ],
      "metadata": {
        "id": "iyH936Vcw_u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178cac1e-4a02-459d-e8d1-ec2188436407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, **TensorFlow veri kümesi (dataset)** oluşturma sürecini gösterir ve **TensorFlow'un `tf.data` API'si** kullanılarak verilerin model eğitimi için uygun bir formatta sunulmasını sağlar.\n",
        "\n",
        "```python\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "```\n",
        "\n",
        "- **`train_labels_one_hot`, eğitim, doğrulama ve test setlerindeki etiketlerin one-hot kodlanmış** haliyle temsil edilen değerlerdir. **One-hot kodlama**, her etiketin bir dizi elemanı olarak temsil edilmesini sağlar. Örneğin, 3 sınıflı bir problemde \"2. sınıf\" için `[0, 1, 0]` şeklinde bir kodlama yapılır.\n",
        "\n",
        "`tf.data.Dataset.from_tensor_slices()` Fonksiyonu:\n",
        "\n",
        "- **`from_tensor_slices()`**: Bu fonksiyon, **tensörler** veya **numpy dizileri** gibi veri yapılarını alır ve bunları **TensorFlow veri kümesine** dönüştürür. Her bir eleman (örneğin bir cümle veya etiket), verisetindeki bir **örnek** (sample) olur.\n",
        "  \n",
        "- Bu fonksiyonun temel amacı, verileri **efektif bir şekilde batch’lemek**, **karıştırmak (shuffle)**, **önceden işleme uygulamak** (örneğin, tokenize etmek) ve modelin eğitim sürecine uygun hale getirmektir.\n",
        "\n",
        "Örneğin:\n",
        "\n",
        "```python\n",
        "train_sentences = [\"Bu bir cümledir.\", \"Bu başka bir cümledir.\"]\n",
        "train_labels_one_hot = [[1, 0], [0, 1]]\n",
        "```\n",
        "\n",
        "Bu verileri `from_tensor_slices()` ile dönüştürdüğümüzde, her cümle ve etiket bir çift (sentence, label) olarak gruplanır ve verisetinin bir parçası haline gelir.\n",
        "\n",
        "```python\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "```\n",
        "\n",
        "Bu işlem, her cümle ve etiketin bir arada olduğu bir **`tf.data.Dataset`** nesnesi oluşturur. Bu nesne, eğitim süreci için daha sonra kullanılabilir.\n",
        "\n",
        "TensorFlow Veri Kümesi Nedir? Ne İşe Yarar?\n",
        "\n",
        "**TensorFlow Veri Kümesi (Dataset)**, büyük ve karmaşık veri kümelerinin **verimli bir şekilde** işlenmesine olanak tanır. Bu nesne, modelin eğitim sürecinde çeşitli işlevler sunar:\n",
        "\n",
        "1. **Veri Yükleme**: Büyük veri kümelerinin belleğe sığmayan kısımlarını verimli bir şekilde yükler.\n",
        "  \n",
        "2. **Batches (Gruplama)**: Verileri küçük gruplara ayırarak modelin her seferinde sadece bir kısmı ile çalışmasını sağlar. Bu, bellek kullanımını optimize eder.\n",
        "\n",
        "3. **Shuffle (Karıştırma)**: Eğitim verilerini karıştırarak, modelin sıralamadan bağımsız olarak öğrenmesini sağlar ve overfitting (aşırı öğrenme) riskini azaltır.\n",
        "\n",
        "4. **Prefetch (Önceden Yükleme)**: Veriler bir batch işlemi için hazır olduğunda, bir sonraki batch'in yüklenmesine başlar. Bu, CPU ve GPU arasında zaman kaybını azaltır ve modelin daha hızlı eğitilmesini sağlar.\n",
        "\n",
        "5. **Transformations (Dönüştürme)**: Veri üzerinde dönüşümler (örneğin, normalizasyon, augmentation, veri temizleme) yapabilirsiniz.\n",
        "\n",
        "Kullanımda Neden Gerekli?\n",
        "\n",
        "TensorFlow veri kümesi, veriyi **yüksek performansla işlemek** için çok önemlidir çünkü:\n",
        "\n",
        "- **Veri Akışını Yönetir**: `tf.data.Dataset`, veri setinin akışını yönetir ve veri üzerinde yapılan işlemleri (örneğin, batch'leme, karıştırma, dönüştürme) kolayca uygular.\n",
        "  \n",
        "- **Bellek Verimliliği**: Büyük veri kümeleriyle çalışırken, `Dataset` nesnesi belleğe tüm veriyi yüklemek yerine, veriyi parça parça işler ve belleği verimli kullanır.\n",
        "  \n",
        "- **Paralel İşlem**: TensorFlow, verisetini paralel işlem yapacak şekilde optimize edebilir, yani birden fazla iş parçacığıyla verileri işleyebilir. Bu, eğitim süresini hızlandırır.\n",
        "\n",
        "- **Pipelines (Veri Boru Hatları)**: `tf.data.Dataset` ile veriyi doğrudan modelle beslemeden önce bir dizi işlem (tokenization, padding, vb.) uygulayabilirsiniz. Bu işlemleri düzenli ve yapılandırılmış bir şekilde yapmanıza olanak tanır.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fQIGWGp3y0hF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorSliceDataset'leri alın ve bunları önceden getirilmiş gruplara dönüştürün\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "bcLnSjss0B9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a758bcae-fc31-4da1-cf82-9c28a1d32b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, daha önce oluşturduğunuz **`train_dataset`, `valid_dataset`,** ve **`test_dataset`** veri kümelerine iki önemli işlem uygular: **batch'leme** ve **prefetching**. Bu işlemler, eğitim sürecini daha verimli hale getirmek ve sistem kaynaklarını optimize etmek için kullanılır.\n",
        "\n",
        "```python\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "1. **Batch'leme (`batch(32)`)**\n",
        "- **`batch(32)`**: Bu, veri kümesindeki verileri küçük gruplara (batch'lere) ayırır. Buradaki `32`, her batch'teki örnek sayısını belirtir. Yani, model her seferinde **32 örneği** (cümleyi, resimleri, vb.) aynı anda işler. Bu, eğitim sırasında işlem verimliliğini artırır ve aynı zamanda GPU'nun paralel işlem kapasitesinden daha fazla yararlanmanıza yardımcı olur.\n",
        "  \n",
        "  - **Batch'leme** avantajları:\n",
        "    - Eğitimde veri kümelerini daha küçük parçalara ayırarak belleği verimli kullanır.\n",
        "    - Modelin her bir batch için daha verimli bir şekilde optimizasyon yapmasını sağlar.\n",
        "    - Hesaplamalar üzerinde paralellik sağlanarak daha hızlı eğitim yapılmasını sağlar.\n",
        "\n",
        "  Örneğin, eğer veri kümeniz 1000 örnekten oluşuyorsa ve batch boyutunu 32 olarak belirlediyseniz, eğitim sürecinde model 1000 örneği işlemek yerine, 32'lik batch'ler halinde çalışacak ve toplamda 32 batch ile tüm veriyi işleyecektir.\n",
        "\n",
        "2. **Prefetching (`prefetch(tf.data.AUTOTUNE)`)**\n",
        "- **`prefetch(tf.data.AUTOTUNE)`**: Prefetching, verinin eğitim sırasında önceden yüklenmesini sağlayarak eğitim sürecinin hızlanmasına yardımcı olur. Bu, verilerin **GPU'nun veya işlemcinin** boşta olduğu zamanlarda yüklenmesini sağlar. Böylece model veriyi işlerken bir sonraki batch'in verileri, işlemci veya GPU tarafından işlenmeden önce yüklenmiş olur.\n",
        "\n",
        "  - **`AUTOTUNE`**: `AUTOTUNE`, TensorFlow'a, verinin ne kadar hızlı yüklenmesi gerektiğini **otomatik olarak** ayarlamasını söyleyen bir mekanizmadır. Bu, TensorFlow'un veriyi yüklerken ve işlerken en verimli yolu bulmasını sağlar.\n",
        "  \n",
        "  - **Prefetching** avantajları:\n",
        "    - Eğitim sırasında veri yükleme süresi minimize edilir.\n",
        "    - CPU ve GPU arasındaki boşluklar doldurulur ve paralel işlem yapılabilir, böylece eğitim hızlanır.\n",
        "    - Verinin eğitim sırasında daha hızlı ve verimli bir şekilde sunulmasını sağlar.\n",
        "\n",
        "---\n",
        "\n",
        "Neden Bunlar Kullanılıyor?\n",
        "\n",
        "1. **Veri Akışı ve Bellek Yönetimi**:\n",
        "   - Eğitim sırasında veri kümeleri genellikle çok büyük olabilir. `batch(32)` kullanmak, verileri küçük parçalara ayırarak belleği daha verimli kullanır. Ayrıca, her batch ile ayrı ayrı çalışmak, daha iyi eğitim sağlar.\n",
        "   - `prefetch(tf.data.AUTOTUNE)` ile, verinin yüklenmesi sırasında modelin eğitimi devam eder. Bu, **I/O (Input/Output) gecikmelerini** azaltarak eğitim sürecini hızlandırır.\n",
        "\n",
        "2. **Paralel İşlem**:\n",
        "   - Bu iki işlem, veriyi paralel olarak yükler ve işler, yani CPU ve GPU arasındaki etkileşim daha verimli hale gelir. GPU'nun işlediği veriler yüklenirken, CPU bir sonraki batch'i hazırlamaya devam eder. Bu paralellik, eğitim süresini önemli ölçüde kısaltabilir.\n",
        "\n",
        "### Örnek Senaryo:\n",
        "\n",
        "Eğer `train_dataset`'inizde 1000 örnek varsa ve batch boyutunu 32 olarak belirlediyseniz, aşağıdaki işlemler gerçekleşir:\n",
        "\n",
        "1. Model, ilk batch (32 örnek) ile eğitim yapmaya başlar.\n",
        "2. Aynı anda, **bir sonraki batch** (32 örnek) **GPU'nun boşta olduğu zamanlarda** CPU tarafından yüklenir.\n",
        "3. İlk batch işlemi tamamlandığında, model ikinci batch'e geçer ve aynı süreç devam eder.\n",
        "   \n",
        "Bu sayede **verinin hazırlanması** ile **modelin eğitilmesi** paralel hale gelir ve eğitim süreci daha hızlı ilerler."
      ],
      "metadata": {
        "id": "J6tgohcg0UYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.7. Kelime Düzeyinde Conv1D İle Modelleme ve Değerlendirme**"
      ],
      "metadata": {
        "id": "fqb4KprBj5FJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tüm derin modellerimiz benzer bir yapı izleyecektir:\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "\n",
        "Baştan sona değiştireceğimiz ana bileşen Katmanlar bileşenidir. Çünkü herhangi bir modern derin NLP modeli, içinde anlamlı kalıplar keşfedilmeden önce metnin bir gömmeye dönüştürülmesini gerektirir.\n",
        "\n",
        "İnşa edeceğimiz ilk model, 1 boyutlu bir Evrişimli Sinir Ağıdır."
      ],
      "metadata": {
        "id": "IZmzYQSf03g6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Dizileri işlemek için 1 boyutlu evrişimli model oluşturun\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\", activation = \"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x)  # özellik vektörümüzün çıktısını yoğunlaştırın\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model_1.compile(\n",
        "    loss = \"categorical_crossentropy\", # eğer etiketleriniz tamsayı biçimindeyse (tek bir sıcak değil) sparse_categorical_crossentropy kullanın\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Modelin uydurulması\n",
        "model_1_history = model_1.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch = int(0.1 * len(train_dataset)),  # daha hızlı eğitim süresi için partilerin yalnızca %10'una sığdır\n",
        "    epochs = 5,\n",
        "    validation_data = valid_dataset,\n",
        "    validation_steps = int(0.1 * len(valid_dataset))  # grupların yalnızca %10'unu doğrulayın\n",
        ")\n",
        "\n",
        "# Model özeti\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "YCjXH3pw3ACE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "f5365342-f437-4a1e-a8bc-8aa1140f069a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.5246 - loss: 1.1679 - val_accuracy: 0.7434 - val_loss: 0.6891\n",
            "Epoch 2/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7473 - loss: 0.6815 - val_accuracy: 0.7733 - val_loss: 0.6248\n",
            "Epoch 3/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.7705 - loss: 0.6218 - val_accuracy: 0.7886 - val_loss: 0.5906\n",
            "Epoch 4/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7861 - loss: 0.5952 - val_accuracy: 0.8022 - val_loss: 0.5655\n",
            "Epoch 5/5\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7905 - loss: 0.5868 - val_accuracy: 0.7955 - val_loss: 0.5651\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization_1                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_embedding (\u001b[38;5;33mEmbedding\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │       \u001b[38;5;34m8,299,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │          \u001b[38;5;34m41,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ text_vectorization_1                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,299,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling1d_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,022,993\u001b[0m (95.46 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,022,993</span> (95.46 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,340,997\u001b[0m (31.82 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,340,997</span> (31.82 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m16,681,996\u001b[0m (63.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,681,996</span> (63.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 30.2 s, sys: 1.99 s, total: 32.2 s\n",
            "Wall time: 42.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model özetini kontrol ederken, eğitilebilir parametrelerin çoğunun gömme katmanı içinde olduğunu fark edeceksiniz. Gömmenin boyutunu artıracak olsaydık (Gömme katmanının output_dim parametresini artırarak), eğitilebilir parametrelerin sayısı önemli ölçüde artardı.\n",
        "\n",
        "Eğitim verilerimiz yaklaşık 200.000 cümle içerdiğinden, bir GPU ile bile derin bir modele uyum biraz zaman alabilir. Bu nedenle, deneylerimizi hızlı tutmak için onları eğitim veri kümesinin bir alt kümesinde çalıştıracağız.\n",
        "\n",
        "Daha spesifik olarak, eğitilecek eğitim setinin yalnızca ilk %10'unu (yaklaşık 18.000 örnek) ve doğrulamak için doğrulama setindeki partilerin ilk %10'unu kullanacağız.\n",
        "\n",
        "🔑 Not: Modellerinizi daha büyük miktarda veriye ölçeklendirmeden önce çalıştıklarından emin olmak için önce daha küçük veri alt kümeleri üzerinde test etmek makine öğreniminde standart bir uygulamadır. Sadece bir avuç büyük deney yerine çok sayıda küçük deney yapmayı hedeflemelisiniz. Ve zamanınız sınırlı olduğundan, daha küçük deneyler yürütmenin en iyi yollarından biri, üzerinde çalıştığınız veri miktarını azaltmaktır (benzer bir dağılımı kapsadığı sürece, tam veri kümesinin %10'u genellikle iyi bir miktardır).\n",
        "\n",
        "- Veri kümesini zaten sığacak şekilde önceden biçimlendirmiştik.\n",
        "- Her dönem için adımların %10'unu atarız. Yani modelin partilerin yalnızca %10'una bakmasını istedik.\n",
        "- Hızlı yapmak için bunu yaptık. Sonuca bakıp hatanın nerede olduğunu anlamak için mümkün olduğunca baştan modeli kısa tuttuk. Denemeleri beş dk altında yapmaya çalıştık."
      ],
      "metadata": {
        "id": "XX2o4Q8I5dJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string)\n",
        "```\n",
        "\n",
        "- **`layers.Input()`**: Modelin giriş katmanını tanımlar.\n",
        "  - **`shape=(1,)`**: Giriş verisi bir **dizi** olacağı için, burada her örnek **tek bir metin dizisi** (string) olacaktır. Bu durumda her örnek, tek bir metin satırını (ya da cümleyi) temsil eder.\n",
        "  - **`dtype=tf.string`**: Giriş veri türü, metin verisi olduğu için `tf.string` olarak belirtilmiştir.\n",
        "\n",
        "Bu katman, modelin aldığı ilk veriyi tanımlar. Buradaki `shape=(1,)`, her giriş örneğinin **tek bir metin dizisi** olduğunu gösterir.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "text_vectors = text_vectorizer(inputs)\n",
        "```\n",
        "\n",
        "- **`text_vectorizer`**: Bu, muhtemelen metni sayısal bir formata dönüştüren bir katmandır. Örneğin, metni **token'lar** veya **kelime gömme vektörleri** (word embeddings) gibi sayısal verilere dönüştüren bir katman olabilir.\n",
        "  - Bu katman, metin verisini **vektörlere** dönüştürür. Eğer `text_vectorizer` bir `TextVectorization` katmanı ise, metni tokenize edip sabit boyutlu sayısal vektörlere dönüştürür.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "token_embeddings = token_embed(text_vectors)\n",
        "```\n",
        "\n",
        "- **`token_embed`**: Burada, **gömme (embedding)** katmanı kullanılarak, kelimeler ya da token'lar, sürekli (dense) vektörlere dönüştürülür.\n",
        "  - **`token_embed`** daha önce tanımladığınız gömme katmanıdır ve burada `text_vectors`'ı alır ve her token'ı sabit boyutlu bir vektöre dönüştürür (örneğin, 64 boyutlu).\n",
        "  \n",
        "---\n",
        "\n",
        "```python\n",
        "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\", activation = \"relu\")(token_embeddings)\n",
        "```\n",
        "\n",
        "- **`Conv1D`**: 1D evrişimsel (convolutional) katman, metin verisiyle çalışırken, kelime veya token sırasındaki ilişkileri öğrenmek için kullanılır.\n",
        "  - **`64`**: Çıkış (feature) sayısıdır. Bu, katmandan çıkan her bir **özellik haritası** (feature map) sayısını belirtir.\n",
        "  - **`kernel_size=5`**: Evrişim için kullanılan çekirdek (kernel) boyutudur. Burada 5, her bir evrişim işleminde 5 token'lık bir pencere boyutunu ifade eder.\n",
        "  - **`padding=\"same\"`**: Çıktı uzunluğunun giriş uzunluğuna eşit olmasını sağlar (yani giriş ve çıkış boyutları eşit olur). Bu, **sıfır dolgusu (zero padding)** ekler.\n",
        "  - **`activation=\"relu\"`**: Aktivasyon fonksiyonu olarak **ReLU** (Rectified Linear Unit) kullanılır. ReLU, evrişimsel katmandan sonra doğrusal olmayan bir aktivasyon sağlar.\n",
        "\n",
        "Bu katman, metin verisindeki özellikleri öğrenmeye çalışır. Her token (veya token dizisi) üzerinde kaydırılarak (sliding window) evrişim yapılır ve metnin önemli özelliklerini çıkarır.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "x = GlobalAveragePooling1D()(x)\n",
        "```\n",
        "\n",
        "- **`GlobalAveragePooling1D`**: Bu katman, **evrişimsel katman** çıktısını **yoğunlaştırarak** (sıkıştırarak) tek bir vektör haline getirir.\n",
        "  - 1D veride, her bir özellik haritasındaki tüm zaman adımlarının (token'lar) ortalamasını alır. Yani, evrişimsel katmandan çıkan her özellik haritası (feature map) üzerinde ortalama hesaplanır ve bu, her harita için bir değer verir.\n",
        "  - Bu işlem, modelin çıkışını daha küçük boyutlu bir **özellik vektörü** haline getirir, bu sayede modelin genel özelliklerini temsil eden bir vektör elde edilir.\n",
        "\n",
        "Global Average Pooling, **evrişimsel katmandan çıkan tüm özelliklerin** özetini alarak, modelin daha genel bir temsilini çıkarmaya yardımcı olur.\n",
        "\n",
        "---\n",
        "\n",
        "Tam Bağlantılı Katman:\n",
        "\n",
        "```python\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "```\n",
        "\n",
        "- **`Dense(num_classes, activation=\"softmax\")`**: Bu, son katmandır ve modelin **sınıflandırma** yapmasını sağlar.\n",
        "  - **`num_classes`**: Modelin tahmin edeceği sınıf sayısını belirtir. Örneğin, 3 sınıflı bir sınıflandırma problemi için `num_classes = 3`.\n",
        "  - **`activation=\"softmax\"`**: **Softmax aktivasyonu**, çok sınıflı sınıflandırma problemleri için yaygın olarak kullanılır. Çıktı, her sınıf için bir olasılık dağılımı döndürür ve tüm sınıfların olasılıkları 1'e eşit olur.\n",
        "\n",
        "Bu katman, modelin çıktısını oluşturur ve verilen giriş metni için hangi sınıfa ait olduğunu tahmin eder.\n",
        "\n",
        "---\n",
        "\n",
        "Modeli Tanımlama:\n",
        "\n",
        "```python\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "```\n",
        "\n",
        "- **`tf.keras.Model()`**: Keras API'sinde, `inputs` ve `outputs` parametreleriyle modelin son halini oluşturur. Bu, modelin **giriş** ve **çıkış** katmanlarını belirler ve modelin tamamlanmasını sağlar.\n",
        "\n",
        "Özetle:\n",
        "\n",
        "Bu kod, bir **1D evrişimli model** oluşturur ve metin verisini sınıflandırmak için kullanılır. Adım adım açıklanacak olursak:\n",
        "\n",
        "1. **Giriş katmanı**: Metin verisini (string) alır.\n",
        "2. **Metin vektörlemesi**: `text_vectorizer` kullanılarak metin, sayısal verilere dönüştürülür.\n",
        "3. **Gömme katmanı**: `token_embed` ile kelimeler veya token'lar gömme (embedding) vektörlerine dönüştürülür.\n",
        "4. **Evrişim katmanı**: `Conv1D` ile metin üzerindeki önemli özellikler öğrenilir.\n",
        "5. **Global Average Pooling**: Evrişimsel katmanın çıkışını sıkıştırarak bir özet vektör elde edilir.\n",
        "6. **Yoğun (Dense) katman**: Son olarak, `softmax` aktivasyonu kullanılarak sınıflandırma yapılır.\n",
        "\n",
        "Sonuç olarak, bu model **metin verilerini** sınıflandırmak amacıyla 1D evrişim kullanarak öğrenme yapar."
      ],
      "metadata": {
        "id": "IqOsN9VH6zdl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras'ta, modelleri oluşturmanın iki ana yolu vardır:\n",
        "\n",
        "1. **Dizisel API**: Bu, modelin katmanlarını sırayla ekleyerek inşa edilen, daha basit ve genellikle daha küçük modeller için uygundur. Bu model türü `Sequential()` sınıfı kullanılarak oluşturulur.\n",
        "   \n",
        "   Örnek:\n",
        "   ```python\n",
        "   model = tf.keras.Sequential([\n",
        "       layers.Input(shape=(1,), dtype=tf.string),\n",
        "       text_vectorizer,\n",
        "       token_embed,\n",
        "       layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\"),\n",
        "       layers.GlobalAveragePooling1D(),\n",
        "       layers.Dense(num_classes, activation=\"softmax\")\n",
        "   ])\n",
        "   ```\n",
        "\n",
        "2. **Fonksiyonel API**: Daha karmaşık, esnek ve modüler modeller oluşturmak için kullanılır. Katmanlar, girdi ve çıktı bağlantıları arasında doğrudan bağlantılar kurularak model tanımlanır. Fonksiyonel API ile daha karmaşık yapıdaki ağlar, paylaşılan katmanlar, çok girişli ve çok çıkışlı ağlar ve daha fazlası tasarlanabilir.\n",
        "\n",
        "Bu kodda **Fonksiyonel API** kullanılmış çünkü modelde daha esnek bir yapı tercih edilmiştir. Birden fazla girdi, çıktı, dallanma veya katman paylaşımı gibi işlemler yapılabilir. Ancak, burada sadece bir girdi ve bir çıktı olsa da, Fonksiyonel API daha modüler bir tasarım sağlar.\n",
        "\n",
        "**Fonksiyonel API'nin Temel Özellikleri**:\n",
        "- Girdi ve çıktı katmanları açıkça tanımlanır.\n",
        "- Katmanlar doğrudan birbirine bağlanır.\n",
        "- Katmanlar arasında dallanma yapılabilir (örneğin, bir girdi birden fazla katmana yönlendirilebilir veya bir katman birden fazla çıktı verebilir).\n",
        "- Modelin yapısı daha esnektir ve genellikle karmaşık mimariler için kullanılır.\n",
        "\n",
        "**Birinci x Katmanında Hangi Değişkenler Eklenebilirdi?**\n",
        "\n",
        "İlk **`x`** katmanı şu şekilde tanımlanmış:\n",
        "\n",
        "```python\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "```\n",
        "\n",
        "İlk `Conv1D` katmanında eklenebilecek bazı değişkenler şunlar olabilir:\n",
        "\n",
        "- **`filters`**: Bu parametre, çıkış kanal sayısını belirtir. Yani, kaç tane konvolüsyonel filtre uygulanacağı. Burada `64` olarak verilmiş, ancak bu sayı arttırılabilir veya azaltılabilir. Örneğin, daha büyük bir modelde `128` veya `256` gibi değerler kullanılabilir.\n",
        "  \n",
        "- **`kernel_size`**: Konvolüsyonel filtrelerin boyutunu belirtir. Burada `5` olarak belirlenmiş, ancak daha büyük veya küçük bir kernel (`3`, `7`, `9`, vb.) seçilebilir. Kernel boyutunun büyüklüğü, modelin nasıl öğrenme yapacağını etkiler.\n",
        "\n",
        "- **`strides`**: Konvolüsyon işleminin adım boyutudur. Varsayılan olarak `1`'dir, ancak daha büyük bir değer (örneğin `2`) kullanarak daha büyük adımlarla özelliklerin çıkarılması sağlanabilir.\n",
        "\n",
        "- **`dilation_rate`**: Konvolüsyon filtresinin genişliği. Bu parametre, filtrelerin girdi üzerinde ne kadar geniş bir aralığa yayıldığını belirler. Eğer dilasyon kullanılırsa, daha geniş aralıklar üzerinden özellik çıkarımı yapılabilir.\n",
        "\n",
        "- **`activation`**: Burada `relu` aktivasyon fonksiyonu kullanılmış. Fakat başka aktivasyon fonksiyonları da kullanılabilir: `tanh`, `sigmoid`, `leaky_relu` vb.\n",
        "\n",
        "- **`use_bias`**: Bu parametre, konvolüsyonel katmanda bias (önyargı) terimi kullanılıp kullanılmayacağını belirler. Varsayılan olarak `True` olarak gelir, ancak `False` yapılabilir.\n",
        "\n",
        "- **`kernel_initializer` ve `bias_initializer`**: Katmanın ağırlıklarının ve bias terimlerinin başlangıç değerlerini belirleyebilirsiniz. Örneğin, `kernel_initializer='he_normal'` gibi.\n",
        "\n",
        "- **`trainable`**: Katmanın eğitilebilir olup olmadığına karar veririz. Burada varsayılan olarak tüm katmanlar eğitilebilir, ancak `trainable=False` yaparak bir katmanın eğitim sırasında güncellenmesini engelleyebilirsiniz.\n",
        "\n",
        "Örneğin:\n",
        "```python\n",
        "x = layers.Conv1D(\n",
        "    filters=128,\n",
        "    kernel_size=3,\n",
        "    padding=\"same\",\n",
        "    activation=\"relu\",\n",
        "    strides=1,\n",
        "    dilation_rate=1,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='he_normal'\n",
        ")(token_embeddings)\n",
        "```"
      ],
      "metadata": {
        "id": "3Ueihj11CdTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doğrulama veri kümesinin tamamını değerlendirin (eğitim sırasında grupların yalnızca %10'unu doğruladık)\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "sjfkts8A5zf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c54192-0107-4037-f423-bed704004d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8012 - loss: 0.5583\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5608068704605103, 0.800973117351532]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminlerde bulunun (modelimiz her sınıf için tahmin olasılıklarının çıktısını verir)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs[:10]\n",
        "\n",
        "# 5 çıkış nöronlu çıkış katmanını olduğuna dikkat!"
      ],
      "metadata": {
        "id": "8rTphKEQ5zZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e88a23e-85b1-4c29-fb4a-bb873f54a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.3424037e-01, 1.6922709e-01, 4.2627126e-02, 1.9663626e-01,\n",
              "        5.7269096e-02],\n",
              "       [4.1625068e-01, 3.8065371e-01, 2.2781698e-02, 1.4178574e-01,\n",
              "        3.8528230e-02],\n",
              "       [1.6555984e-01, 5.2355202e-03, 1.7712441e-03, 8.2736790e-01,\n",
              "        6.5479027e-05],\n",
              "       [3.3826491e-05, 1.9337595e-04, 9.9888712e-01, 8.3502484e-05,\n",
              "        8.0219854e-04],\n",
              "       [7.5173406e-03, 1.0930215e-01, 5.1702136e-01, 4.9837832e-03,\n",
              "        3.6117539e-01],\n",
              "       [1.6721189e-02, 2.0874046e-02, 6.7839271e-01, 7.6261815e-03,\n",
              "        2.7638587e-01],\n",
              "       [1.1944027e-03, 3.2180697e-03, 6.3765353e-01, 7.2400115e-04,\n",
              "        3.5720989e-01],\n",
              "       [4.7482975e-02, 4.4579227e-02, 5.4065734e-01, 2.0480020e-02,\n",
              "        3.4680042e-01],\n",
              "       [2.4076807e-10, 9.4810110e-07, 1.6741293e-06, 7.8157598e-11,\n",
              "        9.9999738e-01],\n",
              "       [1.0809563e-02, 7.8868288e-01, 8.0670901e-02, 3.5253469e-02,\n",
              "        8.4583230e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pred problarını sınıflara dönüştürün\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis = 1)\n",
        "model_1_preds[:10] # her bir dizideki maks. değeri verir"
      ],
      "metadata": {
        "id": "UM8d1V5R5zTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84f003e-77eb-49ca-856b-c757e0a4131e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 3, 2, 2, 2, 2, 2, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`tf.argmax()` fonksiyonu, TensorFlow'da, verilen tensördeki en büyük değeri bulur ve bu değerin **indeksini** döndürür. Bu, genellikle modelin tahminlerinde kullanılan ve **sınıflandırma** problemlerinde kullanılan bir fonksiyondur.\n",
        "\n",
        "1. **`model_1_pred_probs`**:\n",
        "   - Bu, modelin sınıflandırma tahminlerinin olasılıklarını içeren bir tensördür. Model, **softmax aktivasyonu** ile her sınıf için bir olasılık dağılımı döndürür. Örneğin, 3 sınıflı bir sınıflandırma problemi için modelin çıktısı şu şekilde olabilir:\n",
        "     ```python\n",
        "     model_1_pred_probs = [[0.1, 0.7, 0.2],\n",
        "                           [0.4, 0.4, 0.2],\n",
        "                           [0.9, 0.05, 0.05]]\n",
        "     ```\n",
        "     Burada, her satır bir örneğin (örneğin bir metnin) olasılık dağılımını temsil eder ve her sütun bir sınıfın olasılığını gösterir.\n",
        "\n",
        "2. **`tf.argmax(model_1_pred_probs, axis=1)`**:\n",
        "   - **`tf.argmax()`** fonksiyonu, her satırdaki **en yüksek olasılığı** (veya değeri) bulur ve bu değerin **indeksini** döndürür.\n",
        "   - **`axis=1`**: Bu, `tf.argmax()` fonksiyonunun her satırdaki en büyük değeri bulmasını sağlar. Yani, **her örnek için** (her satır) en yüksek olasılığa sahip sınıfın indeksini seçer.\n",
        "     - **`axis=0`** olsaydı, `tf.argmax()` her sütun için en yüksek değeri seçerdi, yani tüm örnekler için her bir sınıfın en yüksek olasılığını bulurdu. Ancak burada `axis=1` kullanıldığı için **her örnek** için (yani her satırda) en yüksek olasılığı buluruz.\n",
        "\n",
        "### Örnek:\n",
        "\n",
        "Diyelim ki, modelinizin çıktısı şu şekilde:\n",
        "\n",
        "```python\n",
        "model_1_pred_probs = [[0.1, 0.7, 0.2],  # 1. örnek için sınıf olasılıkları\n",
        "                       [0.4, 0.4, 0.2],  # 2. örnek için sınıf olasılıkları\n",
        "                       [0.9, 0.05, 0.05]]  # 3. örnek için sınıf olasılıkları\n",
        "```\n",
        "\n",
        "Burada:\n",
        "- 1. örneğin olasılıkları `[0.1, 0.7, 0.2]`. En yüksek olasılık **0.7** ile **2. sınıf**.\n",
        "- 2. örneğin olasılıkları `[0.4, 0.4, 0.2]`. Burada en yüksek olasılık **0.4** ile 1. veya 2. sınıf. Ancak, `tf.argmax()` ilk bulduğu en büyük değeri alacağı için **1. sınıf** dönecektir.\n",
        "- 3. örneğin olasılıkları `[0.9, 0.05, 0.05]`. En yüksek olasılık **0.9** ile **1. sınıf**.\n",
        "\n",
        "Sonuç olarak:\n",
        "\n",
        "```python\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "```\n",
        "\n",
        "**`model_1_preds`** şu şekilde olacaktır:\n",
        "\n",
        "```python\n",
        "model_1_preds = [1, 0, 0]\n",
        "```\n",
        "\n",
        "Bu, modelin her bir örnek için tahmin ettiği sınıf indeksleridir:\n",
        "- 1. örnek için **2. sınıf** (indeks 1),\n",
        "- 2. örnek için **1. sınıf** (indeks 0),\n",
        "- 3. örnek için **1. sınıf** (indeks 0)."
      ],
      "metadata": {
        "id": "K8ggCgzg7nj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_1 sonuçlarını hesapla\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "id": "tR2ZzxEh5zOg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "424a83d9-3d5f-40fe-ccbe-97f404d30303",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-10fbecc56d17>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model_1 sonuçlarını hesapla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_1_results = calculate_results(y_true=val_labels_encoded,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                     y_pred=model_1_preds)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_1_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \"\"\"\n\u001b[1;32m    280\u001b[0m   \u001b[0;31m# Calculate model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m   \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;31m# Calculate model precision, recall and f1 score using \"weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mmodel_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mget_namespace_and_device\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0marrays_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mdevice_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_array_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdevice_other\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;34mf\"Input arrays use different devices: {str(device_)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;34mf\"{str(device_other)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.8. Tensorflow Hub İle Modelleme ve Değerlendirme**"
      ],
      "metadata": {
        "id": "ye8SznEVj5DE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tıbbi Kağıt Özetlerinde Ortak Cümle Sınıflandırması için Sinir Ağlarındaki model mimarisini çoğaltmaya doğru ilerlediğimiz için, belirteç gömmelerini başlatmanın bir yolu olarak önceden eğitilmiş bir GloVe gömme kullandıklarından bahseder.\n",
        "* https://arxiv.org/pdf/1612.05251\n",
        "* https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Bunu taklit etmek için, TensorFlow Hub'dan önceden eğitilmiş Evrensel Cümle Kodlayıcı gömmeleriyle hangi sonuçları alabileceğimizi görelim. https://www.kaggle.com/models/google/universal-sentence-encoder/tensorFlow2/universal-sentence-encoder/2?tfhub-redirect=true\n",
        "\n",
        "🔑 Not: GloVe gömmelerini kağıda göre kullanabiliriz, ancak TensorFlow ile çalıştığımız için TensorFlow Hub'da bulunanları kullanacağız (GloVe gömmeleri değil). Önceden eğitilmiş GloVe gömmelerini uzantı olarak kullanarak tasarruf edeceğiz. https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "\n",
        "Model yapısı şöyle görünecektir:\n",
        "\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "\n",
        "Önceki bir modelde kullandığımız tokenizasyon katmanının eksikliğini fark edeceksiniz. Bunun nedeni, Evrensel Cümle Kodlayıcısının (USE) bizim için tokenizasyonla ilgilenmesidir.\n",
        "\n",
        "Bu tür bir modele transfer öğrenimi veya daha spesifik olarak özellik çıkarma transfer öğrenimi denir. Başka bir deyişle, bir modelin başka bir yerde öğrendiği kalıpları almak ve bunu kendi sorunumuza uygulamak.\n",
        "\n",
        "TensorFlow Hub'dan önceden eğitilmiş bir gömme kullanarak oluşturduğumuz özellik çıkarıcı modeli.\n",
        "\n",
        "Önceden eğitilmiş USE'ı modelimizde kullanabileceğimiz bir katmana indirmek için hub.KerasLayer sınıfını kullanabiliriz.\n",
        "\n",
        "Önceden eğitilmiş gömmeleri donmuş tutacağız (eğitilebilir=Yanlış ayarlayarak) ve model çıktılarını kendi verilerimize göre uyarlamak için üste eğitilebilir birkaç katman ekleyeceğiz.\n",
        "\n",
        "🔑 Not: Nispeten büyük bir modeli (~916MB) indirmek zorunda kaldığından, aşağıdaki hücrenin çalışması biraz zaman alabilir. https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer"
      ],
      "metadata": {
        "id": "5jOVZBqm9Lga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Önceden eğitilmiş TensorFlow Hub'ı indirin KULLANIM\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "id": "_Sc2k-Pv-aNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rastgele cümlelerde gömmeyi test etme\n",
        "\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Rastgele eğitim cümlesi:\\n{random_training_sentence}\\n\")\n",
        "\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Gömme sonrası cümle:\\n{use_embedded_sentence[0][:30]} (kesilmiş çıktı)...\\n\")\n",
        "print(f\"Gömülmüş cümlenin uzunluğu:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "id": "HyKY8GNL-aKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44e8723c-b76e-4e73-bce4-ea928df65849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rastgele eğitim cümlesi:\n",
            "we evaluated angiogenesis-targeted sunitinib therapy in a randomized , double-blind trial of metastatic castration-resistant prostate cancer ( mcrpc ) .\n",
            "\n",
            "Gömme sonrası cümle:\n",
            "[-0.0332844   0.00323283 -0.07341916 -0.04258213 -0.04985864 -0.07613482\n",
            " -0.02224037 -0.04262499  0.03884448 -0.01723633  0.0887475  -0.06006488\n",
            "  0.01688014  0.08200955  0.05170288 -0.04839861 -0.08894092  0.05455948\n",
            "  0.04898502  0.00801988 -0.03343721  0.00720054 -0.03504387 -0.00383746\n",
            "  0.06791933 -0.03750411  0.02844876  0.00618231  0.05129638  0.06099223] (kesilmiş çıktı)...\n",
            "\n",
            "Gömülmüş cümlenin uzunluğu:\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daha önce de belirttiğimiz gibi, TensorFlow Hub'ın önceden eğitilmiş USE modülü, metnimizi bizim için belirteçlemeye özen gösterir ve 512 boyutlu bir gömme vektörü çıkarır."
      ],
      "metadata": {
        "id": "TzkJ03j3--BO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensorflow Hub'dan bir NLP özellik çıkarma modeli kullanımı**\n",
        "- Girişler katman şeklinde çünkü giriş şekli boş bir liste. Simgeleştirilmiş bir yerleştirme katmanı oluşturduğumuzda, simge düzeyinde bir yerleştirme var ve her token 128'e çevirdik. Bu da tüm diziyi tek uzun vektöre dönüştürdü.\n",
        "- relu --> Lineer olmayan aktivasyon ...\n",
        "- Modeli iyileştirme yollarından birisi de araya katman koymaktır. Girdilerden gömme oluşturulabilir. Gömme arasına bir grup katman eklenebilir.\n",
        "- Deney yaptığımız için bu çalışmada büyük bir katman oluşturmadık. Karmaşıklık her zaman arttırılabilir.\n",
        "- Eğitilebilir parametreler yoğun katmandadır. Eğitilebiliri açarsan modelin daha çok kalıp bulması gerektiği anlamına gelir.\n",
        "- Özellik çıkarmada katman sayısı arttıkça deney uzun sürer. Tüm parametreler dondurulmuş olduğu için hızlı eğitim oldu.\n"
      ],
      "metadata": {
        "id": "EOJkymuo_DJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")\n",
        "\n",
        "# Define the custom layer for the Universal Sentence Encoder\n",
        "class UniversalSentenceEncoderLayer(layers.Layer):\n",
        "    def __init__(self, hub_layer):\n",
        "        super().__init__()\n",
        "        self.encoder = hub_layer\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.encoder(inputs)\n",
        "\n",
        "use_layer = UniversalSentenceEncoderLayer(tf_hub_embedding_layer)\n",
        "\n",
        "# Create the model\n",
        "inputs = layers.Input(shape=(), dtype=tf.string)\n",
        "pretrained_embedding = use_layer(inputs)\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_USE_feature_extractor\")\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model_2.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Summary of the model\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "ywHdAJV3doAG",
        "outputId": "4533cb3d-b362-489b-9dd0-2f063dc36143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_2_USE_feature_extractor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2_USE_feature_extractor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m)                      │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ universal_sentence_encoder_layer_2   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mUniversalSentenceEncoderLayer\u001b[0m)      │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                      │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ universal_sentence_encoder_layer_2   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UniversalSentenceEncoderLayer</span>)      │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m66,309\u001b[0m (259.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,309</span> (259.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m66,309\u001b[0m (259.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">66,309</span> (259.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Özellik çıkarıcı modelini 3 dönem için uygun hale getirin\n",
        "model_2.fit(\n",
        "    train_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=valid_dataset,\n",
        "    validation_steps=int(0.1 * len(valid_dataset))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SydjPxThi8V9",
        "outputId": "e2ecf9cb-fc41-4ae9-bd81-ac81a88cfa5c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_49214[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-91-1a024b239fec>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_49214[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_49615]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-1a024b239fec>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Özellik çıkarıcı modelini 3 dönem için uygun hale getirin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_2.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_49214[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-91-1a024b239fec>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_49214[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_49615]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin özetini kontrol ederek çok sayıda toplam parametre olduğunu görebiliriz, ancak bunların çoğu eğitilemez. Bunun nedeni, USE özellik çıkarıcı katmanımızı yerleştirdiğimizde training=False'i ayarlamamızdır.\n",
        "\n",
        "Bu nedenle, modelimizi eğittiğimizde, yalnızca en iyi iki çıkış katmanı eğitilecektir."
      ],
      "metadata": {
        "id": "vaLEK50lBShK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doğrulama veri kümesinin tamamını değerlendirin\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "metadata": {
        "id": "-cBt8TNc_gRj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "outputId": "896f7c45-ba49-44fb-8468-13511e4fa1ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_50115[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-92-80b67b28824a>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 433, in evaluate\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_50115[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_50496]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-80b67b28824a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Doğrulama veri kümesinin tamamını değerlendirin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected at node data defined at (most recent call last):\n<stack traces unavailable>\nDetected unsupported operations when trying to compile graph __inference_one_step_on_data_50115[] on XLA_GPU_JIT: _Arg (No registered '_Arg' OpKernel for XLA_GPU_JIT devices compatible with node {{node data}}\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_STRING, _output_shapes=[[32]], _user_specified_name=\"data\", index=0){{node data}}\nThe op is created at: \nFile \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\nFile \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\nFile \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\nFile \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\nFile \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\nFile \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\nFile \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\nFile \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\nFile \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\nFile \"<ipython-input-92-80b67b28824a>\", line 2, in <cell line: 2>\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 433, in evaluate\nFile \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 165, in one_step_on_iterator\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\", line 356, in placeholder_arguments\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 250, in placeholder_value\nFile \"/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/trace_type/default_types.py\", line 251, in <listcomp>\n\ttf2xla conversion failed while converting __inference_one_step_on_data_50115[]. Run with TF_DUMP_GRAPH_PREFIX=/path/to/dump/dir and --vmodule=xla_compiler=2 to obtain a dump of the compiled functions.\n\t [[StatefulPartitionedCall]] [Op:__inference_one_step_on_iterator_50496]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Özellik çıkarma modeliyle tahminler yapın\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs[:10]"
      ],
      "metadata": {
        "id": "oV575nLT_gOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Özellik çıkarma modeliyle tahminleri sınıflara dönüştürün\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis = 1)\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "id": "VpvF9Oig_gHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Doğrulama kümesindeki TF Hub önceden eğitilmiş yerleştirme sonuçlarından sonuçları hesaplayın\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "id": "NgG6ck4b_f48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.9. Karakter Düzeyinde Conv1D İle Modelleme ve Değerlendirme**"
      ],
      "metadata": {
        "id": "vLOtWFSJj5Ax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medical Paper Abstracts makalesinde Ortak Cümle Sınıflandırması için Sinir Ağları, modellerinin belirteç ve karakter gömmelerinin bir karışımını kullandığından bahseder. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "Özel bir belirteç gömme ve önceden eğitilmiş bir belirteç gömme ile modeller oluşturduk, bir karakter gömme kullanarak bir tane oluşturmaya ne dersiniz?\n",
        "\n",
        "Bir karakter ve belirteç gömme arasındaki fark, karakter gömmenin karakterlere bölünmüş diziler kullanılarak oluşturulmasıdır (örneğin, merhaba -> [h, e, l, l, o]), burada bir belirteç gömme, belirteçlere bölünmüş diziler üzerinde oluşturulur.\n",
        "\n",
        "Belirteç seviyesi, dizileri belirteçlere (kelimelere) böler ve her birini gömer, karakter gömer, dizileri karakterlere böler ve her biri için bir özellik vektörü oluşturur.\n",
        "\n",
        "TextVectorization sınıfını kullanarak önce dizilerimizi (karakterlere ayrıldıktan sonra) vektörleştirerek ve ardından bu vektörleştirilmiş dizileri bir Gömme katmanından geçirerek karakter düzeyinde bir gömme oluşturabiliriz.\n",
        "\n",
        "Dizilerimizi bir karakter düzeyinde vektörleştirmeden önce onları karakterlere ayırmamız gerekecek. Bunu yapmak için bir işlev yazalım.\n",
        "\n",
        "- belirteç = token...\n",
        "- karakter embedding --> her bir hard feature vector'e dönüşür.\n",
        "- **Yukarıda oluşturduğumuz vektörler kelime içindi. Bu çalışma için verileri karakter olarakbiçimlendirme gerekli.**\n",
        "- Her karakteri, harfi bir tam sayıya dönüştürür."
      ],
      "metadata": {
        "id": "okrK5qhkCwbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cümleleri karakterlere bölme işlevi yapın\n",
        "def split_chars(text):\n",
        "  return\" \".join(list(text))\n",
        "\n",
        "# Karakter düzeyinde olmayan diziyi karakterlere bölmeyi test edin\n",
        "split_chars(random_training_sentence)"
      ],
      "metadata": {
        "id": "NHHfexcbDTtw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "4c481759-7180-45be-e777-e6c54784269a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'r e s u l t s   w e r e   r o b u s t   t o   e x t e n s i v e   s e n s i t i v i t y   a n a l y s e s   ,   i n c l u d i n g   v a r i a t i o n s   i n   c l o p i d o g r e l   c o s t   ,   e x c l u s i o n   o f   c o s t s   i n   e x t e n d e d   y e a r s   o f   l i f e   ,   a n d   a   r e c a l i b r a t e d   e s t i m a t e   o f   s u r v i v a l   r e f l e c t i n g   a   l o w e r   u n d e r l y i n g   m o r t a l i t y   r i s k   i n   t h e   u n i t e d   s t a t e s   .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sıra düzeyindeki verileri karakter düzeyindeki veri bölmelerine bölme\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "metadata": {
        "id": "ubehHG1BDTq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3d6524-222c-408c-e02c-5f210fe3bf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ortalama karakter uzunluğu nedir?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "id": "XK66ddldDTlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "771f17c8-29a0-43c2-d6c5-f9d4060b3f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dizilerimizin karakter düzeyinde dağılımını kontrol edin\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "metadata": {
        "id": "ctl0cUqUDTjE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "46074bab-fd86-4a99-f544-46519281247e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hangi karakter uzunluğunun dizilerin %95'ini kapsadığını bulun\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "id": "rBNo-3h2DTgp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f497a4a-95d3-48ab-c27f-c554076cc669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Böylece dizilerin %95'ini kapsayan dizi uzunluğunu biliyoruz, bunu TextVectorization katmanımızda output_sequence_length parametresi olarak kullanacağız.\n",
        "\n",
        "🔑 Not: En uygun output_sequence_length'in ne olması gerektiğini bulmak için burada deney yapabilirsiniz, belki de ortalama sonuçları %95 yüzdelik dilim kullanmak kadar iyi sonuçlar elde edebilirsiniz.\n",
        "\n",
        "Max_tokens'i (dizilerimizdeki farklı karakterlerin toplam sayısı) 28, başka bir deyişle, alfabenin 26 harfi + boşluk + OOV (kelime dağarcığı dışında veya bilinmeyen) belirteçleri olarak ayarlayacağız."
      ],
      "metadata": {
        "id": "Gj_nX7_w1JHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter düzeyinde yerleştirme için tüm klavye karakterlerini alın\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet\n",
        "\n",
        "# ascii --> tüm küçük harfleri kullanmak için"
      ],
      "metadata": {
        "id": "hCtaNLf1DTbz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bce5502f-475b-4281-e774-e516cf241e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `string.ascii_lowercase`: Küçük harflerden oluşan bir sabit (a'dan z'ye kadar olan harfler).\n",
        "  \n",
        "- `string.digits`: Sayılardan oluşan bir sabit (0'dan 9'a kadar olan rakamlar).\n",
        "  \n",
        "- `string.punctuation`: Tüm yaygın noktalama işaretlerini içeren bir sabit (örn. `!\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~`).\n",
        "\n",
        "Bu üç sabitin birleşimi, küçük harfler, rakamlar ve noktalama işaretlerinin birleştirilmesinden oluşan **alfabe**yi oluşturur."
      ],
      "metadata": {
        "id": "mNV1LItTFg2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter düzeyinde belirteç vektörleştirici örneği oluşturun\n",
        "\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 #alfabedeki karakter sayısı + boşluk + OOV belirteci\n",
        "\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Karakter vektörleştiricisini eğitim karakterlerine uyarlayın\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "id": "ALCNGOABzUHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "standardizasyon None olsaydı, çıktı;\n",
        "\n",
        "- 57\n",
        "- '', [UNK], 'e', 't', 'i'\n",
        "- 'I', '\"', ']', '//', ...olurdu.\n",
        "\n",
        "Yani none ile noktalama işaretlerini terketmiş olursunuz.\n",
        "\n",
        "`standardize` parametresi, `TextVectorization` katmanının nasıl bir **ön işleme** yapacağına karar verir. Bu parametre, metni modelin girişine uygun hale getirmeden önce uygulanan işlemleri kontrol eder.\n",
        "\n",
        "`TextVectorization` katmanı, metin verisini bir sayısal temsile dönüştürmeden önce bazı metin ön işleme adımları uygular. Bu işlem, metnin formatını ve biçimini standart hale getirmeye yardımcı olur. `standardize` parametresi, bu ön işleme işleminin nasıl yapılacağını belirler.\n",
        "\n",
        "**Kullanılabilecek `standardize` seçenekleri:**\n",
        "\n",
        "1. **`\"lower_and_strip_punctuation\"`**:\n",
        "   - Bu seçenek, metni **küçük harfe** dönüştürür ve **noktalama işaretlerini** temizler. Yani, metni küçük harflerle yazacak ve noktalama işaretlerini kaldıracaktır.\n",
        "   \n",
        "   Örneğin:\n",
        "   ```python\n",
        "   \"Merhaba, dünya!\" -> \"merhaba dunya\"\n",
        "   ```\n",
        "\n",
        "2. **`\"lower\"`**:\n",
        "   - Sadece metni **küçük harfe** dönüştürür.\n",
        "   \n",
        "   Örneğin:\n",
        "   ```python\n",
        "   \"Merhaba, dünya!\" -> \"merhaba, dünya!\"\n",
        "   ```\n",
        "\n",
        "3. **`\"strip_punctuation\"`**:\n",
        "   - Yalnızca **noktalama işaretlerini kaldırır**, ama büyük/küçük harf farkını korur.\n",
        "   \n",
        "   Örneğin:\n",
        "   ```python\n",
        "   \"Merhaba, dünya!\" -> \"Merhaba dünya\"\n",
        "   ```\n",
        "\n",
        "4. **`None` (Varsayılan)**:\n",
        "   - Hiçbir standartlaştırma yapılmaz. Yani, metin olduğu gibi kalır.\n",
        "   \n",
        "   Örneğin:\n",
        "   ```python\n",
        "   \"Merhaba, dünya!\" -> \"Merhaba, dünya!\"\n",
        "   ```\n",
        "\n",
        "5. **Özel Fonksiyon**:\n",
        "   - Kendi özel standardizasyon fonksiyonunuzu yazabilirsiniz. Örneğin, belirli kelimeleri değiştirmek veya bazı karakterleri silmek gibi.\n",
        "\n",
        "`char_vectorizer.adapt(train_chars)`\n",
        "\n",
        "Son olarak, `char_vectorizer.adapt(train_chars)` satırı, `train_chars` adlı eğitim verisi üzerinde bu vektörleştiriciyi **uyarlamak** için kullanılır. Bu işlem sırasında, `train_chars` verisindeki karakterler gözlemlenir ve model, her karakterin sayısal bir temsilini oluşturmak için uygun parametreleri öğrenir."
      ],
      "metadata": {
        "id": "JkHlH_262aoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter sözlüğü özelliklerini kontrol edin\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Karakter sözlüğündeki farklı karakterlerin sayısı: {len(char_vocab)}\")\n",
        "print(f\"En yaygın 5 karakter: {char_vocab[:5]}\")\n",
        "print(f\"En az yaygın olan 5 karakter: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "id": "3_skzRjfzb5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86569f5-037a-4e3c-a21b-92cffd3d8583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Karakter sözlüğündeki farklı karakterlerin sayısı: 28\n",
            "En yaygın 5 karakter: ['', '[UNK]', 'e', 't', 'i']\n",
            "En az yaygın olan 5 karakter: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter vektörleştiricisini test edin\n",
        "\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "id": "gnG-A9Fzzb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e0809b5-3e0c-421b-848a-fbb3ff11fdc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            "b e f o r e   t r e a t m e n t   ,   t h e r e   w a s   n o   s i g n i f i c a n t   d i f f e r e n c e   b e t w e e n   t w o   g r o u p s   i n   e a c h   i n d e x   (   p   >   @   )   .\n",
            "\n",
            "Length of chars: 80\n",
            "\n",
            "Vectorized chars:\n",
            "[[22  2 17  7  8  2  3  8  2  5  3 15  2  6  3  3 13  2  8  2 20  5  9  6\n",
            "   7  9  4 18  6  4 17  4 11  5  6  3 10  4 17 17  2  8  2  6 11  2 22  2\n",
            "   3 20  2  2  6  3 20  7 18  8  7 16 14  9  4  6  2  5 11 13  4  6 10  2\n",
            "  24 14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uzunluğu 290'dan (output_seq_char_length) daha kısa olan dizilerin sonunda sıfırlarla doldurulduğunu fark edeceksiniz, bu da modelimize geçirilen tüm dizilerin aynı uzunlukta olmasını sağlar.\n",
        "\n",
        "Ayrıca, TextVectorization'ın standartlaştırma parametresinin \"lower_and_strip_punctuation\" ve bölünmüş parametrenin varsayılan olarak \"whitespace\" olması nedeniyle, semboller (@ gibi) ve boşluklar kaldırılır.\n",
        "\n",
        "🔑 Not: Noktalama işaretlerinin kaldırılmasını istemediyseniz (@, % vb. tutun), özel bir standardizasyon çağrılabilir oluşturabilir ve bunu standartlaştırma parametresi olarak geçirebilirsiniz. Daha fazla bilgi için TextVectorization katmanı belgelerine bakın."
      ],
      "metadata": {
        "id": "egnMTV7E3zRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Karakter düzeyinde bir gömme oluşturma**\n",
        "\n",
        "Karakter düzeyindeki dizilerimizi vektörleştirmenin bir yolu var, şimdi bir karakter düzeyinde gömme oluşturma zamanı.\n",
        "\n",
        "Tıpkı özel belirteç gömmemiz gibi, bunu tensorflow.keras.layers.Embedding sınıfını kullanarak yapabiliriz. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "Karakter düzeyinde gömme katmanımız bir giriş boyutu ve çıkış boyutu gerektirir.\n",
        "\n",
        "Giriş boyutu (input_dim), char_vocab'ımızdaki (28) farklı karakterlerin sayısına eşit olacaktır. Ve Tıbbi Kağıt Özetlerinde Ortak Cümle Sınıflandırması için Sinir Ağları Şekil 1'deki modelin yapısını takip ettiğimizden, karakter gömmenin (output_dim) çıktı boyutu 25 olacaktır. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "dokümanda, input_dim --> int. Kelime haznesidir. Örneğin max tamsayı indexi +1 gibi.\n",
        "\n",
        "output_dim --> int. Yoğun gömmenin şekilsel boyutu."
      ],
      "metadata": {
        "id": "BmIAWK9f313t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakter gömmesi katmanı oluştur\n",
        "char_embed = layers.Embedding(\n",
        "    input_dim = NUM_CHAR_TOKENS,  # farklı karakter sayısı\n",
        "    output_dim = 25,              # her karakterin yerleştirme boyutu (Figure 1 ile aynı https://arxiv.org/pdf/1612.05251.pdf)\n",
        "    mask_zero = True,             # maske kullanmayın (True olarak ayarlanırsa bu model_5'i bozar)\n",
        "    name = \"char_embedding\"\n",
        ")\n",
        "\n",
        "# Karakter yerleştirme katmanını test edin\n",
        "print(f\"Charified metin (vektörleştirme ve yerleştirmeden önce):\\n{random_train_chars}\\n\")\n",
        "\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "\n",
        "print(f\"Gömülü karakterler (vektörleştirme ve yerleştirmeden sonra):\\n{char_embed_example}\\n\")\n",
        "\n",
        "print(f\"Karakter yerleştirme şekli: {char_embed_example.shape}\")"
      ],
      "metadata": {
        "id": "nPSTWmFNzb0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeee8d06-0614-4606-bb96-cdd0ae8e71c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified metin (vektörleştirme ve yerleştirmeden önce):\n",
            "b e f o r e   t r e a t m e n t   ,   t h e r e   w a s   n o   s i g n i f i c a n t   d i f f e r e n c e   b e t w e e n   t w o   g r o u p s   i n   e a c h   i n d e x   (   p   >   @   )   .\n",
            "\n",
            "Gömülü karakterler (vektörleştirme ve yerleştirmeden sonra):\n",
            "[[[ 0.0394259   0.02469474 -0.04906693 ... -0.03765197 -0.01020537\n",
            "    0.04477144]\n",
            "  [-0.028685    0.01803899  0.01715585 ... -0.03201541  0.01884799\n",
            "    0.04072127]\n",
            "  [-0.04388865  0.00688157 -0.02571483 ... -0.02481255  0.00622012\n",
            "    0.0067553 ]\n",
            "  ...\n",
            "  [-0.02440536  0.0424017  -0.02214311 ...  0.01463326  0.03493572\n",
            "   -0.0461356 ]\n",
            "  [-0.02440536  0.0424017  -0.02214311 ...  0.01463326  0.03493572\n",
            "   -0.0461356 ]\n",
            "  [-0.02440536  0.0424017  -0.02214311 ...  0.01463326  0.03493572\n",
            "   -0.0461356 ]]]\n",
            "\n",
            "Karakter yerleştirme şekli: (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dizilerimizdeki karakterlerin her biri 25 boyutlu bir gömmeye dönüştürülür. Her bir harf özellik vektörüne dönüştü.\n",
        "\n",
        "290 uzunluğa kadar sıfırlarla doldurulur. 1 dizi var, 290 karakter var (char vectorizer kaç harf olursa olsun 290'a kadar padding yapar), 25 gömme karakteri.\n",
        "\n",
        "Şimdi karakter düzeyindeki dizilerimizi sayılara (char_vectorizer) dönüştürmenin ve onları bir gömme (char_embed) olarak sayısal olarak temsil etmenin bir yolu var, karakter düzeyinde bir dizi modeli oluşturarak dizilerimizdeki bilgileri kodlamada ne kadar etkili olduklarını test edelim.\n",
        "\n",
        "Model, özel belirteç yerleştirme modelimizle (model_1) aynı yapıya sahip olacaktır, ancak belirteç düzeyinde diziler yerine karakter düzeyinde diziler giriş olarak alacaktır.\n",
        "\n",
        "Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)"
      ],
      "metadata": {
        "id": "DavlQQnd5nA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Karakterler için (harf) Conv1D hazırlama\n",
        "inputs = layers.Input(shape = (1,), dtype = \"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size = 5, padding = \"same\", activation = \"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation = \"softmax\")(x)\n",
        "model_3 = tf.keras.Model(\n",
        "    inputs = inputs,\n",
        "    outputs = outputs,\n",
        "    name = \"model_3_conv1D_char_embedding\"\n",
        ")\n",
        "\n",
        "# Modelin derlenmesi\n",
        "model_3.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = [\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Modelimizi verilere sığdırmadan önce, karakter düzeyinde toplu PrefetchedDataset'ler oluşturmalıyız\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(train_char_dataset)\n",
        "\n",
        "# Modeli uydur\n",
        "model_3_history = model_3.fit(\n",
        "    train_char_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=val_char_dataset,\n",
        "    validation_steps=int(0.1 * len(val_char_dataset))\n",
        "    )\n",
        "\n",
        "# Model özeti\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "dT_aU8T96Srn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "outputId": "693a612a-6e61-4ddd-88f2-bd774ca7601c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:934: UserWarning: Layer 'conv1d_2' (of type Conv1D) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>\n",
            "Epoch 1/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4197 - loss: 1.3969 - val_accuracy: 0.5814 - val_loss: 1.0622\n",
            "Epoch 2/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5800 - loss: 1.0410 - val_accuracy: 0.6316 - val_loss: 0.9509\n",
            "Epoch 3/3\n",
            "\u001b[1m562/562\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6223 - loss: 0.9517 - val_accuracy: 0.6446 - val_loss: 0.8973\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_3_conv1D_char_embedding\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_3_conv1D_char_embedding\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_22 (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ char_vectorizer (\u001b[38;5;33mTextVectorization\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ char_embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m25\u001b[0m)             │           \u001b[38;5;34m1,750\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m290\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m8,064\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m325\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ char_vectorizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ char_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,750</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">290</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,064</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,419\u001b[0m (118.83 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,419</span> (118.83 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,139\u001b[0m (39.61 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,139</span> (39.61 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,280\u001b[0m (79.22 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,280</span> (79.22 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 13.5 s, sys: 1.33 s, total: 14.8 s\n",
            "Wall time: 12.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model_3'ü tüm doğrulama karakteri veri kümesinde değerlendirin\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "metadata": {
        "id": "bkJ0W9pP8kQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e890422-2797-4dd2-bec3-8128c0323304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6505 - loss: 0.8906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8938198089599609, 0.6496756076812744]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Yalnızca karakter modeliyle tahminlerde bulunun\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "metadata": {
        "id": "WM6TFX0o8kMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c21ff1c-4cbf-486e-f063-94cc4f385c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m945/945\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.168758  , 0.16304976, 0.23900391, 0.32760364, 0.10158475],\n",
              "       [0.11768349, 0.60637593, 0.011198  , 0.1211826 , 0.14355993],\n",
              "       [0.0998732 , 0.31029567, 0.33654052, 0.21033841, 0.04295219],\n",
              "       ...,\n",
              "       [0.02575635, 0.03783292, 0.37089068, 0.09197588, 0.47354418],\n",
              "       [0.04610219, 0.12186202, 0.4773507 , 0.07366963, 0.28101537],\n",
              "       [0.4160033 , 0.40838563, 0.0707214 , 0.08389489, 0.02099485]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminleri sınıflara dönüştürün\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "metadata": {
        "id": "3rkc6vuO8kHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be7c7a34-2ad4-411a-93e0-6c66944977aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([3, 1, 2, ..., 4, 2, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Yalnızca Conv1D karakter modeli sonuçlarını hesapla\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                        y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "id": "bidY-6e58kCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0589936e-81a9-4f58-c3e4-e70bd8664952",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-2c2eac120973>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Yalnızca Conv1D karakter modeli sonuçlarını hesapla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_3_results = calculate_results(y_true=val_labels_encoded,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                         y_pred=model_3_preds)\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_3_results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mcalculate_results\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    279\u001b[0m   \"\"\"\n\u001b[1;32m    280\u001b[0m   \u001b[0;31m# Calculate model accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m   \u001b[0mmodel_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m   \u001b[0;31m# Calculate model precision, recall and f1 score using \"weighted average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m   \u001b[0mmodel_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weighted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace_and_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mget_namespace_and_device\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0marrays_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_remove_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_array_api\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(remove_none, remove_types, *array_list)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mdevice_other\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_array_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice_\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdevice_other\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;34mf\"Input arrays use different devices: {str(device_)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0;34mf\"{str(device_other)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays use different devices: cpu, /job:localhost/replica:0/task:0/device:GPU:0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.10. Önceden Eğitilmiş Token Gömmeler ve Karakter Gömmeleri Birleştirerek Modelleme ve Değerlendirme**"
      ],
      "metadata": {
        "id": "HJCbXuUXj4-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Medical Paper Abstracts'da Ortak Cümle Sınıflandırması için Sinir Ağları Şekil 1'dekine benzer bir model oluşturmaya yaklaşırken, bahsettikleri hibrit belirteç gömme katmanını ele almanın zamanı geldi. https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "Bu karma belirteç gömme katmanı, belirteç gömme ve karakter gömmelerinin bir kombinasyonudur. Başka bir deyişle, dizileri sıra etiketi tahmin katmanına geçirmeden önce temsil etmek için yığılmış bir gömme oluştururlar.\n",
        "\n",
        "Şimdiye kadar belirteç ve karakter düzeyinde gömmeler kullanan iki model geliştirdik, ancak bu iki model bu gömmelerin her birini özel olarak kullandı.\n",
        "\n",
        "Şekil 1'deki modeli çoğaltmaya (veya çoğaltmaya yaklaşmaya) başlamak için aşağıdaki adımlardan geçeceğiz:\n",
        "\n",
        "1. Token düzeyinde bir model oluşturun (model_1'e benzer)\n",
        "\n",
        "2. Karakter düzeyinde bir model oluşturun (kağıdı yansıtmak için hafif bir değişiklikle model_3'e benzer)\n",
        "\n",
        "3. 1 ve 2'nin çıktılarını birleştirin (layers.Concatenate) https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\n",
        "\n",
        "4. Tıbbi Kağıt Özetlerinde Ortak Cümle Sınıflandırması için Sinir Ağları'nın Şekil 1 ve bölüm 4.2'ye benzer 3'ün üzerine bir dizi çıktı katmanı oluşturun\n",
        "\n",
        "5. Token ve karakter düzeyinde dizileri girdi olarak alan ve çıktı olarak sıra etiketi olasılıkları üreten bir model oluşturun"
      ],
      "metadata": {
        "id": "h_4wovEb87-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Belirteç girişlerini/modelini ayarlayın\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Karakter girişlerini/modelini ayarlayın\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # https://arxiv.org/pdf/1612.05251.pdf adresindeki Şekil 1'de gösterilen bi-LSTM\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Belirteç ve karakter girişlerini birleştirin (hibrit belirteç yerleştirme oluşturun)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output,\n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Çıktı katmanları oluşturun - https://arxiv.org/pdf/1612.05251.pdf 4.2'de açıklanan bırakmanın eklenmesi\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # belirteç/karakter yerleştirme katmanlarının farklı şekilleri nedeniyle Şekil 1'den biraz farklı\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Karakter ve jeton girişleriyle model oluşturun\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")\n",
        "\n",
        "# Belirteç karakter modelini derle\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # https://arxiv.org/pdf/1612.05251.pdf bölümünün 4.2 bölümünde SGD kullanımından bahsediliyor ancak biz Adam'a sadık kalacağız\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Model özeti\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "A5qxQkJd_i7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "ee73c468-f913-4d82-9568-3ef8e28759ba",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tf_hub_embedding_layer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-ed7f7a62d2f3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Belirteç girişlerini/modelini ayarlayın\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtoken_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"token_input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_hub_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtoken_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m token_model = tf.keras.Model(inputs=token_inputs,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf_hub_embedding_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kod, bir **hibrit model** oluşturarak **belirteç (token) temelli yerleştirme** ve **karakter temelli yerleştirme** yöntemlerini birleştiriyor. Kodun belirli bölümlerini daha ayrıntılı açıklayayım:\n",
        "\n",
        "```python\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings)\n",
        "```\n",
        "\n",
        "Bu satırda, **Bidirectional LSTM (Bi-LSTM)** katmanı kullanılmıştır.\n",
        "\n",
        "**Bi-LSTM Nedir?**\n",
        "\n",
        "- **LSTM (Long Short-Term Memory)**, sekans (zaman serisi veya kelimeler gibi sıralı veriler) üzerindeki uzun menzilli bağımlılıkları öğrenebilen bir tür **Recurrent Neural Network (RNN)** katmanıdır. LSTM, özellikle dil işleme görevlerinde yaygın olarak kullanılır çünkü geçmiş bilgileri uzun süre hatırlayabilir ve geçici verileri unutarak önemli olanları öğrenebilir.\n",
        "\n",
        "- **Bidirectional LSTM (Bi-LSTM)**, LSTM katmanının iki yönlü versiyonudur. Bu, sıralı veriyi hem **soldan sağa** hem de **sağdan sola** işleyerek daha fazla bağlam bilgisi elde eder. Bu sayede, metnin başından ve sonundan gelen bağlamları aynı anda öğrenebiliriz.\n",
        "\n",
        "- **`LSTM(25)`**: Bu, LSTM katmanının çıktısının boyutunu belirtir. Yani, her bir zaman adımında 25 boyutlu bir vektör elde edilecek.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "token_model = tf.keras.Model(inputs=token_inputs, outputs=token_output)\n",
        "```\n",
        "\n",
        "```python\n",
        "char_model = tf.keras.Model(inputs=char_inputs, outputs=char_bi_lstm)\n",
        "```\n",
        "\n",
        "Bu satırlarda **model parçaları** tanımlanıyor:\n",
        "\n",
        "- **`token_model`**: Bu, **belirteç temelli yerleştirme** modelidir. `token_inputs` (kelimeler ya da belirteçler) ile başlar ve `token_embeddings`'ten geçtikten sonra, bir **`Dense`** katmanına (`token_output`) bağlanır. Bu model sadece belirteç düzeyinde öğrenme yapar.\n",
        "\n",
        "- **`char_model`**: Bu, **karakter temelli yerleştirme** modelidir. `char_inputs` (karakterler) ile başlar, `char_vectorizer` ile metni vektörleştirir, ardından `char_embed` ile karakter gömmeleri elde edilir ve sonrasında bir **Bi-LSTM katmanı** (`char_bi_lstm`) ile bu karakter dizileri üzerinde öğrenme yapılır.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, char_model.output])\n",
        "```\n",
        "\n",
        "Buradaki `token_model.output` ve `char_model.output` kullanımı, her iki modelin **çıkışlarını** almak için kullanılır:\n",
        "\n",
        "- **`token_model.output`**: `token_model`'in çıkışı, belirteçler için öğrenilen özellikleri içerir (yani, `token_output` katmanından gelen sonuç).\n",
        "  \n",
        "- **`char_model.output`**: `char_model`'in çıkışı, karakterler için öğrenilen özellikleri içerir (yani, `char_bi_lstm` katmanından gelen sonuç).\n",
        "\n",
        "`layers.Concatenate` katmanı, bu iki çıktıyı **birleştirir** (concatenate). Burada `name=\"token_char_hybrid\"` ismi verilmiş. Bu, her iki modelin çıktılarının **hibrit bir şekilde** birleştiği bir özellik vektörü oluşturur.\n",
        "\n",
        "**.output** ifadesi, her modelin son katmanındaki çıkışı belirtir. Modelin katmanlarını tanımlarken, `Model()` sınıfının çıktısı genellikle `.output` olarak erişilir.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "```\n",
        "\n",
        "```python\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "```\n",
        "\n",
        "**Dropout**, **aşırı uyum** (overfitting) problemini önlemeye yardımcı olan bir **düzenleme** (regularization) yöntemidir. Dropout, eğitim sırasında belirli katmanlardan rastgele **nöronları devre dışı bırakır**. Bu sayede, modelin her bir nöronun bağımlı hale gelmesi engellenir ve genelleme yeteneği artırılır.\n",
        "\n",
        "- **`0.5`**: Dropout oranını belirtir. Burada `0.5` değeri, her bir eğitim adımında %50 oranında nöronun rastgele devre dışı bırakılacağı anlamına gelir.\n",
        "\n",
        "- Dropout katmanları, aşırı uyumun önlenmesine yardımcı olur, çünkü her eğitim adımında farklı nöronlar devre dışı bırakıldığı için model, daha sağlam bir şekilde genel kalıpları öğrenir.\n",
        "\n",
        "Eğitim sırasında, **dropout** uygulandıktan sonra model sadece en önemli özellikleri öğrenmeye çalışır ve çok fazla modelin öğrenmesini engelleyen bağımlılıklar oluşmaz."
      ],
      "metadata": {
        "id": "rSXBroPAIUM5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 ile ilgili olarak; model, stokastik gradyan iniş kullanılarak eğitilir ve her gradyan adımında tüm parametreler, yani jeton yerleştirmeleri, karakter yerleştirmeleri, çift yönlü LSTM parametreleri ve geçiş olasılıkları güncellenir. Düzenleme için, karakter geliştirilmiş token yerleştirmelerine ve etiket tahmin katmanından önce 0,5 oranında bırakma uygulanır.\n",
        "\n",
        "5 --> bu sıralı API ile değil fonksiyonel API ile oluşturduk. Bu yüzden token modeli girişine ihtiyacımız var ve bunu da kullanabilmek için char model girişi kullanılmalı."
      ],
      "metadata": {
        "id": "5wDbqDXyAU2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aslında yapılan iki model oluşturuldu, çıktılar birleştirildi, bir token ve bir karakter çıktısı birleşti ve sonra bunlar üzerine bazı katmanlar ekledik."
      ],
      "metadata": {
        "id": "cErVyrbaApfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hibrit jeton ve karakter modelini çizin\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_4)"
      ],
      "metadata": {
        "id": "Oidcjf41AqWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "🔑 Not: Medical Paper Abstracts'ta Ortak Cümle Sınıflandırması için Sinir Ağları Bölüm 4.2, SGD (stokastik gradyan iniş) optimize ediciyi kullanarak bahseder, ancak diğer modellerimizle tutarlı kalmak için Adam optimizer'ı kullanacağız. Bir alıştırma olarak, tf.keras.optimizers.Adam yerine tf.keras.optimizers.SGD kullanmayı deneyebilir ve sonuçları karşılaştırabilirsiniz.\n",
        "\n",
        "- https://arxiv.org/pdf/1612.05251\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD"
      ],
      "metadata": {
        "id": "urMfBOscBCdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve yine, deneylerimizi hızlı tutmak için, token-character-hybrid modelimizi eğitimin %10'una sığdıracağız ve doğrulama gruplarının %10'unu doğrulayacağız. Bununla birlikte, bu model ile fark, iki girdi, belirteç düzeyinde diziler ve karakter düzeyinde diziler gerektirmesidir.\n",
        "\n",
        "Bunu, ilk girdi olduğu gibi bir demet ile bir tf.data.Dataset oluşturarak yapabiliriz, örneğin:\n",
        "\n",
        "((Token_data, char_data), (etiket))"
      ],
      "metadata": {
        "id": "qqgDc_7VBbYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Token ve karakter verilerini bir tf.data veri kümesinde birleştirme**\n",
        "\n",
        "- zip kodu ile iki farklı veri kümesi birleştirilir.\n",
        "- Hızlı deney yapma hedefiyle val...kodları yazıldı.\n",
        "- Token model girdisine ve char model girdisine nasıl sahip olduğumuza dikkat. Token seviyesinde veriler vardı, cümleleri eğittik ve traine aldık. Yani bu modelin inşa edildiği sırayla aynı. Aksi takdirde, farklı bir sırayla iletirsek, modelimiz belirteç seviyesi modelini kullanmaya çalışabilir."
      ],
      "metadata": {
        "id": "gxoztyGTByQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Karakterleri ve belirteçleri bir veri kümesinde birleştirin\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # veri yap\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # etiket yap\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # veri ve etiketleri birleştir\n",
        "\n",
        "# Verileri önceden getirme ve toplu eğitim verileri\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Aynı adımları doğrulama verilerini tekrarlayın\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Eğitim karakteri ve belirteç yerleştirme veri kümesine göz atın\n",
        "train_char_token_dataset, val_char_token_dataset\n",
        "\n",
        "# Token ve karakter düzeyindeki dizilere bir model uydurmak\n",
        "model_4_history = model_4.fit(train_char_token_dataset, # belirteç ve karakterlerden oluşan veri kümesi üzerinde eğitim alın\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
      ],
      "metadata": {
        "id": "8s57gZFECAjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "collapsed": true,
        "outputId": "c6cf8ae2-b3e1-4e3c-e9e9-6ea40a8cbf1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_4' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-3ef23ab4bb4d>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Token ve karakter düzeyindeki dizilere bir model uydurmak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m model_4_history = model_4.fit(train_char_token_dataset, # belirteç ve karakterlerden oluşan veri kümesi üzerinde eğitim alın\n\u001b[0m\u001b[1;32m     20\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_char_token_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_4' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Veri Kümesi Oluşturma (Dataset Creation)**\n",
        "\n",
        "```python\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))\n",
        "```\n",
        "  - `train_sentences` (cümleler) ve `train_chars` (karakterler) eğitim verisini içerir. Burada, her bir cümle ve ona karşılık gelen karakter dizisi eşleştirilir.\n",
        "  - `train_labels_one_hot` ise her örneğe karşılık gelen etiketlerin one-hot kodlamasıdır. (Yani, sınıf etiketlerinin 0-1 vektörleri olarak temsil edilmesi)\n",
        "  - `tf.data.Dataset.from_tensor_slices()` fonksiyonu, bu verileri bir TensorFlow veri kümesine dönüştürür. Bu veri kümesi modelin eğitiminde kullanılacak.\n",
        "  - `tf.data.Dataset.zip()` ile hem veriler (`train_char_token_data`) hem de etiketler (`train_char_token_labels`) eşleştirilir. Bu, modelin eğitim verisi ve etiketleriyle birlikte kullanılabilmesini sağlar.\n",
        "\n",
        "2. **Veri Kümesi Üzerinde İşlem Yapma (Prefetching and Batching)**\n",
        "\n",
        "```python\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "\n",
        "- **Açıklama**: Bu satırda iki şey yapılır:\n",
        "  - `batch(32)`: Eğitim verisi, 32 örnekten oluşan \"batch\" (toplu) olarak gruplandırılır. Bu, modelin daha verimli bir şekilde eğitilmesini sağlar. Batch'ler sayesinde model her seferinde sadece bir kısmı üzerinde işlem yapar, bu da daha hızlı işlemeye olanak tanır.\n",
        "  - `prefetch(tf.data.AUTOTUNE)`: Verilerin \"prefetch\" edilmesi, yani modelin eğitimi sırasında verilerin önceden yüklenmesi anlamına gelir. Bu, I/O işlemlerinin eğitim sırasında engel oluşturmadan hızlı bir şekilde yapılmasını sağlar. `AUTOTUNE` TensorFlow'un otomatik olarak en iyi önceden getirme (prefetch) stratejisini seçmesini sağlar.\n",
        "\n",
        "3. **Doğrulama Verisi için Aynı İşlemleri Tekrarlama**\n",
        "\n",
        "```python\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "```\n",
        "\n",
        "- **Açıklama**: Bu satırlar, doğrulama verisi için yukarıdaki işlemlerin tekrarlanmasıdır. Eğitim verisinde yapılan tüm işlemler doğrulama verisi için de aynı şekilde yapılır. Buradaki temel amaç, eğitim ve doğrulama veri kümelerinin her ikisinin de aynı formatta ve verimli bir şekilde yüklenmesini sağlamaktır.\n",
        "\n",
        "4. **Veri Kümesini İnceleme**\n",
        "\n",
        "```python\n",
        "train_char_token_dataset, val_char_token_dataset\n",
        "```\n",
        "\n",
        "- **Açıklama**: Bu satır, eğitim ve doğrulama veri kümelerini kontrol etmek için yazılmış. Çalıştırıldığında, bu iki veri kümesinin TensorFlow veri kümesi olarak nasıl göründüğünü gösterir. Bu işlem genellikle kodun doğru çalıştığından emin olmak amacıyla kullanılır.\n",
        "\n",
        "5. **Modeli Eğitim İçin Uygulama (Model Fitting)**\n",
        "\n",
        "```python\n",
        "model_4_history = model_4.fit(\n",
        "    train_char_token_dataset,\n",
        "    steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "    epochs=3,\n",
        "    validation_data=val_char_token_dataset,\n",
        "    validation_steps=int(0.1 * len(val_char_token_dataset))\n",
        ")\n",
        "```\n",
        "\n",
        "- **Açıklama**: Bu satır modelin eğitimini başlatır.\n",
        "  - `model_4.fit()` fonksiyonu, verilen eğitim veri kümesi (`train_char_token_dataset`) üzerinde modeli eğitir.\n",
        "  - `steps_per_epoch=int(0.1 * len(train_char_token_dataset))`: Bu parametre, her epoch başına eğitimde kaç adım (batch) yapılacağını belirtir. Burada eğitim setinin %10'u kadar adım atılacak.\n",
        "  - `epochs=3`: Modelin 3 epoch boyunca eğitilmesi sağlanır. Bir epoch, tüm eğitim verisinin bir kez model tarafından görülmesidir.\n",
        "  - `validation_data=val_char_token_dataset`: Modelin her epoch sonunda doğrulama verisi üzerinde nasıl performans gösterdiğini görmek için doğrulama verisi sağlanır.\n",
        "  - `validation_steps=int(0.1 * len(val_char_token_dataset))`: Her epoch sonunda doğrulama verisi için kaç adım (batch) yapılacağını belirtir. Burada doğrulama setinin %10'u kadar adım yapılır.\n",
        "\n",
        "Bu kodlar, modeli eğitim verisi ve doğrulama verisi üzerinde eğitir ve modelin doğruluğunu izler. Eğitim sırasında yapılan her adımda, modelin belirteç ve karakter bazlı girdilerle nasıl öğrenmeye çalıştığını gözlemleyebilirsiniz."
      ],
      "metadata": {
        "id": "u9cp5f63JOfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doğrulama veri kümesinin tamamını değerlendirin\n",
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "metadata": {
        "id": "gzA5TykrCwan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirteç-karakter modeli hibritini kullanarak tahminlerde bulunun\n",
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_pred_probs"
      ],
      "metadata": {
        "id": "VbDZsI2QCyxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasılıklarını tahmin sınıflarına dönüştürün\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
        "model_4_preds"
      ],
      "metadata": {
        "id": "Lh0gSxRMCys4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Token-char-hibrit modelinin sonuçlarını alın\n",
        "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "JiliQHWvCynR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.11. Önceden Eğitilmiş Token Gömmeler, Karakter Gömmeleri ve Konumsal Gömmeleri Birleştirerek Modelleme ve Değerlendirme**"
      ],
      "metadata": {
        "id": "5MW2eP-xj48T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token gömmelerini ve karakter gömmelerini birleştirmek modelimize biraz performans artışı sağladı gibi görünüyor.\n",
        "\n",
        "Ama ekleyebileceğimiz bulmacanın bir parçası daha var.\n",
        "\n",
        "Ya kendi özelliklerimizi modele dönüştürseydik?\n",
        "\n",
        "Yani, modelimize örneklerimiz hakkında daha fazla bilgi vermek için veriler hakkında kendi bilgimizi alıp sayısal bir şekilde kodlasaydık ne olur?\n",
        "\n",
        "Bir modele girdi olarak özellikler oluşturmak için kendi bilginizi uygulama sürecine özellik mühendisliği denir.\n",
        "\n",
        "Sınıflandırmaya çalıştığımız diziler hakkında önemli bir şey düşünebiliyor musunuz?\n",
        "\n",
        "Bir özete bakacak olsaydınız, cümlelerin sırayla görünmesini bekler miydiniz? Yoksa sırayla görünmeleri mantıklı mı? Örneğin, begging'de SONUÇLAR olarak etiketlenmiş diziler ve sonunda HEDEF olarak etiketlenmiş diziler?\n",
        "\n",
        "Özetler tipik olarak sıralı bir sırada gelir, örneğin:\n",
        "\n",
        "- OBJECTIVE ...\n",
        "- METHODS ...\n",
        "- METHODS ...\n",
        "- METHODS ...\n",
        "- RESULTS ...\n",
        "- CONCLUSIONS ...\n",
        "\n",
        "ya da;\n",
        "\n",
        "- BACKGROUND ...\n",
        "- OBJECTIVE ...\n",
        "- METHODS ...\n",
        "- METHODS ...\n",
        "- RESULTS ...\n",
        "- RESULTS ...\n",
        "- CONCLUSIONS ...\n",
        "- CONCLUSIONS ...\n",
        "\n",
        "Tabii ki, dizi etiketlerinin kendilerini eğitim verilerine dönüştüremeyiz (test zamanında bunlara sahip değiliz), ancak bir dizi dizinin sırasını soyut olarak kodlayabiliriz.\n",
        "\n",
        "Örneğin,\n",
        "\n",
        "- Sentence 1 of 10 ...\n",
        "- Sentence 2 of 10 ...\n",
        "- Sentence 3 of 10 ...\n",
        "- Sentence 4 of 10 ...\n",
        "\n",
        "Bunu preprocess_text_with_line_numbers() işlevimizi oluşturduğumuzda fark etmiş olabilirsiniz. Bir özet metin dosyasında okuduğumuzda, bir özetteki satır sayısını ve her satırın kendisinin sayısını saydık.\n",
        "\n",
        "Bunu yapmak, DataFrames'lerimizin \"line_number\" ve \"total_lines\" sütunlarına yol açtı."
      ],
      "metadata": {
        "id": "3EvF95--DkZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering\n",
        "- Verilerden kesin olmayan özellikleri alıp rakamlara dönüştürme (amaç modelin öğrenmesi).\n",
        "- Modele nasıl fazladan veri kaynağı ekleyebiliriz?\n"
      ],
      "metadata": {
        "id": "CKcmd9jADr1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim veri çerçevesini inceleyin\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "oxLk9XZHDt5X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ae740d25-8fe7-428b-9f0a-029f9644ea58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      target                                               text  line_number  \\\n",
              "0  OBJECTIVE  to investigate the efficacy of @ weeks of dail...            0   \n",
              "1    METHODS  a total of @ patients with primary knee oa wer...            1   \n",
              "2    METHODS  outcome measures included pain reduction and i...            2   \n",
              "3    METHODS  pain was assessed using the visual analog pain...            3   \n",
              "4    METHODS  secondary outcome measures included the wester...            4   \n",
              "\n",
              "   total_lines  \n",
              "0           11  \n",
              "1           11  \n",
              "2           11  \n",
              "3           11  \n",
              "4           11  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-81e5bba4-b49d-4b77-bd82-698ff314ff67\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81e5bba4-b49d-4b77-bd82-698ff314ff67')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-81e5bba4-b49d-4b77-bd82-698ff314ff67 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-81e5bba4-b49d-4b77-bd82-698ff314ff67');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-88013b99-3848-4eb5-af80-a75db57a7554\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88013b99-3848-4eb5-af80-a75db57a7554')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-88013b99-3848-4eb5-af80-a75db57a7554 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Line_number\" ve \"total_lines\" sütunları, mutlaka eğitim verileriyle birlikte gelmeyen, ancak konumsal bir gömme olarak modelimize aktarılabilen özelliklerdir. Başka bir deyişle, konumsal gömme, cümlenin bir soyutta göründüğü yerdir.\n",
        "\n",
        "Bu özellikleri kullanabiliriz çünkü test zamanında mevcut olacaklar.\n",
        "\n",
        "Özetler tipik olarak onlar hakkında sıralı bir sıraya sahip olduğundan (örneğin, arka plan, amaç, yöntemler, sonuçlar, sonuç), belirli bir cümlenin gerçekleştiği yerin satır numarasını modelimize eklemek mantıklıdır. İşin güzel yanı, bu özellikler test zamanında mevcut olacak (sadece bir özetteki cümle sayısını ve her birinin sayısını sayabiliriz).\n",
        "\n",
        "Yani, modelimizin hiç görmediği bir soyuttaki dizilerin etiketlerini tahmin edecek olsaydık, çizgi sayısını ve her bir çizginin konumunu izleyebilir ve modelimize aktarabilirdik.\n",
        "\n",
        "🛠 Alıştırma: Konumsal gömme özelliğimizi oluşturmanın başka bir yolu, \"line_number\" ve \"toplam_lines\" sütunlarını bir arada birleştirmek olacaktır, örneğin bir \"line_position\" sütunu 1_of_11, 2_of_11, vb. gibi değerler içerebilir. 1_of_11, 11 cümle uzunluğunda bir özetteki ilk satır olacaktır. Aşağıdaki adımlardan geçtikten sonra, bu konumsal gömme aşamasını tekrar gözden geçirmek ve birleşik bir \"line_position\" sütununun iki ayrı sütuna karşı nasıl gittiğini görmek isteyebilirsiniz."
      ],
      "metadata": {
        "id": "y39iRrv9D18c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Konumsal Gömmeler**\n",
        "\n",
        "\"Line_number\" ve \"total_line\" sütunlarımız zaten sayısal olduğundan, onları modelimize olduğu gibi geçirebiliriz.\n",
        "\n",
        "Ancak modelimizin \"line_number\"=5 içeren bir satırın \"line_number\"=1 olan bir satırdan beş kat daha büyük olduğunu düşünmekten kaçınmak için, \"line_number\" ve \"total_lines\" özelliklerimizi kodlamak için one-hot-encoding kullanacağız.\n",
        "\n",
        "Bunu yapmak için tf.one_hot yardımcı programını kullanabiliriz.\n",
        "\n",
        "Tf.one_hot, tek sıcak kodlanmış bir tensör döndürür. Bir diziyi (veya tensörü) girdi olarak kabul eder ve derinlik parametresi döndürülen tensörün boyutunu belirler.\n",
        "\n",
        "Derinlik parametresini neye ayarlamamız gerektiğini bulmak için, \"line_number\" sütununun dağılımını araştıralım.\n",
        "\n",
        "🔑 Not: Özelliklerimizi tek sıcak kodlama söz konusu olduğunda, Scikit-Learn'in OneHotEncoder sınıfı burada başka bir uygulanabilir seçenektir. https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
      ],
      "metadata": {
        "id": "2awP-O6dD-5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Özellik mühendisliği uygulanırken satır numaraları (cümle nolar, her cümle 1 satır diye geçiyor burada) kullanılmalı mı?\n",
        "\n",
        " Bir model yalnızca eğitildiği formatta veriler üzerinde gerçekleştirebilir veya tahminlerde bulunabilir.\n",
        "\n",
        "Aksi durumda chorme gibi farklı tarayıcılarda sorun çıkabilir?\n",
        "\n",
        " Özellik mühendisliği test zamanında erişilebilir olmalı.\n",
        " - line numbers\n",
        " - toyal lines"
      ],
      "metadata": {
        "id": "rwTJ0JfEEFDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaç farklı satır numarası var?\n",
        "train_df[\"line_number\"].value_counts()"
      ],
      "metadata": {
        "id": "0nTf_fhPEKMG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f2c2912-f9fb-45e2-afaf-5c349eeeecde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "line_number\n",
              "0     15000\n",
              "1     15000\n",
              "2     15000\n",
              "3     15000\n",
              "4     14992\n",
              "5     14949\n",
              "6     14758\n",
              "7     14279\n",
              "8     13346\n",
              "9     11981\n",
              "10    10041\n",
              "11     7892\n",
              "12     5853\n",
              "13     4152\n",
              "14     2835\n",
              "15     1861\n",
              "16     1188\n",
              "17      751\n",
              "18      462\n",
              "19      286\n",
              "20      162\n",
              "21      101\n",
              "22       66\n",
              "23       33\n",
              "24       22\n",
              "25       14\n",
              "26        7\n",
              "27        4\n",
              "28        3\n",
              "29        1\n",
              "30        1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>line_number</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>14949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>14758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>14279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>7892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>4152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"line_number\" sütununun dağılımını kontrol edin\n",
        "train_df.line_number.plot.hist()"
      ],
      "metadata": {
        "id": "6eJrMPx2EKFL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "1cae3949-c0d5-4860-db74-1607e369ee17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 103
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"line_number\" sütunumuzun sıcak kodlanmış tensörlerini oluşturmak için TensorFlow'u kullanın\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"
      ],
      "metadata": {
        "id": "7CqFusHPEKBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu satırlar, **sıra numaraları (line numbers)** gibi kategorik bir özelliğin **one-hot encoding** (tek sıcak kodlama) yöntemini kullanarak sayısal verilere dönüştürülmesini sağlar.\n",
        "\n",
        "1. **`train_df[\"line_number\"].to_numpy()`**:  \n",
        "   Bu kısım, eğitim veri setindeki `\"line_number\"` adlı sütunu seçer ve bu sütundaki değerleri **NumPy dizisi** (`np.array`) haline getirir.\n",
        "   - Burada `train_df` veri çerçevesindeki her bir satırın sıra numarasını almak istiyoruz.\n",
        "   - Örneğin, bu sütun her cümlenin bulunduğu satır numarasını veya belge sırasını içerebilir.\n",
        "\n",
        "2. **`tf.one_hot(..., depth=15)`**:  \n",
        "   TensorFlow'un `tf.one_hot()` fonksiyonu, kategorik veriyi **one-hot encoding** formatına dönüştürür. Yani her sıra numarasını 15 elemanlı bir vektöre dönüştürür ve sadece ilgili index'e 1 yerleştirir, geri kalan tüm elemanlar 0 olur. Bu `depth=15` parametresiyle belirtilen 15, sınıf sayısını belirtir (yani sıralama numaralarının 0'dan 14'e kadar olduğunu varsayıyoruz).\n",
        "   \n",
        "   Örneğin:\n",
        "   - Eğer bir satırın numarası `2` ise, one-hot encoding sonucu şöyle bir vektör olacaktır: `[0, 0, 1, 0, 0, ..., 0]` (sadece 3. pozisyon 1 olacak, diğerleri 0 olacak).\n",
        "   - Eğer satır numarası `4` ise, one-hot encoding sonucu şu şekilde olacaktır: `[0, 0, 0, 0, 1, 0, ..., 0]`.\n",
        "\n",
        "3. **`depth=15`**:  \n",
        "   Bu parametre, one-hot encoding için kullanılan vektörün uzunluğunu belirtir. Yani burada 15 sınıf olduğu belirtilmiş, bu da her satırın 0'dan 14'e kadar olan bir numaraya sahip olduğu anlamına gelir.\n",
        "\n",
        "### Örnek:\n",
        "Eğer `train_df[\"line_number\"]` şu şekilde bir dizi içeriyorsa:\n",
        "```python\n",
        "[2, 4, 0, 1, 3]\n",
        "```\n",
        "\n",
        "`tf.one_hot()` fonksiyonu, bu diziyi şu şekilde dönüştürür:\n",
        "\n",
        "```python\n",
        "[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 2'yi one-hot encode etti\n",
        " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 4'ü one-hot encode etti\n",
        " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 0'ı one-hot encode etti\n",
        " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],  # 1'i one-hot encode etti\n",
        " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]  # 3'ü one-hot encode etti\n",
        "```\n",
        "\n",
        "Kullanım Amacı:\n",
        "- **Model Eğitimi**: Bu tür one-hot encoding, modelin sıralama bilgisiyle (satır numaralarıyla) anlamlı ilişkiler öğrenmesine olanak tanır. Kategorik verileri sayısal verilere dönüştürmek, modelin bu veriyi anlayabilmesi için gereklidir.\n",
        "- **Kategorik Veriyi Sayısal Hale Getirme**: Özellikle sinir ağlarında kategorik verilerin (satır numaraları, sınıflar, vb.) işlemeye uygun hale gelmesi için one-hot encoding yaygın olarak kullanılır."
      ],
      "metadata": {
        "id": "Fpj-avFdKDcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf.one_hot'un derinlik parametresini 15'e ayarlamak, \"line_number\" değeri 15'in üzerinde olan herhangi bir numunenin tüm 0'ların tensörüne ayarlandığı anlamına gelir; burada 15'in altındaki \"satır_number\" olan herhangi bir örnek, tüm 0'ların tensörüne dönüşür, ancak dizinde \"line_number\" değerine eşit bir 1 ile.\n",
        "\n",
        "🔑 Not: \"line_number\" (derinlik=30) tüm potansiyel değerleri için yer olan tek sıcak bir tensör oluşturabiliriz, ancak bu, değerlerin büyük çoğunluğunun 0 olduğu mevcut olanın (derinlik=15) iki katı büyüklüğünde bir tensörle sonuçlanır. Ayrıca, yalnızca ~2.000/180.000 örnek 15'in üzerinde bir \"satır_numarası\" değerine sahiptir. Bu nedenle, özellik alanımızı ikiye katlamak için verilerimiz hakkında fazla bilgi edinmezdik. Bu tür bir soruna boyutsallığın laneti denir. Ancak, bu derin modellerle çalıştığımız için, modele mümkün olduğunca fazla bilgi atmaya ve ne olduğunu görmeye değer olabilir. Derinlik parametresinin değerlerini bir uzantı olarak keşfetmeyi bırakacağım."
      ],
      "metadata": {
        "id": "C-dIrngIEa1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tek-etkin kodlanmış \"satır_numarası\" özellik örneklerini kontrol edin\n",
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"
      ],
      "metadata": {
        "id": "NLKFWXMMEdSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6501669-374a-4436-90dd-fc81c9221114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 15]),\n",
              " <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Toplam_satır\" sütunuyla \"satır_numarası\" sütunumuz için yaptığımızın aynısını yapabiliriz. İlk olarak, tf.one_hot'un derinlik parametresi için uygun bir değer bulalım."
      ],
      "metadata": {
        "id": "aMNXtsKsEjST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaç farklı sayıda satır var?\n",
        "train_df[\"total_lines\"].value_counts()"
      ],
      "metadata": {
        "id": "CHsRJrcgEjyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "outputId": "961c4e95-e2dc-4851-8125-cc19009875a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "total_lines\n",
              "11    24468\n",
              "10    23639\n",
              "12    22113\n",
              "9     19400\n",
              "13    18438\n",
              "14    14610\n",
              "8     12285\n",
              "15    10768\n",
              "7      7464\n",
              "16     7429\n",
              "17     5202\n",
              "6      3353\n",
              "18     3344\n",
              "19     2480\n",
              "20     1281\n",
              "5      1146\n",
              "21      770\n",
              "22      759\n",
              "23      264\n",
              "4       215\n",
              "24      200\n",
              "25      182\n",
              "26       81\n",
              "28       58\n",
              "3        32\n",
              "30       31\n",
              "27       28\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_lines</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>24468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>22113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>19400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>18438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>12285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>10768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>5202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toplam satırların dağılımını kontrol edin\n",
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "id": "W602daECEoko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "93a5a488-0c5a-4f83-fdd3-6125b97ee063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Total_lines\" sütunumuzun dağılımına bakıldığında, 20 değeri örneklerin çoğunu kapsıyor gibi görünüyor.\n",
        "\n",
        "Bunu np.percentile() ile doğrulayabiliriz. https://numpy.org/doc/stable/reference/generated/numpy.percentile.html"
      ],
      "metadata": {
        "id": "Xk-Tl-3pEs35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 20 değerindeki \"total_lines\" değerinin kapsamını kontrol edin\n",
        "np.percentile(train_df.total_lines, 98) # 20 değeri örneklerin %98'ini kapsar"
      ],
      "metadata": {
        "id": "LM0_IfxSEwWi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a886f5a-57a3-4279-b4cd-9a139df23f98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \"total_lines\" sütunumuzun sıcak kodlanmış tensörlerini oluşturmak için TensorFlow'u kullanın\n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "\n",
        "# Tek-sıcak tensörün toplam çizgilerinin şeklini ve örneklerini kontrol edin\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
      ],
      "metadata": {
        "id": "YaahGOUCEwTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ac586c-a2a0-46a6-c54f-ec6f70c76b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 20]),\n",
              " <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tribrid gömme modeli oluşturma**\n",
        "\n",
        "Konumsal gömme tensörleri hazır.\n",
        "\n",
        "Şimdiye kadar inşa ettiğimiz en büyük modeli inşa etme zamanı. Token gömmeleri, karakter gömmeleri ve yeni hazırlanmış konumsal gömmelerimizi içeren bir tane.\n",
        "\n",
        "Keşfedilmiş bölgeye gireceğiz ama burada daha önce uygulamadığınız hiçbir şey olmayacak.\n",
        "\n",
        "Daha spesifik olarak aşağıdaki adımlardan geçeceğiz:\n",
        "\n",
        "1. Token düzeyinde bir model oluşturun (model_1'e benzer)\n",
        "\n",
        "2. Karakter düzeyinde bir model oluşturun (kağıdı yansıtmak için hafif bir değişiklikle model_3'e benzer)\n",
        "\n",
        "3. Bir \"line_number\" modeli oluşturun (tek-sıcak kodlanmış \"line_number\" tensörünü alır ve doğrusal olmayan bir katmandan geçirir)\n",
        "\n",
        "4. Bir \"total_lines\" modeli oluşturun (tek-sıcak kodlu \"total_lines\" tensörü alır ve doğrusal olmayan bir katmandan geçirir)\n",
        "\n",
        "5. 1 ve 2'nin çıktılarını bir token-karakter-hibrit gömme içinde birleştirin (katmanlar kullanarak. Birleştirin) ve Tıbbi Kağıt Özetlerinde Ortak Cümle Sınıflandırması için Sinir Ağları'nın Şekil 1 ve bölüm 4.2'sine çıktı serisini iletin https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\n",
        "\n",
        "6. 3, 4 ve 5'in çıktılarını bir token-karakter-konumsal tribrid gömmede birleştirin (katmanlar kullanarak. Birleştirin)\n",
        "\n",
        "7. Tribrid gömme ve çıkış tahmin edilen etiket olasılıklarını kabul etmek için bir çıktı katmanı oluşturun\n",
        "\n",
        "8. 1, 2, 3, 4 girişlerini ve 7'nin çıkışlarını bir tf.keras.Model'de birleştirin https://www.tensorflow.org/api_docs/python/tf/keras/Model\n",
        "\n",
        "https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "LSTM(32) dokümandan gelir, videoda 24 yapmış gerekçesi de karakter gömme token 50 ike 25 alıyor, ama 8'in katlarını tercih etmek için bunu uyguluyor.\n",
        "\n",
        "train_line_numbers_one_hot[0].shape --> 15\n",
        "\n",
        "train_total_lines_one_hot.shape --> (180040,20)\n",
        "\n",
        "4'te model ismi y diye adlandırıldı, x ile karıştırmamamk için. Ayrıca 32'lik özellik vektörüne gömülme olur."
      ],
      "metadata": {
        "id": "Li_eIdYWE9Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Token girişleri\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Karakter girişleri\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Satır numarası girişleri\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Toplam satır girişleri\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Token ve karakter yerleştirmelerini hibrit bir yerleştirmede birleştirin\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Konumsal yerleştirmeleri birleştirilmiş belirteç ve karakter yerleştirmeleriyle bir tribrid yerleştirmede birleştirin\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Çıktı katmanı oluştur\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Modeli bir araya getir\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)\n",
        "\n",
        "# Model özeti\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "BUhOreQAHmC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "outputId": "e7f2f8cc-89e8-482e-c6d9-2537e956e8da",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Exception encountered when calling layer 'keras_layer_6' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_6' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>\n  • training=None",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-a872e6e0cd48>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 1. Token girişleri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtoken_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"string\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"token_inputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtoken_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_hub_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtoken_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m token_model = tf.keras.Model(inputs=token_inputs,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow_hub/keras_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;31m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer_6' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>,) and kwargs: {} for signature: (inputs: TensorSpec(shape=<unknown>, dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_6' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=False, name=token_inputs>\n  • training=None"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* char_inputs --> karakter gömme\n",
        "* token_inputs --> token dömme\n",
        "* line_number_input ve total_line_input --> özellik gömme"
      ],
      "metadata": {
        "id": "-C3leZpGH0rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirteci, karakteri ve konumsal gömme modelini çizin\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_5)"
      ],
      "metadata": {
        "id": "KYOnB4LWH2Sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modeli görselleştirmek, anlaşılmayı çok daha kolay hale getirir.\n",
        "\n",
        "Esasen yaptığımız şey, dizilerimiz hakkında mümkün olduğunca fazla bilgiyi çeşitli gömmelere (modelimize girdiler) kodlamaya çalışmaktır, böylece modelimiz hangi etiketin bir diziye (modelimizin çıktıları) ait olduğunu bulmak için en iyi şansa sahiptir.\n",
        "\n",
        "Modelimizin, Tıbbi Kağıt Özetlerinde Ortak Cümle Sınıflandırması için Sinir Ağları Şekil 1'de gösterilen modele çok benzediğini fark edeceksiniz. Ancak, hala birkaç fark devam ediyor: https://arxiv.org/pdf/1612.05251\n",
        "\n",
        "- GloVe emebdding'ler yerine önceden eğitilmiş TensorFlow Hub belirteç gömmeleri kullanıyoruz.\n",
        "\n",
        "- Bi-LSTM katmanı yerine token-karakter hibrit gömmelerimizin üzerinde yoğun bir katman kullanıyoruz.\n",
        "\n",
        "- Makalenin Bölüm 3.1.3'ü, bir etiket dizisi optimizasyon katmanından bahseder (bu, dizi etiketlerinin saygın bir sırayla çıkmasını sağlamaya yardımcı olur) ancak Şekil 1'de gösterilmez. Modelimizde bu katmanın eksikliği için makyaj yapmak için konumsal gömme katmanlarını oluşturduk.\n",
        "\n",
        "- Makalenin 4.2. Bölümü, belirteç ve karakter gömmelerinin eğitim sırasında güncellendiğinden bahseder, önceden eğitilmiş TensorFlow Hub gömmelerimiz donmuş kalır.\n",
        "\n",
        "- Kağıt SGD optimize ediciyi kullanıyor, Adam'a bağlı kalacağız.\n",
        "\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam\n",
        "\n",
        "Yukarıdaki tüm farklılıklar bu projenin potansiyel uzantılarıdır."
      ],
      "metadata": {
        "id": "jtIvT9P0IfnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelimizin hangi katmanlarının eğitilebilir olup olmadığını kontrol edin\n",
        "for layer in model_5.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "metadata": {
        "id": "8sh9zvfUIhQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi modelimiz inşa edildi, derleyelim.\n",
        "\n",
        "Bu sefer, kayıp fonksiyonumuza label_smoothing adlı yeni bir parametre tanıtacağız. Etiket yumuşatma, bir örneğe belirli bir etiket uygulamaya çok fazla odaklanmadığından emin olarak modelimizi düzenlemeye (aşırı takmayı önlemeye) yardımcı olur.\n",
        "\n",
        "Örneğin, bir çıktı tahminine sahip olmak yerine:\n",
        "\n",
        "- Bir numune için [0.0, 0.0, 1.0, 0.0, 0.0] (model, doğru etiketin indeks 2 olduğundan çok emindir).\n",
        "\n",
        "Tahminler şöyle bir şey olacak şekilde yumuşatılacak:\n",
        "\n",
        "- [0.01, 0.01, 0.096, 0.01, 0.01] diğer etiketlerin her birine küçük bir aktivasyon vererek, umarım genellemeyi iyileştirir.\n",
        "\n",
        "📖 Kaynak: Etiket yumuşatma hakkında daha fazla bilgi için, PyImageSearch'ün harika blog gönderisine bakın, Keras, TensorFlow ve Deep Learning ile etiket yumuşatma. https://pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/\n",
        "\n",
        "label smooting --> 0-1 arası float türünde sayıdır. Etiket değerleri yumuşatılmıştır. Etiket değerine olan güvenirlilik esnektir. Örneğin bu değer 0.2 ise bir 0 etiketi için 0.1 ve 1 etiketi için 0.9 kullanılır.\n",
        "\n",
        "Sıfırda, bir sıfır noktasında takılırsa, öğrenmeyi tamamen durdurabilir çünkü model der ki ben sadece 1.0 olanı öğreneceğim, diğerleri unutulabilir.\n",
        "\n",
        "Ama yumuşatılmışta model 0.01'de sıkışıp kalmaz, daha sağlıklı tahminler...\n",
        "\n",
        "Etiket yumuşatması olan bu işlevi kullanabilmek için etiketlerimize tek bir sıcak kodlama biçiminde ihtiyacımız vardı."
      ],
      "metadata": {
        "id": "HMjBdGvrInhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirteç, karakter ve konumsal gömme modelini derleyin\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # etiket yumuşatma ekleyin (gerçekten kendine güvenen örnekler biraz yumuşatılır)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "raX_NfJVIshF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tribrid gömme veri kümeleri oluşturun ve tribrid modelini sığdırın**\n",
        "\n",
        "Bu sefer modelimiz dört özellik girişi gerektiriyor:\n",
        "\n",
        "1. Eğitim hattı numaraları tek sıcak tensör (train_line_numbers_one_hot)\n",
        "\n",
        "2. Eğitim toplam hatları bir-sıcak tensör (train_total_lines_one_hot)\n",
        "\n",
        "3. Token-seviye dizileri tensörü (train_sentences)\n",
        "\n",
        "4. Char-level dizileri tensörü (train_chars)\n",
        "\n",
        "Uygun şekilde şekillendirilmiş ve toplu PrefetchedDataset'ler oluşturmak için bunları tf.data.Dataset.from_tensor_slices() yöntemimize demet olarak aktarabiliriz."
      ],
      "metadata": {
        "id": "XhfjFl1WI1MW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitim ve doğrulama veri kümeleri oluşturun (dört tür girdinin tümü)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # satır numarası\n",
        "                                                                train_total_lines_one_hot, # toplam satırlar\n",
        "                                                                train_sentences, # eğitim tokenleri\n",
        "                                                                train_chars)) # eğitim karakterleri\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # eğitim etiketleri\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # veri ve etiketleri birleştir\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # gruplara dönüştürün ve uygun şekilde önceden getirin\n",
        "\n",
        "# Doğrulama veri kümesi\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # gruplara dönüştürün ve uygun şekilde önceden getirin\n",
        "\n",
        "# Giriş şekillerini kontrol edin\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset\n",
        "\n",
        "# Belirteci, karakteri ve konumsal gömme modelini takın\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
      ],
      "metadata": {
        "id": "H5CasYHFI_zE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "collapsed": true,
        "outputId": "55278ded-da1b-4f83-a2fc-7582e9eea99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_5' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-fce7297ceb32>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Belirteci, karakteri ve konumsal gömme modelini takın\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m history_model_5 = model_5.fit(train_pos_char_token_dataset,\n\u001b[0m\u001b[1;32m     24\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pos_char_token_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_5' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirteç-karakter-konumsal hibrit modelle tahminler yapın\n",
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ],
      "metadata": {
        "id": "-ksTPa__I_vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasılıklarını tahmin sınıflarına dönüştürün\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "id": "4GiTVX7UJHHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Belirteç-karakter-konumsal hibrit modelin sonuçlarını hesaplayın\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "id": "K0JyqPRgJHDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Model Sonuçlarını Karşılaştır**"
      ],
      "metadata": {
        "id": "X0Wpqr5pj453"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model sonuçlarını bir DataFrame'de birleştirin\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
        "                                  \"pretrained_token_embed\": model_2_results,\n",
        "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
        "                                  \"hybrid_char_token_embed\": model_4_results,\n",
        "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "metadata": {
        "id": "gKjUX9iWKItN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "3b824fcd-f81c-4f70-8039-3a749708c3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_1_results' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-1dd819eba5ab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model sonuçlarını bir DataFrame'de birleştirin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n\u001b[0;32m----> 3\u001b[0;31m                                   \u001b[0;34m\"custom_token_embed_conv1d\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_1_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                   \u001b[0;34m\"pretrained_token_embed\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_2_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                   \u001b[0;34m\"custom_char_embed_conv1d\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_3_results\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_1_results' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Doğruluğu diğer ölçümlerle aynı ölçeğe düşürün\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "metadata": {
        "id": "jqgTmVXQKilu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tüm model sonuçlarını çizin ve karşılaştırın\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "metadata": {
        "id": "3hPNgcX_KiiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model sonuçlarını f1 puanına göre sıralayın\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "metadata": {
        "id": "t_JExj_JKp_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-scores'a dayanarak, tribrid gömme modelimiz adil bir farkla en iyi performansı sergiliyor gibi görünüyor.\n",
        "\n",
        "Bununla birlikte, PubMed 200k RCT'nin Tablo 3'ünde bildirilen sonuçlarla karşılaştırıldığında: Tıbbi Özetler makalesinde Sıralı Cümle Sınıflandırması için Bir Veri Kümesi, modelimizin F1-skoru hala düşük performans gösteriyor (yazar modeli, ~82.6'lık F1 skorumuza karşı 20k RCT veri kümesinde 90.0'lık bir F1 puanı elde ediyor). https://arxiv.org/pdf/1710.06071\n",
        "\n",
        "Bu fark hakkında dikkat edilmesi gereken bazı şeyler var:\n",
        "\n",
        "- Modellerimiz (taban çizgisi hariç), 20k RCT veri kümesindeki tam ~180.000 yerine ~18.000 (partilerin %10'u) dizi ve etiket örneği üzerinde eğitilmiştir.\n",
        "\n",
        "  - Bununla birlikte, makine öğrenimi deneylerinde genellikle durum böyledir, eğitimin daha az sayıda örnek üzerinde çalıştığından emin olun, ardından gerektiğinde yükseltin (bu projenin bir uzantısı, tam veri kümesinde bir model eğitecektir).\n",
        "\n",
        "- Modelimizin tahmin performans seviyeleri, test veri kümesinde değil, doğrulama veri kümesinde değerlendirilmiştir (en iyi modelimizi kısa süre içinde test veri kümesinde değerlendireceğiz)."
      ],
      "metadata": {
        "id": "ClYQ_b-4K3Sn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Model Kaydetme ve Yükleme**"
      ],
      "metadata": {
        "id": "UO4VfrMFj43n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Çok az deney yaptığımız için, en iyi performans gösteren modelimizi kaydetmek iyi bir fikirdir, böylece onu yeniden eğitmek zorunda kalmadan yeniden kullanabiliriz.\n",
        "\n",
        "Üzerinde save() yöntemini çağırarak en iyi performans gösteren modelimizi kaydedebiliriz. https://www.tensorflow.org/guide/keras/serialization_and_saving#the_short_answer_to_saving_loading\n",
        "\n",
        "Modeli kaydettiğinde model kaydedilir ve veri kümesini değerlendirdiğinde onu tekrar yüklemiş olursun.\n",
        "\n",
        "Bu modeli kaydedip colab dışında başka bir yerde kullanabilmeliyiz."
      ],
      "metadata": {
        "id": "44p9qpHhLEtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En iyi performans gösteren modeli SavedModel formatına kaydedin (varsayılan)\n",
        "model_5.save(\"skimlit_tribrid_model\") # model dizeyle belirtilen yola kaydedilecek"
      ],
      "metadata": {
        "id": "Y1_I9C-FLN8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "İsteğe bağlı: Google Colab kullanıyorsanız, daha kalıcı depolama için kayıtlı modelinizi Google Drive'a kopyalamak (veya indirmek) isteyebilirsiniz (bağlantınızı kestikten sonra Google Colab dosyaları kaybolur). https://colab.research.google.com/notebooks/io.ipynb#scrollTo=hauvGV4hV-Mh"
      ],
      "metadata": {
        "id": "lnUPeJLBLPH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kaydedilen modelin Google Colab'dan Drive'a kopyalanmasına örnek (Google Drive'ın takılı olmasını gerektirir)\n",
        "# !cp skimlit_best_model -r /content/drive/MyDrive/tensorflow_course/skim_lit"
      ],
      "metadata": {
        "id": "p_7hEtnMLSx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tüm iyi yemek pişirme şovları gibi, önceden eğitilmiş bir modelimiz var (tam olarak Google Drive ve Google Storage'da kaydedilen ve saklanan model_5 için oluşturduğumuz aynı tür model). https://drive.google.com/file/d/1quaeTYEzwolI0dXv98S9GEXOTVu9Akfk/view\n",
        "\n",
        "Bu nedenle, değerlendirme için hepimizin aynı modeli kullandığımızdan emin olmak için onu indirip yükleyeceğiz.\n",
        "\n",
        "Ve modelimize yüklerken, birkaç özel nesne (TensorFlow Hub katmanımız ve TextVectorization katmanımız) kullandığından, bunları tf.keras.models.load_model()'ın custom_objects parametresinde belirterek yüklememiz gerekecek.\n",
        "\n",
        "- https://www.tensorflow.org/guide/keras/serialization_and_saving#custom_objects\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model"
      ],
      "metadata": {
        "id": "Yg13s_RPLV5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Depolama Alanından önceden eğitilmiş modeli indirin\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/skimlit/skimlit_tribrid_model.zip\n",
        "!mkdir skimlit_gs_model\n",
        "!unzip skimlit_tribrid_model.zip -d skimlit_gs_model"
      ],
      "metadata": {
        "id": "5WWuzIxgLY0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow modeli bağımlılıklarını içe aktarın (gerekirse) - https://github.com/tensorflow/tensorflow/issues/38250\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "model_path = \"skimlit_gs_model/skimlit_tribrid_model/\"\n",
        "\n",
        "# İndirilen modeli Google Depolama Alanından yükle\n",
        "loaded_model = tf.keras.models.load_model(model_path)\n",
        "                                          # Not: TensorFlow 2.5+ ile SavedModel'inizde keras_metadata.pb dosyası varsa\n",
        "                                          # (model.save() kullanılırken oluşturulur), özel_nesnelere ihtiyacınız olmamalıdır\n",
        "                                          # parametre. Yapmanız durumunda kodu aşağıya bırakıyorum.\n",
        "                                          #custom_objects={\"TextVectorization\": TextVectorization, # karakter vektörleştirmesi için gereklidir\n",
        "                                          # \"KerasLayer\": hub.KerasLayer}) # belirteç yerleştirme için gerekli"
      ],
      "metadata": {
        "id": "FSsq-qLbLewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dosyada oluşan modele sağ tık yaparsan istediğin yükleme seçenekleri çıkmaz.\n",
        "\n",
        "Yüklü modeli test etmenin yollarından birisi de tahmin yapıp karşılaştırmaktır. Bu tahminler result kodundaki sonuçlar ile çok yakın olmalı."
      ],
      "metadata": {
        "id": "Clt3zOhwLhet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Değerlendirme**"
      ],
      "metadata": {
        "id": "3cawrazvj41R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin doğru bir şekilde kaydedildiğinden ve yüklendiğinden emin olmak için, onunla tahminlerde bulunalım, değerlendirelim ve ardından daha önce hesapladığımız tahmin sonuçlarıyla karşılaştıralım.\n",
        "\n",
        "Bir model ile sadece eğitim aldığı veri formatıyla aynı formatta tahminler yapılabilir.\n",
        "\n",
        "Kaynak şablonundaki veri tabloları google depolama alanında kayıtlıdır. Buradan veri almak için sağ tık link kopyala yap. (learntensorflow.io) Bu link !wget...unzip komutları ile yüklenebilir. -d dizin demek."
      ],
      "metadata": {
        "id": "mroVT5nYMDi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1. Doğrulama Veri Setini Değerlendir**"
      ],
      "metadata": {
        "id": "DpDJaWtUj4y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Doğrulama setindeki yüklü modelle tahminler yapın\n",
        "loaded_pred_probs = loaded_model.predict(val_pos_char_token_dataset, verbose=1)\n",
        "loaded_preds = tf.argmax(loaded_pred_probs, axis=1)\n",
        "loaded_preds[:10]"
      ],
      "metadata": {
        "id": "cwzeRgKsMJWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yüklenen modelin tahminlerini değerlendirin\n",
        "loaded_model_results = calculate_results(val_labels_encoded,\n",
        "                                         loaded_preds)\n",
        "loaded_model_results"
      ],
      "metadata": {
        "id": "B9N_rvuwMJRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yüklenen model sonuçlarını orijinal eğitilmiş model sonuçlarıyla karşılaştırın (oldukça yakın olmalıdır)\n",
        "np.isclose(list(model_5_results.values()), list(loaded_model_results.values()), rtol=1e-02)"
      ],
      "metadata": {
        "id": "DMRnKJfgMLn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yüklenen model özetini kontrol edin (eğitilebilir parametrelerin sayısını not edin)\n",
        "loaded_model.summary()"
      ],
      "metadata": {
        "id": "VNQhtubUMLj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaydedilmiş bir Model'e yüklemenin tüm katmanları çözdüğünü (hepsini eğitilebilir hale getirdiğini) belirtmekte fayda var. Bu nedenle, herhangi bir katmanı dondurmak istiyorsanız, eğitilebilir özelliklerini False olarak ayarlamanız gerekir."
      ],
      "metadata": {
        "id": "CFojRoCCMQsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2. Test Veri Setinde Modeli Değerlendir**"
      ],
      "metadata": {
        "id": "163xCEfGj4wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelimizin performansını PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts makalesinin Tablo 3'ünde bildirilen sonuçlarla daha karşılaştırılabilir hale getirmek için, test veri kümesi hakkında tahminlerde bulunalım ve bunları değerlendirelim. https://arxiv.org/pdf/1710.06071"
      ],
      "metadata": {
        "id": "nqV35BVoMc06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test veri kümesi kümesi oluşturun ve önceden getirildi\n",
        "test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
        "                                                               test_total_lines_one_hot,\n",
        "                                                               test_sentences,\n",
        "                                                               test_chars))\n",
        "test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n",
        "test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Şekilleri kontrol edin\n",
        "test_pos_char_token_dataset"
      ],
      "metadata": {
        "id": "RTjmfluCMfLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test veri kümesi üzerinde tahminler yapın\n",
        "test_pred_probs = loaded_model.predict(test_pos_char_token_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
        "test_preds[:10]"
      ],
      "metadata": {
        "id": "biV13K1vMfIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yüklü model test tahminlerini değerlendirin\n",
        "loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                              y_pred=test_preds)\n",
        "loaded_model_test_results"
      ],
      "metadata": {
        "id": "--HxtalYMfFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Görünüşe göre (şimdiye kadarki en iyi modelimiz) kağıttaki sonuçların performansını eşleştirmek için hala bazı yollara sahip (onların modeli test veri kümesinde 90.0 F1 puanı alır, bizimki de ~82.1 F1 puanı alır).\n",
        "\n",
        "Bununla birlikte, daha önce tartıştığımız gibi, modelimiz RCT 20k veri kümesindeki toplam ~180.000 dizinin yalnızca 20.000'inde eğitilmiştir. Ayrıca önceden eğitilmiş gömmelerimizi (kağıt ince ayarlı GloVe gömmeleri) ince ayar yapmadık. Sonuçlarımızı iyileştirmek için deneyebileceğimiz birkaç uzantı var."
      ],
      "metadata": {
        "id": "1Evv65cwMm1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3. En Çok Yanlışı Bul**"
      ],
      "metadata": {
        "id": "XTrjtxcRj4uf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelinizin nerede yanlış gittiğini (veya potansiyel olarak verilerinizin nerede yanlış olduğunu) araştırmanın en iyi yollarından biri, \"en yanlış\" tahminleri görselleştirmektir.\n",
        "\n",
        "En yanlış tahminler, modelin yüksek olasılıklı bir tahminde bulunduğu ancak yanlış anladığı örneklerdir (modelin tahmini, temel doğruluk etiketiyle aynı fikirde değildir).\n",
        "\n",
        "En yanlış tahminlere bakmak, daha fazla modeli nasıl geliştireceğimiz veya verilerimizdeki etiketleri nasıl düzelteceğimiz konusunda bize değerli bilgiler verebilir.\n",
        "\n",
        "Test veri kümesinden en yanlış tahminleri görselleştirmemize yardımcı olacak bazı kodlar yazalım.\n",
        "\n",
        "Önce tüm tamsayı tabanlı test tahminlerimizi dize tabanlı sınıf adlarına dönüştüreceğiz."
      ],
      "metadata": {
        "id": "PUPyCbzHMyQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Test tahminlerinin sınıf adlarının listesini alın\n",
        "test_pred_classes = [label_encoder.classes_[pred] for pred in test_preds]\n",
        "test_pred_classes"
      ],
      "metadata": {
        "id": "8vu2RfkbM1R_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi test DataFame'imizi birkaç değerle zenginleştireceğiz:\n",
        "\n",
        "1. Belirli bir örnek için modelimizin tahminini içeren bir \"tahmin\" (dize) sütunu.\n",
        "\n",
        "2. Belirli bir örnek için modelin maksimum tahmin olasılığını içeren bir \"pred_prob\" (float) sütunu.\n",
        "\n",
        "3. Modelin tahmininin numunenin hedef etiketiyle eşleşip eşleşmediğini gösteren bir \"doğru\" (bool) sütunu."
      ],
      "metadata": {
        "id": "4FhTMPm1M6gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahminle zenginleştirilmiş test veri çerçevesi oluşturun\n",
        "test_df[\"prediction\"] = test_pred_classes # test tahmin sınıfı adlarını içeren sütun oluşturun\n",
        "test_df[\"pred_prob\"] = tf.reduce_max(test_pred_probs, axis=1).numpy() # Maksimum tahmin olasılığını elde edin\n",
        "test_df[\"correct\"] = test_df[\"prediction\"] == test_df[\"target\"] # tahminin doğru olup olmadığına ilişkin ikili sütun oluşturun\n",
        "test_df.head(20)"
      ],
      "metadata": {
        "id": "mwSihef_M83u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En yanlış 100 örneği bulun (not: 100 ikili bir sayıdır, isterseniz hepsini inceleyebilirsiniz)\n",
        "top_100_wrong = test_df[test_df[\"correct\"] == False].sort_values(\"pred_prob\", ascending=False)[:100]\n",
        "top_100_wrong"
      ],
      "metadata": {
        "id": "nF-VSwrjM_-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En çok yanlış tercihleri ​​araştırın\n",
        "for row in top_100_wrong[0:10].itertuples(): # farklı örnekleri görüntülemek için dizinleri ayarlayın\n",
        "  _, target, text, line_number, total_lines, prediction, pred_prob, _ = row\n",
        "  print(f\"Hedef: {target}, Pred: {prediction}, Tahmin: {pred_prob}, Satır numarası: {line_number}, Toplam satır sayısı: {total_lines}\\n\")\n",
        "  print(f\"Cümle:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "metadata": {
        "id": "rrgQJWhvM_6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En yanlış tahminler hakkında ne fark ediyorsunuz? Model aptalca hatalar yapıyor mu? Veya bazı etiketler yanlış/belirsiz mi (örneğin, soyuttaki bir satır potansiyel olarak HEDEF veya ARKA PLAN olarak etiketlenebilir ve mantıklı olabilir).\n",
        "\n",
        "Buradaki bir sonraki adım, tutarsız etiketlere sahip birkaç örnek varsa, eğitim veri kümenizi gözden geçirebilir, etiketleri güncelleyebilir ve ardından bir modeli yeniden eğitebilirsiniz. Veri kümenizin etiketlerini iyileştirmeye/araştırmaya yardımcı olacak bir model kullanma süreci genellikle aktif öğrenme olarak adlandırılır."
      ],
      "metadata": {
        "id": "Hn21riYDNE_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.4. Örnek Tahminler Yap**"
      ],
      "metadata": {
        "id": "MdOKNl6_j4r7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Tamam, test veri kümesi hakkında bazı tahminlerde bulunduk, şimdi modelimizi gerçekten test etme zamanı.\n",
        "\n",
        "Bunu yapmak için, vahşi doğadan bazı veriler alacağız ve modelimizin nasıl performans gösterdiğini göreceğiz.\n",
        "\n",
        "Başka bir deyişle, PubMed'den bir RCT özeti bulacak, metni modelimizle çalışması için önceden işleyecek, ardından hangi etiketi tahmin ettiğini görmek için vahşi soyuttaki her diziyi modelimizden geçirecektik.\n",
        "\n",
        "Uygun bir örnek için, bölünmüş özetler olmadan RCT'ler (randomize kontrollü çalışmalar) için PubMed'i aramamız gerekecek (PubMed'i keşfederken, özetlerin çoğunun zaten ayrı bölümlere önceden biçimlendirilmiş olduğunu fark edeceksiniz, bu okunabilirliğe önemli ölçüde yardımcı olur).\n",
        "\n",
        "Çeşitli PubMed çalışmalarından geçerken, yüksek işlevli otizm spektrum bozuklukları için manuelleştirilmiş bir sosyal tedavinin RCT'den aşağıdaki yapılandırılmamış özetini bulmayı başardım: https://pubmed.ncbi.nlm.nih.gov/20232240/\n",
        "\n",
        "Orjinali:\n",
        "\n",
        "This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n",
        "\n",
        "Çevirisi:\n",
        "\n",
        "Bu RCT, HFASD'li çocuklar için manuelleştirilmiş bir sosyal müdahalenin etkinliğini incelemiştir. Katılımcılar rastgele tedavi veya bekleme listesi koşullarına atandı. Tedavi, sosyal becerileri, yüz-duygu tanımayı, ilgi alanını genişletmeyi ve edebi olmayan dilin yorumlanmasını hedefleyen öğretim ve terapötik faaliyetleri içeriyordu. Sorunlu davranışları azaltmak ve beceri edinimini teşvik etmek için bir response-cost programı uygulandı. Yedi birincil sonuç ölçütünün beşi (ebeveyn derecelendirmeleri ve doğrudan çocuk ölçümleri) için önemli tedavi etkileri bulundu. Personel derecelendirmelerine (yalnızca tedavi grubu) dayalı ikincil önlemler, ebeveynler tarafından bildirilen kazanımları doğruladı. Yüksek düzeyde tedavi sadakati ile birlikte yüksek düzeyde ebeveyn, çocuk ve personel memnuniyeti bildirilmiştir. Standartlaştırılmış etki boyutu tahminleri öncelikle orta ve büyük aralıklardaydı ve tedavi grubunu tercih etti.\n",
        "\n",
        "Büyük metin yığınına bakmak oldukça korkutucu görünebilir. Şimdi, çalışmanızla ilgili bir çalışma bulmak için literatürü gözden geçirmeye çalışan bir tıp araştırmacısı olduğunuzu hayal edin.\n",
        "\n",
        "Oldukça zor görünüyor değil mi?\n",
        "\n",
        "SkimLit'e girin 🤓🔥!\n",
        "\n",
        "Şimdiye kadarki en iyi modelimizin (model_5) yukarıdaki soyuttan ne yaptığını görelim.\n",
        "\n",
        "Ama bekle...\n",
        "\n",
        "Tahmin edebileceğiniz gibi, yukarıdaki özet, modelimizin eğitildiği verilerle aynı yapıda biçimlendirilmemiştir. Bu nedenle, üzerinde bir tahminde bulunmadan önce, tıpkı diğer dizilerimiz olduğu gibi onu önceden işlememiz gerekir.\n",
        "\n",
        "Daha spesifik olarak, her özet için şunları yapmamız gerekecek:\n",
        "\n",
        "- Cümlelere (satırlara) bölün.\n",
        "\n",
        "- Karakterlere bölün.\n",
        "\n",
        "- Her satırın numarasını bulun.\n",
        "\n",
        "- Toplam satır sayısını bulun.\n",
        "\n",
        "1 numaradan başlayarak, özetlerimizi gerçek cümlelere bölmenin birkaç yolu vardır. Basit bir tanesi, Python'un in-built split() string yöntemini kullanmak ve bir fullstop'un göründüğü her yerde özeti bölmek olacaktır. Ancak, bunun nerede yanlış gidebileceğini hayal edebiliyor musunuz?\n",
        "\n",
        "Başka bir daha gelişmiş seçenek, spaCy'nin (çok güçlü bir NLP kitaplığı) sentencizer sınıfından yararlanmak olacaktır. SpaCy'nin İngilizce dil modeline dayanan kullanımı kolay bir cümle ayırıcıdır.\n",
        "\n",
        "- https://spacy.io/\n",
        "- https://spacy.io/usage/linguistic-features#sbd\n",
        "- https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "Modelimizi denemek için PubMed RCT makalelerinden bazı özetler hazırladım, GitHub'dan indirebiliriz."
      ],
      "metadata": {
        "id": "6cJwYEvANpPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Örnek özetleri indirin ve açın (PubMed'den kopyalayıp yapıştırın)\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
        "  example_abstracts = json.load(f)\n",
        "\n",
        "example_abstracts"
      ],
      "metadata": {
        "id": "nKQ_N5jONsyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek özetlerimizin neye benzediğini görün\n",
        "abstracts = pd.DataFrame(example_abstracts)\n",
        "abstracts"
      ],
      "metadata": {
        "id": "Zm2u_l8HN21o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cümle oluşturucu oluşturun - Kaynak: https://spacy.io/usage/linguistic-features#sbd\n",
        "from spacy.lang.en import English\n",
        "nlp = English() # setup English sentence parser\n",
        "\n",
        "# spaCy'nin yeni versiyonu\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\") # cümle bölme boru hattı nesnesi oluştur\n",
        "\n",
        "# Ayrıştırılmış dizilerin \"belgesini\" oluşturun, farklı bir özet için dizini değiştirin\n",
        "doc = nlp(example_abstracts[0][\"abstract\"])\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)] # dize türünde belgeden tespit edilen cümleleri döndür (spaCy belirteç türü değil)\n",
        "abstract_lines"
      ],
      "metadata": {
        "id": "afnc2_kdN4vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Güzel! SpaCy, özetteki cümleleri doğru bir şekilde bölmüş gibi görünüyor. Bununla birlikte, ayrı cümlelere mükemmel bir şekilde bölünmeyen daha karmaşık özetler olabileceği unutulmamalıdır (Baclofen'deki örnek gibi, hepatit C virüsü (HCV) enfeksiyonu olan alkol bağımlı sirotik hastalarda alkol yoksunluğunu teşvik eder), bu durumda, daha özel bölme tekniklerinin araştırılması gerekir. https://pubmed.ncbi.nlm.nih.gov/22244707/\n",
        "\n",
        "Şimdi özetimiz cümlelere bölündü, toplam satırların yanı sıra satır sayılarını da saymak için biraz kod yazmaya ne dersiniz?\n",
        "\n",
        "Bunu yapmak için, preprocess_text_with_line_numbers() işlevimizin bazı işlevlerinden yararlanabiliriz."
      ],
      "metadata": {
        "id": "5EfzFjniN7wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Toplam satır sayısını al\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Özet olarak her satırı gözden geçirin ve her satır için özellikler içeren sözlüklerin bir listesini oluşturun\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "id": "y6sCauQ-N-Vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Şimdi \"line_number\" ve \"total_lines\" değerlerimiz var, onları tf.one_hot ile tek sıcak kodlayabiliriz, tıpkı eğitim veri kümemizde yaptığımız gibi (derinlik parametresi için aynı değerleri kullanarak)."
      ],
      "metadata": {
        "id": "1tNyjLVYOARq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek özetteki tüm satır_numarası değerlerini alın\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "# Eğitim verileriyle aynı derinliğe kadar tek seferde kodlama, böylece model doğru giriş şeklini kabul eder\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
        "test_abstract_line_numbers_one_hot"
      ],
      "metadata": {
        "id": "hMCoiyvOOBvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek özetten tüm total_lines değerlerini alın\n",
        "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
        "\n",
        "# Eğitim verileriyle aynı derinliğe kadar tek sıcak kodlama, böylece model doğru giriş şeklini kabul eder\n",
        "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
        "test_abstract_total_lines_one_hot"
      ],
      "metadata": {
        "id": "fNKkHKlRODSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Özet satırlarını karakterlere ayırın\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "metadata": {
        "id": "z8FYBK3mOFH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek soyut özelliklere ilişkin tahminlerde bulunun\n",
        "%%time\n",
        "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "id": "qnaA1TO6OGhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasılıklarını tahmin sınıflarına dönüştürün\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "id": "eRcoMUpKOGe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin sınıfı tamsayılarını dize sınıfı adlarına dönüştürün\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "id": "ss5foczTOGdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Özet satırlarını ve tahmin edilen sıra etiketlerini görselleştirin\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "id": "_N8aPl1nOGbm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okumak çok daha kolay değil mi? Demek istediğim, modelimizin tahminleri geliştirilebilir gibi görünüyor, ama bu ne kadar havalı?\n",
        "\n",
        "Sitedeki yapılandırılmamış herhangi bir RCT özetini biçimlendirmek için modelimizi PubMed web sitesinin arka ucuna uyguladığımızı hayal edin.\n",
        "\n",
        "Ya da herhangi bir yapılandırılmamış RCT özetine (modelimiz tarafından desteklenen) yapı ekleyecek \"SkimLit\" adlı bir tarayıcı uzantısı bile olabilir.\n",
        "\n",
        "Ve eğer tıbbi araştırmacı arkadaşınızı gösterdiyse ve tahminlerin standartlara uygun olmadığını düşündülerse, \"bu etiket doğru mu?... değilse, ne olmalı?\" diyen bir düğme olabilir. Bu şekilde, modelimizin gelecekteki tahminleriyle birlikte veri kümesi zaman içinde geliştirilebilir.\n",
        "\n",
        "Tabii ki, modeli, kullanılabilirliği, ön işleme işlevselliğini (örneğin, örnek soyut ön işleme boru hattımızı işlevsel hale getirmek) geliştirmek için kullanabileceğimiz daha birçok yol var, ancak bunları alıştırmalar/uzantılar için bırakacağım.\n",
        "\n",
        "🤔 Soru: Vahşi doğadan test örneğimizin sonuçlarının gerçekten vahşi olduğundan nasıl emin olabiliriz? Test ettiğimiz numune hakkında kontrol etmemiz gereken bir şey var mı?"
      ],
      "metadata": {
        "id": "OMyLT03sOK7V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.5. Kendi Denemelerim :)**"
      ],
      "metadata": {
        "id": "4xj7Hp2kj4p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/MuhammedBarut/dosyalar_nlp/main/kronik_gastrit.json\"\n",
        "\n",
        "response = requests.get(url)\n",
        "kronik_gastrit = response.json()\n",
        "\n",
        "print(kronik_gastrit)"
      ],
      "metadata": {
        "id": "E7y6XPhrOXa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek özetlerimizin neye benzediğini görün\n",
        "ozet = pd.DataFrame(kronik_gastrit)\n",
        "ozet"
      ],
      "metadata": {
        "id": "5a5A0WKaOXXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cümle oluşturucu oluştur\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "\n",
        "# spaCy'nin yeni versiyonu\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "# Ayrıştırılmış dizilerin \"belgesini\" oluşturun, farklı bir özet için dizini değiştirin\n",
        "doc = nlp(kronik_gastrit[0][\"abstract\"])\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)]\n",
        "abstract_lines"
      ],
      "metadata": {
        "id": "SoGBCuDOOXU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Toplam satır sayısını al\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Özet olarak her satırı gözden geçirin ve her satır için özellikler içeren sözlüklerin bir listesini oluşturun\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "id": "im3nNHGWOXSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek özetteki tüm satır_numarası değerlerini alın\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "\n",
        "# Eğitim verileriyle aynı derinliğe kadar tek sıcak kodlama, böylece model doğru giriş şeklini kabul eder\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
        "test_abstract_line_numbers_one_hot"
      ],
      "metadata": {
        "id": "K8Qo2uH6OXQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Özet satırlarını karakterlere ayırın\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "metadata": {
        "id": "akIHCZPxOePU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Örnek soyut özelliklere ilişkin tahminlerde bulunun\n",
        "%%time\n",
        "test_abstract_pred_probs = loaded_model.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "id": "gDrqAXl5OeNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin olasılıklarını tahmin sınıflarına dönüştürün\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "id": "VQfIRKL3OeIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahmin sınıfı tamsayılarını dize sınıfı adlarına dönüştürün\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "id": "4w6bcPqFOeFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Özet satırlarını ve tahmin edilen sıra etiketlerini görselleştirin\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "id": "mglcLDf-OjxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Kaynakça**"
      ],
      "metadata": {
        "id": "qViT0ESjj4nV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Bir metin veri kümesi indirme (GitHub'dan PubMed RCT200k) https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "* Model mimarisini https://arxiv.org/abs/1612.05251 adresinden çoğaltma\n",
        "* Dosyalar & Kaynaklar: https://github.com/mrdbourke/tensorflow-deep-learning\n",
        "* Bu dosyanın orjinali: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb"
      ],
      "metadata": {
        "id": "cd164cAkxZ7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Eğitim veri kümesindeki tüm veriler üzerinde model_5'i iyileştirmeyi durdurana kadar birçok dönem boyunca eğitin. Bu biraz zaman alabileceğinden, kullanmak isteyebilirsiniz:\n",
        "\n",
        "  - Sadece modelin en iyi ağırlıklarını kaydetmek için tf.keras.callbacks.ModelCheckpoint. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
        "\n",
        "  - tf.keras.callbacks.Doğrulama kaybı ~3 dönem için gelişmeyi durdurduktan sonra modeli eğitimden durdurmak için EarlyStopping. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping\n",
        "\n",
        "2. Önceden eğitilmiş GloVe gömmelerini kullanma konusunda Keras kılavuzuna göz atın. Bunu modellerimizden biriyle çalıştırabilir misin? https://keras.io/examples/nlp/pretrained_word_embeddings/\n",
        "\n",
        "  - İpucu: Bunu özel bir belirteç Gömme katmanıyla birleştirmek isteyeceksiniz. https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
        "\n",
        "  - GloVe gömülerini ince ayar yapıp yapmamanız veya donmuş bırakmanız size kalmış.\n",
        "\n",
        "3. TensorFlow Hub BERT PubMed uzmanı (PubMed metinleri üzerinde önceden eğitilmiş bir dil modeli) için TensorFlow Hub Evrensel Cümle Kodlayıcısı önceden eğitilmiş gömmeyi değiştirmeyi deneyin. Bu etki ortaya çıkar mı? https://www.kaggle.com/models/google/experts-bert/tensorFlow2/pubmed/2?tfhub-redirect=true\n",
        "\n",
        "  - Not: BERT PubMed uzmanı önceden eğitilmiş gömmeyi kullanmak, diziler için ekstra bir ön işlem adımı gerektirir (TensorFlow Hub kılavuzunda ayrıntılı olarak açıklandığı gibi). https://www.kaggle.com/models/google/experts-bert/tensorFlow2/pubmed/2?tfhub-redirect=true\n",
        "\n",
        "  - BERT modeli bu makalede bahsedilen sonuçları yendi mi? Https://arxiv.org/pdf/1710.06071.pdf\n",
        "\n",
        "4. Her dizi için line_number ve total_lines özelliklerimizi birleştirirseniz ne olur? Örneğin, bunun yerine bir X_of_Y özelliği oluşturuldu mu? Bu, model performansını etkiler mi?\n",
        "\n",
        "  - Başka bir örnek: line_number=1 ve total_lines=11, line_of_X=1_of_11'e dönüşür.\n",
        "\n",
        "5. Örnek bir soyut dize almak için bir işlev (veya bir dizi işlev) yazın, önceden işleyin (modelimizin eğitildiği şekilde), özetteki her dizi için bir tahminde bulunun ve özeti biçimde döndürün:\n",
        "\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "  - PREDICTED_LABEL: SEQUENCE\n",
        "\n",
        "...\n",
        "\n",
        "PubMed'den kendi düzenlenmemiş RCT özetinizi bulabilir veya bunu şu adresten deneyebilirsiniz: Baclofen, hepatit C virüsü (HCV) enfeksiyonu olan alkol bağımlı siroz hastalarında alkolden uzak durmayı teşvik eder. https://pubmed.ncbi.nlm.nih.gov/22244707/"
      ],
      "metadata": {
        "id": "rlMysx6CORZ0"
      }
    }
  ]
}